{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import model_img\n",
    "import fasttext\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "from keras import regularizers\n",
    "from importlib import reload\n",
    "from sklearn import metrics as sklm\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# CHOSEN_GPU_ID = 1\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "#   try:\n",
    "#     tf.config.experimental.set_visible_devices(gpus[CHOSEN_GPU_ID], 'GPU')\n",
    "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Visible devices must be set before GPUs have been initialized\n",
    "#     print(e)\n",
    "# else:\n",
    "#     print('No GPUs detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/srv/home/gwiedemann/pss-lre/model.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model_img)\n",
    "reload(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text_train = model.read_csv_data(\"data/Tobacco800/dataset.train\", csvformat=\"Tobacco800\")\n",
    "data_text_test = model.read_csv_data(\"data/Tobacco800/dataset.test\", csvformat=\"Tobacco800\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ft' not in locals():\n",
    "    ft = fasttext.load_model(\"./../embeddings/wiki.en.bin\")\n",
    "    model.ft = ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_text = load_model(\"models/exp1_single-page_repeat-07.hdf5\")\n",
    "model_text = load_model(\"models/tobacco800_exp1_prev-page_repeat-06.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8687258687258688\n",
      "Kappa: 0.7300263658102888\n"
     ]
    }
   ],
   "source": [
    "_, y_true, _, _, _ = zip(*data_text_test)\n",
    "y_true = [1 if y == 'FirstPage' else 0 for y in y_true]\n",
    "y_predict = np.round(model_text.predict(model.TextFeatureGenerator2(data_text_test)))\n",
    "print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predict)))\n",
    "print(\"Kappa: \" + str(sklm.cohen_kappa_score(y_true, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text.layers.pop()\n",
    "model_text_features = Model(model_text.input, model_text.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_train = model_text_features.predict(model.TextFeatureGenerator2(data_text_train))\n",
    "text_features_test = model_text_features.predict(model.TextFeatureGenerator2(data_text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (224,224)\n",
    "model_img.img_path_template = 'data/Tobacco800/images/%s.tif.small.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image_train = model_img.read_csv_data(\"data/Tobacco800/dataset.train\", csvformat=\"Tobacco800\")\n",
    "data_image_test = model_img.read_csv_data(\"data/Tobacco800/dataset.test\", csvformat=\"Tobacco800\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_image = load_model(\"models/exp2_img_repeat-07.hdf5\")\n",
    "model_image = load_model(\"models/Tobacco800_exp2_prev-page_repeat-05.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9111969111969112\n",
      "Kappa: 0.8157495901766108\n"
     ]
    }
   ],
   "source": [
    "_, y_true, _, _, _ = zip(*data_text_test)\n",
    "y_true = [1 if y == 'FirstPage' else 0 for y in y_true]\n",
    "y_predict = np.round(model_image.predict(model_img.ImageFeatureGenerator(data_image_test, img_dim, prevpage=True)))\n",
    "print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predict)))\n",
    "print(\"Kappa: \" + str(sklm.cohen_kappa_score(y_true, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_image.layers.pop()\n",
    "model_image_features = Model(model_image.input, model_image.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_train = model_image_features.predict(model_img.ImageFeatureGenerator(data_image_train, img_dim, prevpage=True))\n",
    "image_features_test = model_image_features.predict(model_img.ImageFeatureGenerator(data_image_test, img_dim, prevpage=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and test targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "_, data_train_y, _, _, _ = zip(*data_text_train)\n",
    "data_train_y = [1 if y == 'FirstPage' else 0 for y in data_train_y]\n",
    "# Test data\n",
    "_, data_test_y, _, _, _ = zip(*data_text_test)\n",
    "data_test_y = [1 if y == 'FirstPage' else 0 for y in data_test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, validation_x, validation_y, metric = 'kappa'):\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "        self.validation_x = validation_x\n",
    "        self.validation_y = validation_y\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = np.round(self.model.predict(self.validation_x))\n",
    "        true_labels = self.validation_y\n",
    "\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='binary', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metric)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            self.model.save(self.filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1031, 52)\n",
      "(259, 52)\n"
     ]
    }
   ],
   "source": [
    "lda_train_x = []\n",
    "with open(\"data/Tobacco800/lda_train.csv\") as f:\n",
    "    next(f)\n",
    "    for l in f:\n",
    "        lda_train_x.append([float(n) for n in l.split(\",\")])\n",
    "lda_train_x = np.array(lda_train_x)\n",
    "print(lda_train_x.shape)\n",
    "\n",
    "lda_test_x = []\n",
    "with open(\"data/Tobacco800/lda_test.csv\") as f:\n",
    "    next(f)\n",
    "    for l in f:\n",
    "        lda_test_x.append([float(n) for n in l.split(\",\")])\n",
    "lda_test_x = np.array(lda_test_x)\n",
    "print(lda_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1031, 52)\n",
      "(1031, 52)\n",
      "(259, 52)\n",
      "(259, 52)\n"
     ]
    }
   ],
   "source": [
    "features_x_train = lda_train_x\n",
    "features_x_test = lda_test_x\n",
    "sequence_x_train = np.empty((len(features_x_train),2,len(features_x_train[0])))\n",
    "sep_tp_x_train = np.empty((len(features_x_train),len(features_x_train[0])))\n",
    "sep_pp_x_train = np.empty((len(features_x_train),len(features_x_train[0])))\n",
    "for i, d in enumerate(features_x_train):\n",
    "    if d[3] == \"\":\n",
    "        prev_page = np.zeros((1,len(features_x_train[0])))\n",
    "    else:\n",
    "        prev_page = features_x_train[i-1]\n",
    "    sequence_x_train[i][0] = sep_pp_x_train[i] = prev_page\n",
    "    sequence_x_train[i][1] = sep_tp_x_train[i] = features_x_train[i]\n",
    "\n",
    "sequence_x_test = np.empty((len(features_x_test),2,len(features_x_test[0])))\n",
    "sep_tp_x_test = np.empty((len(features_x_test),len(features_x_test[0])))\n",
    "sep_pp_x_test = np.empty((len(features_x_test),len(features_x_test[0])))\n",
    "for i, d in enumerate(features_x_test):\n",
    "    if d[3] == \"\":\n",
    "        prev_page = np.zeros((1,len(features_x_test[0])))\n",
    "    else:\n",
    "        prev_page = features_x_test[i-1]\n",
    "    sequence_x_test[i][0] = sep_pp_x_test[i] = prev_page\n",
    "    sequence_x_test[i][1] = sep_tp_x_test[i] = features_x_test[i]\n",
    "print(sep_tp_x_train.shape)\n",
    "print(sep_pp_x_train.shape)\n",
    "print(sep_tp_x_test.shape)\n",
    "print(sep_pp_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_x_2inputs_train = [sep_tp_x_train, sep_pp_x_train]\n",
    "sequence_x_2inputs_test = [sep_tp_x_test, sep_pp_x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/40\n",
      "1031/1031 [==============================] - 3s 3ms/step - loss: 0.7090 - acc: 0.4985 - val_loss: 0.6468 - val_acc: 0.6139\n",
      "\n",
      "kappa improvement: 0.09699463077888582 (before: -inf), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 2/40\n",
      "1031/1031 [==============================] - 0s 9us/step - loss: 0.6676 - acc: 0.5752 - val_loss: 0.6288 - val_acc: 0.6139\n",
      "Epoch 3/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.6375 - acc: 0.6382 - val_loss: 0.6159 - val_acc: 0.6371\n",
      "\n",
      "kappa improvement: 0.15839325221238942 (before: 0.09699463077888582), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 4/40\n",
      "1031/1031 [==============================] - 0s 10us/step - loss: 0.6204 - acc: 0.6625 - val_loss: 0.6042 - val_acc: 0.6602\n",
      "\n",
      "kappa improvement: 0.21875642695550834 (before: 0.15839325221238942), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 5/40\n",
      "1031/1031 [==============================] - 0s 9us/step - loss: 0.6139 - acc: 0.6712 - val_loss: 0.5933 - val_acc: 0.6795\n",
      "\n",
      "kappa improvement: 0.26828687157493436 (before: 0.21875642695550834), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 6/40\n",
      "1031/1031 [==============================] - 0s 9us/step - loss: 0.6002 - acc: 0.6790 - val_loss: 0.5832 - val_acc: 0.6988\n",
      "\n",
      "kappa improvement: 0.3171308815575987 (before: 0.26828687157493436), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 7/40\n",
      "1031/1031 [==============================] - 0s 9us/step - loss: 0.5813 - acc: 0.7071 - val_loss: 0.5735 - val_acc: 0.7104\n",
      "\n",
      "kappa improvement: 0.34611371057326556 (before: 0.3171308815575987), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 8/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.5678 - acc: 0.7333 - val_loss: 0.5638 - val_acc: 0.7220\n",
      "\n",
      "kappa improvement: 0.3765712757421771 (before: 0.34611371057326556), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 9/40\n",
      "1031/1031 [==============================] - 0s 9us/step - loss: 0.5545 - acc: 0.7556 - val_loss: 0.5542 - val_acc: 0.7375\n",
      "\n",
      "kappa improvement: 0.4144168107461098 (before: 0.3765712757421771), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 10/40\n",
      "1031/1031 [==============================] - 0s 10us/step - loss: 0.5477 - acc: 0.7449 - val_loss: 0.5451 - val_acc: 0.7568\n",
      "\n",
      "kappa improvement: 0.46114725405369705 (before: 0.4144168107461098), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 11/40\n",
      "1031/1031 [==============================] - 0s 7us/step - loss: 0.5318 - acc: 0.7740 - val_loss: 0.5362 - val_acc: 0.7606\n",
      "\n",
      "kappa improvement: 0.4718458097618735 (before: 0.46114725405369705), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 12/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.5246 - acc: 0.7789 - val_loss: 0.5278 - val_acc: 0.7761\n",
      "\n",
      "kappa improvement: 0.5085710546977231 (before: 0.4718458097618735), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 13/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.5186 - acc: 0.7730 - val_loss: 0.5194 - val_acc: 0.7876\n",
      "\n",
      "kappa improvement: 0.535857417483953 (before: 0.5085710546977231), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 14/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.5015 - acc: 0.8021 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "\n",
      "kappa improvement: 0.5449043342444357 (before: 0.535857417483953), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 15/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.4884 - acc: 0.8060 - val_loss: 0.5032 - val_acc: 0.8031\n",
      "\n",
      "kappa improvement: 0.5730355238064453 (before: 0.5449043342444357), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 16/40\n",
      "1031/1031 [==============================] - 0s 7us/step - loss: 0.4773 - acc: 0.8041 - val_loss: 0.4956 - val_acc: 0.8108\n",
      "\n",
      "kappa improvement: 0.5908636642058094 (before: 0.5730355238064453), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 17/40\n",
      "1031/1031 [==============================] - 0s 9us/step - loss: 0.4781 - acc: 0.8089 - val_loss: 0.4878 - val_acc: 0.8108\n",
      "Epoch 18/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.4725 - acc: 0.8099 - val_loss: 0.4811 - val_acc: 0.8108\n",
      "Epoch 19/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.4625 - acc: 0.8157 - val_loss: 0.4743 - val_acc: 0.8108\n",
      "Epoch 20/40\n",
      "1031/1031 [==============================] - 0s 7us/step - loss: 0.4483 - acc: 0.8312 - val_loss: 0.4676 - val_acc: 0.8108\n",
      "Epoch 21/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.4450 - acc: 0.8177 - val_loss: 0.4615 - val_acc: 0.8147\n",
      "\n",
      "kappa improvement: 0.6007963521931796 (before: 0.5908636642058094), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 22/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.4385 - acc: 0.8361 - val_loss: 0.4553 - val_acc: 0.8224\n",
      "\n",
      "kappa improvement: 0.6184345375352294 (before: 0.6007963521931796), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 23/40\n",
      "1031/1031 [==============================] - 0s 8us/step - loss: 0.4338 - acc: 0.8244 - val_loss: 0.4498 - val_acc: 0.8263\n",
      "\n",
      "kappa improvement: 0.6272189349112427 (before: 0.6184345375352294), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 24/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.4273 - acc: 0.8380 - val_loss: 0.4443 - val_acc: 0.8301\n",
      "\n",
      "kappa improvement: 0.6359803232607169 (before: 0.6272189349112427), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 25/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.4203 - acc: 0.8332 - val_loss: 0.4390 - val_acc: 0.8301\n",
      "Epoch 26/40\n",
      "1031/1031 [==============================] - 0s 7us/step - loss: 0.4078 - acc: 0.8351 - val_loss: 0.4341 - val_acc: 0.8301\n",
      "Epoch 27/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.4041 - acc: 0.8380 - val_loss: 0.4292 - val_acc: 0.8340\n",
      "\n",
      "kappa improvement: 0.6437869822485207 (before: 0.6359803232607169), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 28/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3913 - acc: 0.8497 - val_loss: 0.4245 - val_acc: 0.8417\n",
      "\n",
      "kappa improvement: 0.6612435001754554 (before: 0.6437869822485207), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 29/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3896 - acc: 0.8497 - val_loss: 0.4199 - val_acc: 0.8417\n",
      "Epoch 30/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3844 - acc: 0.8574 - val_loss: 0.4157 - val_acc: 0.8456\n",
      "\n",
      "kappa improvement: 0.6699375557537912 (before: 0.6612435001754554), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 31/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3810 - acc: 0.8555 - val_loss: 0.4120 - val_acc: 0.8456\n",
      "Epoch 32/40\n",
      "1031/1031 [==============================] - 0s 7us/step - loss: 0.3921 - acc: 0.8555 - val_loss: 0.4086 - val_acc: 0.8494\n",
      "\n",
      "kappa improvement: 0.6794452730792422 (before: 0.6699375557537912), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 33/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3644 - acc: 0.8565 - val_loss: 0.4050 - val_acc: 0.8494\n",
      "Epoch 34/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3763 - acc: 0.8555 - val_loss: 0.4014 - val_acc: 0.8571\n",
      "\n",
      "kappa improvement: 0.6966733137087329 (before: 0.6794452730792422), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 35/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3810 - acc: 0.8535 - val_loss: 0.3982 - val_acc: 0.8571\n",
      "Epoch 36/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3850 - acc: 0.8448 - val_loss: 0.3954 - val_acc: 0.8571\n",
      "Epoch 37/40\n",
      "1031/1031 [==============================] - 0s 5us/step - loss: 0.3566 - acc: 0.8642 - val_loss: 0.3926 - val_acc: 0.8571\n",
      "Epoch 38/40\n",
      "1031/1031 [==============================] - 0s 5us/step - loss: 0.3761 - acc: 0.8613 - val_loss: 0.3901 - val_acc: 0.8571\n",
      "Epoch 39/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3573 - acc: 0.8691 - val_loss: 0.3878 - val_acc: 0.8649\n",
      "\n",
      "kappa improvement: 0.7130693508055581 (before: 0.6966733137087329), saving to Tobacco800_exp3_img-text_lda_model.hdf5\n",
      "Epoch 40/40\n",
      "1031/1031 [==============================] - 0s 6us/step - loss: 0.3586 - acc: 0.8710 - val_loss: 0.3853 - val_acc: 0.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.keras.callbacks.History at 0x7f42079efa58>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tp = Input(shape=sequence_x_2inputs_train[0][0].shape)\n",
    "input_pp = Input(shape=sequence_x_2inputs_train[1][0].shape)\n",
    "difference = subtract([input_pp, input_tp])\n",
    "final_feat = concatenate([input_tp, input_pp, difference])\n",
    "final_feat = Dense(400)(final_feat)\n",
    "final_feat = LeakyReLU()(final_feat)\n",
    "final_feat = Dropout(0.9)(final_feat)\n",
    "model_output = Dense(1, activation = 'sigmoid')(final_feat)\n",
    "combined_model = Model([input_tp, input_pp], model_output)\n",
    "model_path = \"Tobacco800_exp3_img-text_lda_model.hdf5\"\n",
    "checkpoint = ValidationCheckpoint(model_path, sequence_x_2inputs_test, data_test_y)\n",
    "combined_model.compile(loss = 'binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "combined_model.fit(sequence_x_2inputs_train, data_train_y, validation_data = (sequence_x_2inputs_test, data_test_y), \n",
    "                   batch_size=4096, epochs=40, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text = load_model(\"models/tobacco800_exp1_prev-page_repeat-06.hdf5\")\n",
    "model_image = load_model(\"models/Tobacco800_exp2_prev-page_repeat-05.hdf5\")\n",
    "model_lda = load_model(\"models/Tobacco800_exp3_img-text_lda_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t_train = model_text.predict(model.TextFeatureGenerator2(data_text_train))\n",
    "p_v_train = model_image.predict(model_img.ImageFeatureGenerator(data_image_train, img_dim, prevpage=True))\n",
    "p_l_train = model_lda.predict(sequence_x_2inputs_train)\n",
    "p_t_train = np.concatenate([1 - p_t_train, p_t_train], axis = 1) # probability from text model\n",
    "p_v_train = np.concatenate([1 - p_v_train, p_v_train], axis = 1) # probability from visual model\n",
    "p_l_train = np.concatenate([1 - p_l_train, p_l_train], axis = 1) # probability from lda model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t_test = model_text.predict(model.TextFeatureGenerator2(data_text_test))\n",
    "p_v_test = model_image.predict(model_img.ImageFeatureGenerator(data_image_test, img_dim, prevpage=True))\n",
    "p_l_test = model_lda.predict(sequence_x_2inputs_test)\n",
    "p_t_test = np.concatenate([1 - p_t_test, p_t_test], axis = 1) # probability from text model\n",
    "p_v_test = np.concatenate([1 - p_v_test, p_v_test], axis = 1) # probability from visual model\n",
    "p_l_test = np.concatenate([1 - p_l_test, p_l_test], axis = 1) # probability from lda model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.1 0.1\n",
      "Accuracy: 0.915057915057915\n",
      "Kappa: 0.8244284217661921\n"
     ]
    }
   ],
   "source": [
    "# scoring with diffent i, j in (0,1] power normalizations\n",
    "max_kappa = 0\n",
    "test_exponents = [x / 10 for x in range(1,11)]\n",
    "for i in test_exponents:\n",
    "    for j in test_exponents:\n",
    "        for k in test_exponents:\n",
    "            y_predict = np.argmax(np.power(p_t_test, i) * np.power(p_v_test, j) * np.power(p_l_test, k), axis = 1)\n",
    "            acc = sklm.accuracy_score(y_true, y_predict)\n",
    "            kappa = sklm.cohen_kappa_score(y_true, y_predict)\n",
    "            if kappa > max_kappa:\n",
    "                max_kappa = kappa\n",
    "                print(str(i) + \" \" + str(j) + \" \" + str(k))\n",
    "                print(\"Accuracy: \" + str(acc))\n",
    "                print(\"Kappa: \" + str(kappa))\n",
    "\n",
    "# Best results: i = 0.4 k = 0.1 j = 0.2\n",
    "# Accuracy: 0.9338567222767419\n",
    "# Kappa: 0.7078080262749252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.2 0.1\n",
      "Accuracy: 0.918918918918919\n",
      "Kappa: 0.8313436075537226\n"
     ]
    }
   ],
   "source": [
    "i = 0.1\n",
    "j = 0.2\n",
    "k = 0.1 \n",
    "y_predict = np.argmax(np.power(p_t_test, i) * np.power(p_v_test, j) * np.power(p_l_test, k), axis = 1)\n",
    "acc = sklm.accuracy_score(y_true, y_predict)\n",
    "kappa = sklm.cohen_kappa_score(y_true, y_predict)\n",
    "print(str(i) + \" \" + str(j) + \" \" + str(k))\n",
    "print(\"Accuracy: \" + str(acc))\n",
    "print(\"Kappa: \" + str(kappa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Training set*\n",
    "......\n",
    "\n",
    "with LDA\n",
    "\n",
    "0.1 0.2 0.1\n",
    "Accuracy: 0.918918918918919\n",
    "Kappa: 0.8313436075537226\n",
    "\n",
    "without LDA\n",
    "\n",
    "0.1 0.1\n",
    "Accuracy: 0.915057915057915\n",
    "Kappa: 0.8244284217661921\n",
    "\n",
    "\n",
    "*Test set*\n",
    ".......\n",
    "\n",
    "0.1 0.1 without LDA\n",
    "Accuracy: 0.915057915057915\n",
    "Kappa: 0.8244284217661921\n",
    "\n",
    "0.1 0.3 0.4 with LDA\n",
    "Accuracy: 0.9305019305019305\n",
    "Kappa: 0.8548838946647576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Tobacco800/images/tza31a00.tif.small.png\n",
      "data/Tobacco800/images/vrr09c00-page03_1.tif.small.png\n",
      "data/Tobacco800/images/wau30a00-page9_10.tif.small.png\n",
      "data/Tobacco800/images/wdf61f00-page2_1.tif.small.png\n",
      "data/Tobacco800/images/yru03f00-page03_1.tif.small.png\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsnXd8lFX2/9/PlMxMZtInvYcSIAkECBDpIjWAioqCgK6yIlhY8auu7qrozxVlZRVdXYUVBBVcYFFEESkiGEKoAZKQQhrpvSeTTH1+f7DPswlNUFBw83m98prMzFPu3Ofec88953POEURRpAtd6EIXJCh+7QZ0oQtduL7QJRS60IUudEKXUOhCF7rQCV1CoQtd6EIndAmFLnShC53QJRS60IUudMI1EwqCIEwUBCFbEIRcQRCevVb36UIXunB1IVwLnoIgCErgNDAOKAGOADNFUcy46jfrQhe6cFVxrTSFwUCuKIr5oihagH8Bt12je3WhC124ilBdo+sGAsUd3pcAQy52sNFoFMPCwq5RU7rQhd8GRFGkoqICtVqN0Wi84vOPHTtWI4qi948dd62EgnCBzzrtUwRBmAfMAwgJCeHo0aPXqCld6MJvAzabjSVLlhAYGMjcuXOv+HxBEAov57hrtX0oAYI7vA8CyjoeIIriSlEU40RRjPP2Piu8HA4HJpPpkhcWRZFTp06RlpZ2lZvchS50Aa6dUDgC9BAEIVwQBCdgBrD1x046ffo0u3fvxuFwXPQYURSpra2lrq7u6rW2C13ogoxrsn0QRdEmCMJjwA5ACawWRfHUj53Xq1cvunXrRmtrKy4uLoiiiCB03okoFAqGDx8OnFWnVKprtQP6deFwOBAE4bzf/7+IC42DLlw7XLMZJYriN8A3V3qeWq1GrVYDXHQgKBSKS35/I8NutwOgVCplwfC/iPb2dux2OwqFAq1W2yUY/oNfItXBDc1o/KmD5JfMIeFwOBBF8by/i8FqtWIymdiwYQOtra2dju943oWuce5xF3vtePy517zYdc9tx+X8lkud82PPwG63Y7VaaWtr46WXXkIQBOx2+xW177eIX0IwXpdC4WIP/+dCGixtbW2dPpcm7oXa8XPuBZCRkcGZM2coLi6mtbX1PHuIw+HoZEPRarW4uLhwzz338Omnn2K32zlz5gwOh4Pc3FysVitWq5WGhgasVqt8H6vVSllZGW1tbVRXV2M2m6msrEQURSwWCwA5OTmYTCZaWlowm81UVVVRUVEhX6OgoIDa2lra2tpoa2vDZrNhNpuprq6mqakJi8WC1WqltraWsrIyampqZMOwKIrYbDZEUcRut9Pa2kprayvV1dXyObW1teTm5lJUVER1dbX8u202G+3t7QA0NDQAoNfrcXNzw93dndmzZ7N+/XqUSiV1dXW0tLQAYLFYcDgcNDU1UVVVJfeJyWSisPCyDO03HIqKiq65YLguN+RZWVkcOnSIBx988KpeVxAEHA4Hf/vb33jhhRew2WwkJiZy8OBBJk2aRN++fVEoFLKqqlQqf/K9HA4HSqWS3//+94wbNw69Xo8gCPj5+fHFF1+wZcsWLBYL8+bNY8yYMdx3333nXWPIkCHs2LGDbdu2sXTpUnbv3s3UqVN59NFHSUhIID09nbfffhtBEKiqquKpp56iT58+iKJIVFQU7777Lt988w2TJk1ix44dfPnll0RHR5OVlYWHhweVlZXodDoWLlwIwLp16+jfvz8lJSVYrVZKSko4c+YMrq6utLa2UlRUxMaNG/nggw8QRZHw8HAaGhp48skncTgcTJs2jXfeeYcTJ07g7e3Nrl27OHz4MMHBwURERODh4YEoiuTk5GA0Gnn22WexWCysWLGC4uJi/vKXv5z3vADc3NxISkqiubmZ+vp64uLiGDt2LGvXruXUqVOMGDGCTz75hHnz5vHtt98SGRmJUqlkyJAh9O/f/yc/w+sRgYGB11wLui6FQlRUFFFRUVftetIkf+aZZ5g6dSrPP/88ANu3b2fMmDGsW7eOPn36yMc3NzfjcDiYO3cumzdvljUMyZYhiqI86e12uyw8pPt0VF8bGxvJysrCbrfj6urKgQMHyM3N5a233sJkMmG1Wvn6668JDg7m5ptvls/94YcfWL9+PTabjUOHDvHJJ5/wz3/+kx07dtCzZ0+WL19OQkICzz77LKIo4uTkRGZmJgMHDmT79u2YzWZqa2uZMmUKsbGxzJw5k/z8fKZOnUp1dTVGo5Ht27fj5+eHTqfDw8ODTz/9FJVKhSAIaDQaWltb0Wg0lJaWMnnyZMLCwpg2bRo2m42EhASOHDlCRkYGgYGBVFVVMXHiRBYvXkx0dDQVFRWyVtPY2IiHhwfffPMNCoWCOXPmkJyczObNm3E4HOzbtw+9Xs9zzz3H0aNHGTNmDIsXL8bhcKBQKJg/fz7Nzc1ERERgNBopKCjg888/Jz09nV69erF7924sFgsffvght99+OydOnCAxMZHg4ODfnFAwmUzXXFO4JrEPV4q4uDjxcslLkvFNmqQdJ+KFOkv63Gq1kpeXR0REBE5OTuzatYvu3buzdu1abrrpJiZMmEBZWRmfffYZWVlZzJ07lzNnzjB27Fg8PDxQKpWUlJSgUCjw8vJCo9HQ0tKCwWA4zwsiCYri4mKCg4Npb2+XtRSlUomTkxMNDQ0IgoCTk5P8KgkdgLa2Nux2OyqVCq1WS0NDA+7u7pjNZsxmM66urrS0tHTqDxcXFxobG3FxccFkMslta29vR61Wo9VqaWlpkYWZs7MzoijKQtDT05PW1tZO/Sa1rbm5GYVCgcFgQKFQ0NraKguP5uZmue+1Wi02m03+rZLRuK2tDb1eD0BTUxMajQaz2QyAs7OzvFVzdnamubkZV1dXuS8aGxvR6/W0tbV12nI4OztjsVjkvnNycqK+vh6tVotGo8FisaDT6S5vEN4AsNls3HvvvUyaNIkHHnjgis8XBOGYKIpxP3bcdakpSCvEhdDR83Duynwh4SC9f+SRR/jb3/4GnN1/G41G3NzcGDt2LMOHD8dqtZKUlERWVhbz5s1j3759PPnkkyxcuJClS5eSmZnJ8ePHaW5uZvLkyfz73/8mJCSElpYWnJ2duf/++yktLSUwMBCr1UpxcTELFixg+/btqFSq81yn7u7u5/22jm0/dzBLx2s0GjQaDQAGg+G8a0jHubi4AJ29OT92DiBP3HPh4eHR6X3H65z73YXg5OQk/+/p6XnJe3UUCHB2+wD//U0dcW4/Sde+0He/BQQHB/9vbR+kSXHy5En69+9/nnBoaWlh2rRpjB8/nqSkJJ577jnS0tIQRZEjR47w4osvYrfbCQ0NlVeeAwcOkJKSwoIFC3B1daWmpoaZM2eybt06SktLZc5DXV0dra2thISEcOLECZ566imef/55HnjgARoaGnjwwQeZNm0aDzzwAI899hgDBw5k7NixPPbYYxgMBnl1ltRtvV7P+PHjZa3hxx6kIAjU19fj6en5i1vOu1x9Nw5sNts1v8d1JRQkXExL0Gq1BAQEEBYWRkpKCs3NzQwcOJBt27YRERHRafIpFArsdjvFxcWUl5dz8uRJoqOjsVqtvP/++/j4+HRaQZVKJe7u7owePRpXV1eam5uZM2cOkZGRJCcns2TJEoYPH467u7tsaHN1deXJJ58kODgYvV6PxWLB398fgK1bt5KQkIBCobjsSSetkF2TtAsXg5ub2zVfNG4om4LJZOK7774jJCQEhUKBm5sbqampxMTEYLFY0Gg0GAwGduzYQW5uLgEBASQlJdHU1MRdd92FWq3GarXS3t4ubx9SU1Ox2WzYbDaCg4NpbW2lpqaGbt26ERsby4kTJwgKCsJut9Pc3ExZWRlqtZq6ujr69OmDyWSipKREtqybzWbsdjs6nQ673X5Jyva5kLY/HaFQKPD29qasrAy9Xo/JZLqo0LxcOBwOvL29qampwWq18tBDD3WRg24AXIWAqBvXpnAxODs7M3XqVHlrIAgCISEhnQa0w+Fg5syZ8jkdDTIbN25kxowZwH95BD169CAvL4/Tp09z991343A4OHbsGEePHuWjjz7ilVdeITExkb179/LCCy908jb8ltAlELog4bokL10M7e3tZGZmolQqsVqtCIJAXl4eNTU1FBQU0NbWJnskpEkvWf1ffPFFZsyYQUZGBnv27MHhcJCSksLatWspKCigubmZjz/+mB07dpCdnY3JZGLLli0A9OvXD2dnZ+DiW5sudOG3ghtKU2htbSUzM5PVq1fT1NREv379yMrK4p133uGzzz5j5syZlJaW0r17d5lZ9/HHH7NixQpefvllAHr37k1YWBiFhYUMHDgQX19fgoKC5HtIiSxWrVpFWloau3btoqamht///vfAtV9RO24fBEHAbDbL3oYuXDku5o260HddOIsbSigIgkBmZiaTJ08mKCiInJwcmfIr+f51Oh1Hjx6loKAAnU7H+++/T3NzM6tWraK2thaz2YzRaJQ1BWdnZ/7xj3/g4uIiW/7j4+MZM2YM6enpWK1W/P39OXbsGDk5Obi7u+Pr6wucdXlVV1eTkZGBSqXCaDRiNpsJCwtj3LhxVzToWltbZdajJAgKCgrw8vLCZrOh0WhkLaVLW7kytLe3U1lZiaurK0qlksbGRhQKBUajsUvgXgA3lKGxIy4VWlxRUSGTbXQ6HUqlUv5f0iAcDgdOTk60trbKg8Td3R1BEHB2dpYJTxUVFfKx0lZErVbLxB2AmpoaFAoFer0ejUaDTqeTtxsdtzEdA3Y62kDUajX5+flERESQkpLCvn37sNlsfP/998yZM4eMjAxeeeUVDh48SHx8PFartRO78uesdhc6v+NK2vGzc9+fex3pValUdvreZrNdcnW+kIH150Lq1w0bNjBhwgReeOEFPDw8MBqN+Pn50dzcTHt7O3PnzpVZnFezTefyaCT8HHtUl6HxApAEQcdXu92OWq3uNNh8fX3l1bwjLjR59Ho9Pj4+FzxOq9XKJB1RFKmpqWHDhg34+/uTlpaGt7c3FosFi8UiBw9ZrVaio6NRKpW4ublRVFSEw+FAr9dTWVmJzWZDp9NhNBplTcPV1ZW0tDTWr1/P448/TlJSEiNHjkSlUnHo0CEOHDjAgQMHOHHiBFOnTuWBBx7g4MGDWK1WHA6HTB5qaGhAr9cTEhJCTk6OfC8p2EitVmOxWDppGg6HA4PBgNlsRq1Wo9PpcHNzQxAEKioqcHJyQq1Wo9FoaGpqQqfTYTabZa1KsuFI7MqioiKmT59Ov379ZKH9//7f/6N3797U19djMpnk56fRaHBxccFut9PS0oIgCDQ3N6NUKrHZbCiVSiIiIsjJyQHOamY9e/akqKiIgIAAtFotDocDi8Ui25Pq6+tRq9V4eHhQUlJCbm4uOTk5GAwGmpqaSElJITAwkNzcXPz8/OQgL1dXV1n419fXExUVhcPhQKPRyONMq9V2ohmfS5jTaDRUVFRgMBjw9fWltLSU2tpaLBYLAQEBaDQaRowYIbsVr9etyw0lFFJSUkhPT8fX15eDBw8ydOhQdu3axf33389nn33GkiVLWLduHbNmzbokK7IjfuzBdPxer9ezb98+nnjiCfr374/ZbOa1114jISGBkSNHcv/997N48WIGDRrE/v37ycnJob29HaVSSVxcHKIo4ubmxkMPPcQzzzzDmjVrGDBgAOnp6SxcuJDFixezYsUKxo8fz7hx45g2bRoACxculDkVUsq6KVOmyO8lpp9EPQbo06ePPMilKEmVStVp1ZbOl+jC7u7u2Gw2DAYDFotF3o5J1GwpFsJisXTyl0u0Z7vdTm1tLd26det0j7S0NDQaDZMmTSInJwdPT0+amprw8/OjurqaoUOH0tDQgEKhOC8dn0qlonfv3rKAEQRBthl1hBT/IQk5jUYja3cqlUrWYKqrqwkODmbRokWoVCpGjBhBc3MzX3zxBaIoctddd9HU1ESvXr3Iz89HpVLJHJbs7GyioqJkQ7ZEFxcEAYVCwerVqxk3bhybN2/mvffeY9myZcybN4/GxkZSU1PJyspi/PjxlzXufk3cUELB3d2d/fv38+c//5kffviB/v3709bWxuHDh2U+wNatW5k1a9ZV73RBENDr9XTr1o3u3bvj6emJUqkkOzub8PBwAAYNGkRcXBwajYYPP/yQ1NRUbr/9dsLCwoiKiiI/P5/MzEw8PT25+eab2bVrF+PHj2fHjh0EBASwePFihg4dyoQJE65q2y8XSUlJ9OvXT9aOztW2pFyaF4JERQ4ODu70ucPhICgoCH9/f77//nsOHTrEW2+9xc6dOwkPD2ft2rXcfvvteHl5XbZqLdlcfspqK5HLXF1diY2N5eTJkyQkJGC32xk+fDjr169nwoQJ1NbW0tjYSG5uLt7e3sTFxbF7927uuusuOdYlMzNTDtw7duwYkZGR3HzzzSQnJ6NUKvHz86OiooLq6mr69u3LrbfeekVt/bVwQ9kU6urqOHbsGCqVSuYL+Pv7y4Qem82G1WqlZ8+eeHl5XRMV7YUXXuCVV16RB8YTTzzByJEjmTBhAjU1NYSGhmKxWKioqKCtrU3O39CnTx/UajUKhaKTPaSjzeGtt94iLi6OESNGXBbpyeFwsGHDBvbu3cvUqVOZOHEiTk5OvPHGG8ydO5empiZcXFyoqKjAy8sLNzc3Tp8+LRO3tFotdXV1NDc3s2nTJp599tkrIltJ7T53DHX8bYIgyMzQBx54gKamJs6cOUNgYCAlJSVs2rSJJ554gtraWoxGo2xb6dgvgiDIMRzvvPMOs2fPxsPDg5aWFnn7cqG+MRgM9OjR47zPFQoFI0eOZN68eYSFheHs7ExFRQUWi4VevXphMplkLUAKPHN1dcVsNneyY7m4uFBcXIzD4cDf319OiqPX62lqasJgMNDW1oZSqaS9vR2FQkFkZCRarfaK+lhCl03hAvD09GTcuHGXffy1UNH8/PxklVFqU1tbG0VFRfj6+vLOO+8QEhJCY2MjX375JTqdDl9fX26//XaGDRsG0MlIWFZWxnfffcewYcPw9/end+/enY65FCRjWl5eniyA4GzMfVlZGf/85z+ZPHkyKSkp2Gw22traZHuA0Whk1qxZvP/++/j5+bFw4cJO4eFXgov1s/S5QqGgtLSUxMREfHx8iI+Pp6qqioSEBI4fP86+ffvYsmULb7zxBikpKSiVShISEmTNob29ncLCQtzc3Fi6dKkciflz8nMOGTKE6OhosrOzueeee1i+fDnV1dWcPHmS06dP89BDD3Hs2DHGjh0rR3i++OKLbNq0CYvFQk1NDSqVijNnznDPPfdc8QIkHV9YWEhoaOhP/h3XAjeUUJDyGHTEhazgVxJvcKU4efIkr776KoMHD6atrQ2r1crevXsZPHgw69evx9PTk5ycHGprazlz5gy9e/cmPDycXbt24eLigk6nQ61WyyuH3W4nMTGR1NRUhgwZQnNzM+Xl5ZecnNJvdHJyYu/evXh4eFBcXMzy5cu54447yMrKwtPTk5KSEtzc3KioqMDHx4esrCwWLFjAvn37SE9Pp7y8nIKCAubNmydnV4KzEZCS4LPZbFgsFkRRlKnbcNZo2dzcjJubmzxBbTYbJpOJwMBAvLy85OdjtVq5+eabKSwsZNu2bZhMJg4dOsS9997Lt99+y+TJk2XquLu7O6mpqYSEhMheI1EU+fOf/4ynpycvvfQStbW1lJeXExERgdlsvmBfScbd7t27X7AP8/Pz2bdvH3Fxcezbt4+mpiYEQeDYsWMoFAqqq6s5c+YMaWlpVFVVERAQgMlkIi8vD6vVyvLly/Hw8CAhIYETJ0502vpImqCzszOtra1y36hUKrp169ZJU7jUluzXwg0lFH5uNqSrgZ49e9KjRw8mTpyIKIqkpqYybNgwGhsbGTJkCEePHiU2NhaTycQnn3zC1KlTKS8v5/7776eiooKGhgba29sZOXIkoiiSmZlJbGws8+bN6xSgdTFIg+uPf/wj48ePZ8KECWzcuJGKigpee+011Go1kZGRhIeHM3HiRFpaWnByciIgIIAdO3aQk5ODv78/Q4cORalUMnz4cB5++GEiIiLo27cv0dHR5OfnU15eTnV1NbNnz5bTr3l6ehIREUF1dTWlpaVMmDCB1atXk5aWRnl5Obfeeiv333//ea7i9evX8+abbxIUFCTbK4YOHUpGRgYPPvggYWFh7Nu3j7CwMDIzM5k+fTqpqaloNBry8/P5wx/+wOuvv46rqyslJSUMHjz4JydPkYTMlClTGDBgAP369cPhcJCeni4n1fH09GTAgAH06NFDTo935MgRAgICyMrKorq6mvHjx6PT6ejVqxebN29m/vz5wFl7R2pqKoMGDWLhwoW88847JCcnc9NNN3H06FEsFgvZ2dmcPn2a6dOnX5fh3TeUUPg1IYoi9fX12Gw2ysvLKSsrIzk5GaPRSEtLCyqVitbWVjw8PDhz5gz19fVERkbi4eGBq6srR44cYdiwYbi6ujJ37lxGjBiBwWDg+++/54knnkCtVl9RTsjZs2cTExPDsmXLGDhwIKWlpaxcuZIFCxbg6emJ2WyWXYAxMTE0NTURGBhIQ0MDgYGBnDhxgri4OKZMmSK7MhMSElCr1WRlZaFUKhk0aBDr16/n0UcfxcvLiy1btlBSUoKrqyttbW00NjZy++234+7ujoeHB1lZWbz00kvEx8czadIkWWO777776NatG0eOHMFgMFBaWoqbmxsZGRkMHTqUHTt2UF1dzdGjR/nuu+/w8/MjOTmZsLAwKisrOXDgAI2NjSxdupQPPviA06dP/2hfSV4VyQjcEYIg8OWXX6LRaHB3d8disdDY2Mhzzz2Hk5MTSqUSFxcXmpqa0Gq19OrVi9OnT5OdnU1iYiINDQ2EhIRQW1uLUqkkNzeXtLQ02ctRX1/P999/T2xsLCtXriQ9PR2dTseqVauIiIigf//+TJky5bp1S95QhsZfG+3t7Tz33HOMGDGCO+64A5vNxp133omHhwczZswgLy8Pf39/OYnpe++9xw8//ADASy+9REREBPHx8fTs2VO+5pXWd5AGUnFxMZs2bcJutzN48GCysrL4/e9/j1Kp5O9//zu33norGzZsoL29nZiYGMrKyti9ezcJCQlyVOTF0JFYdSGDqPTduUa+i/2GxYsX8/DDD7N7927MZjNTpkwhOzsbPz8/VqxYwRtvvMHSpUv585//zP79++UcF83NzdjtdrZv305oaChDhw790X7JysqiV69eFz1OMlCvWrWKoKAgwsLCEAQBNzc31q9fz8iRI2lra5PbAHD8+HH69+8vv/7cyXy57vJz0WVovA6h1WoZMmQIwcHBVFdXk5WVRWBgIIsXL6aiooLc3FxZFQ4KCuqUkahXr15yhGbHSMsrHRxSmrMXX3yRRx55BDiba9Lf35+tW7cybdo0DAYDoaGh1NXVMWHCBJKTkykrK2PAgAEy0/JyBnXHtp17/JXU3lAoFLz22mu0trbi4+PDkSNH2LdvH5GRkVRWVrJ7926++uorbrnlFpYtW4ZGo8HHx4e8vDw++OADFi5cSENDAy+//DKzZs265KQURZG8vDw5fP1cF6l03rp165g5cyYnT57Ey8uL8PBwjh8/jslkoqGhgV69elFfX48oinz11Vd89NFHDBs2DL1eL3MUrgSiKKJWq/Hz8/vJ3odfCl2awhXAarWyf/9+AEaPHo3VauXQoUOYTCaGDBmCwWCQ065LRqaOKcckI+nViF1ob29Hq9VSWVnJt99+y5AhQwgJCcHZ2Znjx49jt9vp168farWampoaDAYDy5cvlzNF/RKQJq8Uq3L33XeTkZFBZGQkjY2NeHl5UVVVhUajoaSkBF9fX86cOUNoaCjt7e00NTVRXl5OXl4ecXFxuLm54ePjIxucz6VjSyQih8OB1WpFp9Odxw3o6JIcMWIEAwYMwNXVldTUVI4cOSK7dYuKiujfvz8tLS1UVVUhCAI9e/akrq5Otm1JrMvLgcPhQKfTMXToUNzd3X+SttGlKVyHcDgc5Ofno1QqaWtrIzc3l507dxIXF8eOHTs4deoUixYt4uTJk+Tk5LBjxw7+/e9/ywP4agYySRRfKSnMyZMnyczMZNq0aZw6dYrZs2fz7rvv0rNnT6qrq6mtraW6upp9+/YxefLkq9aOS0Ea9D4+PgQFBfHFF1/IdHApMW1TUxMZGRmIosj06dOZOHEira2tuLq6sn37doYOHcqCBQtkGrEgCFgsFvLz83F1dcVoNLJv3z4EQSA2NhaDwUBDQwMNDQ0yoepC6NatGw6Hg71799KtWzciIyPJz89n8+bNREdHEx4eTkpKCtHR0YSFhREdHS3X3nA4HIwaNQq1Wi2zKKXEuRaLBZVKhcPhQKVS0dLSIgsAtVr9qxvKLwe/SaFwrQw4Go1Gth04OzvTp08ftFot7e3t3H777dx1112yRX/UqFHMnDmT9vZ2eZW42lqZFI9RX1/PpEmTCAkJASAiIoK8vDwWLFggCzDJhWm1WjvxLC6EiwUDXWhlvthxHa9fXFxMU1MTCxcu5PTp0zg5OeHm5kZAQAC5ubkMGTKExsZG3N3dKSgowGaz0dLSQlBQEDabjbS0NI4dO8aJEycYN24cwcHBWK1WnJycWLNmDaGhoXh6elJfXy/TpWtray/ozZE0BXd3d/Lz87npppsYMWIEtbW13HHHHVRXV2OxWAgLC6O9vR0nJydUKhVFRUXs2LGD4cOH09bWRkFBAVarFTibqdrFxYWMjAyioqL45JNPWL58OX/605+YPn06JpMJJycntm3bxmuvvXYFT/jXwW9SKFwri67VakWv15Ofn0/fvn1RqVQkJiZSWVlJnz59OHz4ML1798ZsNtPc3MySJUt4+OGHKS8vJy4ujltuueWqrhSCIKDVajl8+DAuLi4sWrQIOFu9W61Ws3PnTtzd3SktLcXFxYW0tDQiIyN5/PHHL+val/Pdj/W1w+Hg1VdfRRRFMjIyqK+v5+GHH+aDDz6ge/fu7N+/Xyak6fV66uvr6dOnDx9++CHLly9n8eLFjBs3joCAAHx8fCguLmb+/PmcOXOGhoYGIiPmZt+ZAAAgAElEQVQjufPOOy97IZCOcXJyIjo6mqlTp1JZWUlVVZXMfWhsbMRms1FdXY2/vz9msxmdTkdgYCDjx4+X3cJnzpwhLCwMOJuG/tNPP+Xpp58mPT0dg8FAt27d5N/2ww8/8Oijj8pbt+vR6yDhZ9kUBEE4AzQDdsAmimKcIAiewAYgDDgD3C2KYv2lrnO1bQomkwmdTndVO14URQ4cOMCaNWvo27cv/v7+lJSUoFKpqK+vp1evXnz66afMmDGD8vJyuSxbWFgYJpNJDtttbW2lvb0dT09PDAYDH3/8Md27d2fbtm3ceuutFBYWMmfOHPLy8vj444/5/e9/T0BAAA0NDbz00kv079+fBx54gNraWrn2wbZt2ygvL2f8+PEEBgaSk5PDiBEjOHPmDBUVFcDZ/aiUZXr06NGkp6cD/w371ul0dO/eHaPRKJenS0xMpKCggGXLluHq6sqDDz7ITTfdxOjRowkNDWXt2rVkZWXx7LPPytuj9vZ2wsLC6NOnj9z/99xzDz179uS2225j48aNxMTEkJaWxs0330xFRQV79+4lKipK1mT0er2cPLesrAy73U5aWhozZsxAqVTS0tJC7969UalU1NbWyudIarxSqaSwsFAu6NNx2yZN6Llz56LVaomNjZUrXUkRpyqVCj8/P/bv309oaCj19fUYjUYOHDhAZGQkBoOBvXv30r9/f7kQsMlkwsvLi8rKSkJDQ2lpaZFzOEhjsb29ncmTJ//kKMkbyaZwsyiKNR3ePwt8J4ri64IgPPuf93+8Cve5bEgW9qsB6eF9//335OTk8M9//pNTp04RFRWF3W7nD3/4A42NjcyZM4esrCwGDBhAamoqBQUFFBYW0r9/f7Zu3cqqVav44osvCA4OprCwkOnTp3Pq1CmcnZ05ffo0f/rTn/j6669Zs2YNSUlJMs12woQJpKenM2XKFDIyMvi///s/CgsLueWWW+Q2uru7k5uby5w5c9BoNGzcuJGePXty6NAhoqKi+PTTT9FoNBQXF9OnTx90Oh09evSQi6vU1tai0Wjo168fKpWKwYMH8/HHHzN06FBmzZpFnz59yMrKkoOJ7rrrLtrb2xk3bhze3t6MGjXqoslK7HY7AwcORKfTceLECQIDAxk2bBi9evVCrVbz0Ucfcf/99/Pxxx/z6KOPMnz4cBQKBWazWd52JSYmsmTJkqvyPKWJ6OHhga+vL3PmzEGr1bJ161aysrIoKiqiuLiYJUuW4O/vz9ixY2WhIvX5oUOHmDVrFn379v3JC89vXVOI6ygUBEHIBkaLolguCII/sFcUxchLXedG8T4A5ObmkpyczJw5c2hsbJRzKAQGBsrehtbWVtkQqFKp5P2vVDFKslpLNGLJeCYZoqRcER0p25KRq6ioiLFjx8rtsVqtbNq0CU9PT4YPH47BYMBkMslVl6TAHsnYabfb5Qnc2tpKVVUVoaGhF3WzXSidGVz+oHY4HPzxj3/EaDQyZswYiouL8fDwIC0tjf79+9Pa2iprGJKA8vPzw+FwUFVVhVqtxsvLC3d3dzIzM/H19ZUNfK2treeV7Ot4X4PBwMiRIztpClKf9O7dm4iICO6//365rmZNTQ1+fn6YTCYiIiLYtWsXEydOpKqqSl5orFYrQUFBlJWVAWejLfPz8wkPD+fdd99lwoQJfP755zz++OM4HA5cXV3ZuXMn/fr1Izg4mLCwMHx9fX/TmoII7BQEQQRWiKK4EvAVRbEc4D+CwedCJwqCMA+YB8gGsusVUvz8zp07ef/99+XCt87Ozjz66KPY7XbmzZtHRkYGAwYMYN++fXh5eWE0GrFarSxbtoxNmzaxZs0aFi1aJNd3kDgHgiDIhkhJAEiuNbvdzueff87kyZOZO3dup+zUNpuNdevWyentJffnpk2b6N+/P42NjZSVlXHixAlsNhuTJk1i//79JCQkUF5ejl6v59///jf/+Mc/OlXeltrQMdJR6oOOwuNyBIQoinh7e5OUlMSYMWPkYrkSj+CNN97gww8/5JlnnuGJJ56gpKSE7t278+STT7Jq1SpZQKSlpREdHU18fDx79uxhzJgxP2liSW2fOXOmTNsuLy/H39+f0tJS7HY7np6ejB49Gq1WS3x8PG+++aZcRLehoYHs7GzZgyMIZ4sXjRo1ioqKCu655x6qq6sZPHgwer2esrIyXn755fM8T9ezpvBzfWTDRFEcAEwCHhUEYeTlniiK4kpRFONEUYy7HoNCOsJisfDKK69gNpvlfa3dbmfHjh307duXCRMmUF1dTVlZGSUlJYiiiJ+fH+np6Xh5eckx9x4eHp1Kt58buNUxqlB6FQSBoKAgrFYrf//73zsdr1AoGDZsGC0tLRQVFfHVV19RW1tLQUEBe/bsobGxkdbWVrKysrBYLBQXF6PT6eRUdVFRUTINuGMSk4737khSUigUnbSJy2FiCoJAWVkZs2fPZu3ateTk5JCdnc2pU6fQarU4OTmRmJjIsWPH2LNnDz/88AN5eXmYzWa+++47SkpKWLBgAceOHaNnz548//zziKJISkoKhw4dIiMjg7y8PPkaJSUllJSUUFxcLE/yjpC4Ips3b+a2224jPz+flJQUfHx8OHnypJxjITs7m71791JYWEhhYSGVlZXk5eWRn59PQ0MDGRkZlJaW8sknn1BTU8P27dtJS0ujqamJ2tpaMjMzeeSRR/j+++8pKSnh5MmTbN269bwkMtcjfpamIIpi2X9eqwRB+AIYDFQKguDfYftQdRXa+atCo9GwePFiADZs2CDz4xMSEjh48CAA3bt3p1evXhQUFBAaGoqLiwtvvPEGb775JiqVirKyMtkt+PjjjzN16lSeffZZUlJSLllLQqlUEh8fjyAI9OvXj9jY2E7fl5SUoNFoiI+PZ+DAgQCEhoaiVqs5ePAgTzzxBE5OTsTExPDuu++i1WoJDw+XV+9Dhw5dw547KxQeeeQR3nzzTe68807q6+sxGAzExMRgNpsRRZGSkhLGjBnDsGHDqK6u5pZbbuHAgQNEREQQFBTEq6++ypYtW6irq+OVV165oCDq1q3bZbVHomaPHz+ePXv24OzsTExMjMzfWLlyJfX19fj5+eHu7o6bmxvh4eH4+vri7e0tbxl79OiBUqlkzpw5PPbYY0yaNImGhgaZO9G9e3def/11DAYDaWlpDBky5GfZIH5J/GShIAiCHlCIotj8n//HA/8P2ArcD7z+n9cvr0ZDf21IKr1er0elUmE2m1m7dq1MJx4+fDjvvfceDocDrVZLSkoKsbGxBAQEkJCQQG5uLpmZmZhMJiZPnkxjYyMjR55VrH5soFyM9CQJiszMTHJycmhqamLQoEE4Ozuj1WpxdnaWU6p9++23jB49GovFIlehNhqN8tbtWg1WURQ5ePAgZrOZjRs3YjKZSE5Oxmw2y3kQKysr8fT05LvvvqOwsJD169dTV1dHYWEhTk5OrF69mjvvvJOWlhaSkpJkIpAoilgslk5t12q1WK1WPDw8qKurIy4urlNxW+k55uXlMX36dI4ePYooikRERLBy5UpuvvlmFAoFbW1tuLq60t7ejouLC9XV1TLLsq2tjcLCQvR6PUePHsVoNLJlyxZSUlKYMmUKe/fuxWq1Ehsby7p163jjjTfIzc1FFEWCgoKuy8jIjvjJhkZBECKAL/7zVgWsF0XxVUEQvICNQAhQBEwXRbHuUte6kQyNNpuNvLw8IiMjqaur4/jx43h7e6NSqYiIiEClUtHe3o4oilRVVbFt2zbuuOMOmYjTcb+uUCh+FstRFEXy8/OpqKigrq6OUaNGodfr+e6773B1dSU+Ph6AJUuWMHnyZDZu3Mj8+fMJDg6WJ5OU3PVawW6388wzz3D8+HHefvttOVFqU1MTDQ0NrFixgvfff5+TJ0/i5+dHaWkpTk5O+Pv7y33p5uZGS0sLNptN7i8pwYpUFEiCFG2q1+tpaWlh0KBBFxQK8fHxmEwmXnvtNYKCgmhra+Ojjz7i+eefp66uDi8vL4qKivDw8MBsNuPl5UVtbS2FhYWkp6czatQoOYGslBqusbGRb775Bk9PT0JDQ3F3d6eiokL22giCQHx8PH5+fte1ofEnj0hRFPNFUez3n78oURRf/c/ntaIo3iKKYo//vF5SINxo+Oyzz/D09KSlpYUvvviCw4cPk5+fz6FDhxg/fjxVVVVs2rSJxsZG3n77bVQqFceOHZNDkIuLi/nTn/5EXl4eCQkJwH/3uVcKURQ5c+YMa9eupbW1lezsbNnwVVdXx1tvvcWxY8fw8vJi9erVAHz++efA2cg/KUvztYQ0Edzc3Hj//fdZsGAB+fn5fPbZZwwaNIjg4GBKSkr4/vvv5cI+ffv2xcfHB39/f2JiYmhpaSEiIoLu3bvL+SzCw8MJDw+nZ8+edOvWjR49etC9e3eCgoIICgrC3d2d4ODg87Zl0kT09fVl3759cpIbNzc3iouLWb16NSdOnGDNmjUsW7YMJycnDh48yN69e/m///s/goKC2Lt3L0ajkba2No4dO0Z4eDhlZWX8+9//5sUXX+Txxx/n5ptvZuzYsUyaNInY2Fj69evH0KFDZWPw9byN6AqIukJUVFTg5+eHzWajsrISNzc3eWJJlnmJ7FJfX49Go5FdjVarVU4ZLlnyf05KMThLsZWyNUskJMmQ6OzsjFqtloviarVaNBoNa9asYd68eT85hPdKYLfbWbVqFa+//jrvvfce1dXVeHt7c/z4caKiokhMTKS5uZnIyEji4+PZvXs3kZGRuLi4UFpayrZt25gxYwZ+fn7o9Xo8PDzOK8duMpnQarVyBuqmpiY5I1NCQgJarVaehB1za5pMJvbs2cPq1avlWJVHHnmE7OxsOWP4qFGjKCkpISQkRCZ6SS5lKQcjnE1cK7V9zZo1PPnkk2zZsoX77rtPbt/27dt5+umnCQwM/G1qCv+rkDIcq1QqAgIC0Ov1clJRyQAppSJzd3eX068pFApZeEjbhqsxIXU6Ha6urri5ueHi4oJKpZINZBL339/fH6PRiMFgwMnJiXnz5sntuNYQBAF3d3diYmLYvHkzb7/9NocPH2bjxo307dsXhUJBYGAgCoWCf/7zn9x2222cOnWKHTt2EBoayl//+lciIiIwGAwoFAqampowmUyd/nQ6HSqVCicnJ4xGI76+vgwePJjAwMDzCr1ImkNVVRV6vZ5FixaxYcMGXFxcKCkpQavVcvDgQYKDg8nPz8fZ2ZmAgACys7P58ssviY+PZ9SoUbLt4aabbmLq1KlUVFQQGBhITEwMcXFxODs7YzKZ8Pb25vDhw+j1epYvXy5H2V7P+E3GPlxLXA7vX/r8UiuBVMjlasTWn3ufH3v/S0Oq4v3CCy8QHh6Os7Mzd999N0eOHJHDk1taWujbty87d+7E19cXo9FIdXU1a9eu5Xe/+x0tLS3nqd6STcTJyanTyltRUUFpaSnl5eWyR0aCxA3Zt28fU6dORRRFvLy8KCwsZOLEiZhMJu68806Sk5OZNWsWp0+fxs3NDWdnZ3x8fDh48CAeHh5yYZyjR49SVVWFj48P3333HZ6enpw8eZJevXoxceJEMjMzGTBgADabjWeeeUbmmVyvWZegSyj8auho/PqtY/78+WRlZREfH09iYiLTp08nMzOTuro6uXqVm5sbYWFhjBkzBovFgpOTE19//TUPPvhgJ0r3z4WkHS1evBhXV1e8vLyIi4ujpKRErj6Vk5NDQkICqampzJo1i1OnTjFo0CA5T0N2djZjx46V8yo88cQTzJ8/H7PZzMyZMykvL2fatGly5m+lUslXX33F7Nmz5axQ13M90P8JoXA1pfL1LOGvVzzxxBMYjUaOHj2KSqUiKSmJhoYG/P39sdls2O12Pv30U0aNGkVBQQFqtZrq6moiIyMpKyvj7bffRqPRsH//fuLi4hAEQc59KdV+uBCUSiW33nprJ5uCpCls2rSJgIAABg4cSENDA8OGDWPPnj307NlTzh9pNpvZtWsXKSkpFBUVodFo8PDwoKamhuLiYoxGI01NTdx3330kJyfj7e3N3r17ycnJISsri2XLljFhwgRycnKYNWsWX331FSaTifj4+CtOw/dL4oYVCpKBVHo9d2B0jJirrKzEx8enk9rZkVJ8uWnhJcPcoUOHGDJkSKd4AmnVuFhbL9bOC12/Y8zCjZCU41IQRZH77rsPvV6PVqvl+PHjxMbGsnPnTnQ6HadPn+bhhx8mPz+fp556itWrVzN69Gg++eQTbrrpJjk7U2ZmJt27d+8U9/FTIPV/7969USqVcs2GkpIS2QajVCrp3r0733zzDc888wy9e/emZ8+e/OUvf+H555+Xn0tqaiqDBw8G/kvS+sc//sGBAweIjo4mMTGRcePGMW7cOJKSkvD395fdxF2awlVGR6v5uRP5QlmO/Pz85P87TtDLtb53nNBS0EzHe0sehI6CqiMfQWqP9L00qDrGOEhCqWNswY0uEOBsH4WFhbFo0SLuvPNONm7cKAdgvf322/Tt25cNGzaQnp7Otm3bZG2gsLCQL7/8ktmzZzN//nwmT57M2LFjKSkpob6+Hp1OJ9e9vFRUrLu7e6dnLD0bHx8fDAaDnHlZKqqblZWFQqGgoKCAAwcOUFdXR2pqKkVFRZw+fZra2lrgLMs1JyeH4OBgnJ2d2bdvH926dePo0aM4HA6qq6vJz8+nqKiIl19+mVGjRsmeCGdnZzngy2g0/mwP1NXG9dWaS0CaOJ988glNTU3U19eTkJDAV199hVKp5Pnnnwdg2bJlckXk77//nvXr1wPw6quvEhUVRW5uLiqVisrKSkpKShg1ahS7d+/m1VdfJTw8/IJC4quvvqJ3794kJyczbNgwNm/ezDPPPIPD4eCll15i2LBhMsd/5syZvPvuu8THx7Nx40buvfde1q9fT0xMDHa7nfnz5/OPf/yD++67j6VLl/LCCy/IhWCGDx9OUlISR44cYdCgQaxatYq5c+f+7GpIvyakVdjJyYmBAweSm5vL4MGD+de//sXy5cv58MMPGT16NDk5OXJGZYVCwcCBA7HZbGzYsIHPP/+807YtKCjoZ7frxIkTCILA6NGjmThxIhkZGQAEBASQnJzM8OHDsdvt1NfXY7FY8PDwYMyYMRQVFbFixQreeustjh8/zogRI1Cr1YwfP56ePXsSFhbGgAED5GK57u7u9OvXj/vuu4/Dhw8zePBgmpqa+Pbbb7n77rt/9u+4Frh+dZhLwMnJCYPBQG5uLuHh4XJuAzib0NTZ2RmFQsHQoUNlH76np6e8hSgpKcHb25t7772XtrY21Go1xcXFF72f0Wjkww8/5Pbbbyc3N5e2tjbq6ur44YcfCAoKorS0lOLiYtRqNW+99RY7duygoKAArVbLunXrUKlUNDc3c+TIEWpra2Wq7oEDB+Ry9DU1NUyYMIFVq1ZhNpvl3wnI9QRuVJSUlNCjRw8OHjxIcnIypaWlbN26laSkJNra2liyZAlbt24lLS2N6upqAJ555hleffVV+vTpQ0tLi5zPsampicbGxk6v0l97ezutra2YTCZaWlpoamo6r9+k94MHD2bgwIF88803ZGdn09jYSEFBATt37qS8vFyu36DVasnNzWXbtm1YLBZ0Op1MpZbsIRL5rKysjKKiInkhkvJSJCUlAWfdoM899xxbtmzhpptu+smktWuNG468JAXRtLe34+7uLmc1rqiowM3NDYfDgdlsRqvVYjKZcDgcsqQXBKGT+8put8ulxi+1lZA49idPnuSFF17gpZdeYuDAgajVat5++218fX2ZOXMma9asoUePHnK5uBUrVvDoo49y6NAhBg8efNGAmHO3E78lOBwOsrOzyc7Opnv37hw4cIARI0bw2muvsWDBAgCio6N59dVXueuuu9izZw9Dhw4lPj5ezn24bt06brnllk7bwJ8K6dnPnj2b22+/nQkTJpCRkUFgYCApKSkIgoDJZCI6OprevXt3qvsJZwlEarVaJjDZbDbq688mFjObzfj6+qJSqbBYLCiVSpknYbVaz9P2ushLVwkajQatViunyZZ4535+fuh0OvR6PZ6enjg7O2M0GuVMws7Ozjg7O6NSqVCr1ahUKjQaTacq0BeC9N3rr79OaWkps2fPpqioSK7j6OXlRXl5ORs3bmTp0qU4Oztz5MgR2Td94MABGhoa+Prrr+VVxW63d6qLKdkOOho+pXv/FiDVo/zXv/7F+++/z9GjRwkODubYsWMsW7aMhoYGOetxVlYWJ0+epKGhgSeffJLVq1czY8YMfHx8aG5uxmKxyNmgJRehxOrs2Hc/BovFglarJTk5uRP1+/Tp07S3t/Ptt9+eV+hGCsQC5MmuUqnQarV8+umn7Nq1CycnJwThbO5MtVotjyvpfyn+5Xr0Oki4MTeqXDgjkPT+UpmIL/T5pR6Q9N1tt91GbGwsDQ0NbNq0CUAuz6bRaPD29mbTpk34+vry0EMPATBt2jTi4uKw2+3ySiF5Oi7UpnPb8lvRGg4cOMBf/vIX/vznPxMZGUlVVRV+fn4cOXKEkJAQvv32W+rr6/nrX/8KQEFBAR9++CH5+fk4OTlRX1+P1WolMjKS1NRUvLy8CAgIkHMbBAcHU1lZiU6nIyAgQJ58SqWSadOmdcrXKbkkm5ub2b9/P0qlEp1Oxw8//MChQ4eYOHEibW1t1NTUsHHjRgA5KlbSPiWDsEqlwm63y4LAarXy0UcfkZmZSUxMDFlZWcTExKBQKGhpaaGwsJB7772XyMjI61orvGGFwqVYe1dTCguCwOHDh/H39+eLL76Q04UBnZKmShWbHnvsMZKSkpg7dy6JiYn4+vry4IMP8ve//50777yTRYsWycVNfqn6C78mRFEkJCSElStX0tzcDJyttLx79245hsTPzw83NzeCgoLIzMzk9ddf55133mHJkiWkp6czadIk5syZw+HDh3nrrbdobGzEw8ODO+6444p5I9I2bdGiRfTr14+tW7ciCAL33nsv6enphIWFsWvXLubOnUtpaSlGo1FO47906VI+//xzeUKvWrWKe++9F51OR11dHZs3b2batGn07NkTPz8/mQT19ddfM2vWrE7BZ9erQIAbWCj8kmhoaGDZsmVs3LiR1NRUTp48idlsljMxWSwWTCYTDz30kJzPwNfXl4iICI4fP07Pnj3Zu3cva9asweFwEB8ff8N6E64U0qr69NNPM2PGDKKiojhx4gRRUVHk5OTg6enJoUOHMBqNcu6HlStXkpaWhouLC21tbbzwwgsEBwfj5OTEU089RUBAACNHjmTPnj0XddsKgoDZbJYzXHfUFCQv1oYNG1CpVHh4eLBp0yY5a1JoaCjV1dVyqvzMzExCQ0Px8/Pjgw8+kAvPjhkzhm+//RZBEKiuriY3N5fVq1dTXFxMZGQktbW1bN26lczMTNzc3PD19cVkMjFy5MguTeFGx5gxY4iOjgagrq5OTr4aHR3NunXrqKioICEhgYaGBsLDwzl9+jS+vr6Ul5fz8MMPs2XLFubPn09ycjLjxo37xcq2XQ+QjMJDhgzhd7/7HcnJyfTr14+ioiImTZpEaWkpw4cPZ+vWrbK9pW/fvjzyyCNkZGTw3nvvsWrVKrnwikQUuxSTseM20mAwXFCLlPb4jzzyCDU1NTgcDubNm4darSY1NZXY2FhKS0vx8/Nj2LBhmM1mYmJi5JoQLi4uPPnkk6xcuZLt27fz0EMPsX79embOnCkX32lpaSE9PZ0JEybIMS4SrbvLpnCDQ6VSyYkyRowYwfbt29Hr9SQmJjJmzBi2bNmCt7c3ERERndTZuLg4DAYDDz/8sBw92dzc/D8lFCQ7iYeHB7m5uWRnZ+Pj40N9fT2nTp2SbQOpqanExMSwYcMGioqKeOmll1i4cCHTpk1j0aJFxMfHy/UhpUkniiLu7u40NDQgiqJcsyEwMFBOZhsSEtIpUlJ6PhMnTqS0tJQtW7ag0+mIjY3ltdde45577sFgMFBZWSmHa1dUVNDW1iYHTgUGBtLW1sbTTz/N559/Tl5eHhEREXh4eFBWVkZ+fr7szuzWrRtlZWWy1+tSpeyuF3QJhcuENKhKS0tlS/eIESNYuXIlXl5eHDx4kNjYWDmct62tTc5ELHHkR4wYcV2vENcKgYGBHDlyhL/+9a84OzsTGhqKQqFgypQpvPvuu9x9991yVqXPP/9cXokTExPZvn07S5cuxWazYbVaZd4JXLiMHXTer3eMe+j4XV5eHqIoEh8fT0REBHV1dbi6urJr1y6GDBnCyJEjaWxsRBRFmpub6datGxs3bpRp7nPmzCE8PJzIyEi5NF90dDSnTp2SczJGRkZ2cofDf7kn1/M4uD43NdcxpFRhDoeDiooKsrKyGDx4MF999RVr164lKSkJq9VKSkoK77zzDm+//TZff/01K1as6ESx/l+BpCV4enqyefNmTpw4QVJSEu+++y4Oh4Pu3bvT1NTE3Llzef/999HpdGg0Go4cOUJ1dTWLFy/GycmJwsJCjh8/jpeXF97e3nh7e2M0GjEajee99/T0lP/OrScp9b+7uzuPP/44tbW1bNq0icDAQGJjY4mKiqK4uJiTJ0+SmJhISEgImzdvBiA7Oxs3NzfMZjNbt27Fw8MDg8Eg58woLi6moKCABx98kIEDB2IwGOR2eHh44OHh0akK+fWKLk3hCuHr6yt7H/z8/HjzzTex2Ww8//zzBAcHdzp26NChsqENrs3qcC2vfTXgcDjIy8ujtbWVPn36UFpaKiehWbx4MQ888ABlZWUsW7YMlUrF+PHjefLJJwkODiYmJoajR4/S+P/ZO+/4qMrs/78nM5NJnfTeQwqBQCB0JIFQpIkgEBBQkLWjrl9FBVd3lZW1rLgWVAT8sciCBaX3jtTQElpCQhLSe08mycwkM/f3B95nkxCkWDbs8nm98prkzp17b+6d5zznOXnz7hoAACAASURBVOdzPqemhq5du+Ll5UViYqJQX3Jzc6O8vBwHBwdqamqoq6trVWtia2uLl5dXq4EoLx8SExPR6XS4u7sLgdaCggImTpxIeno6FhYWTJw4kYsXL/Lwww9z5coVZs2ahZWVFV26dMHS0pKzZ88CV72Puro6LC0tOXnyJL6+vjg4OKDX6695Lk5OTgQGBnboats70ijIM27LYqK2g6PlPi3RNurbtihJ/mzbY8mvckuzlrJqCoVCiKHKuWs59dU2yCVfa8vtJpPppqo0294DeQDo9Xry8vIIDQ1t9V7Lgqy2RJy29+G3qsi0sLDAy8uL6dOnc/78efbs2UN8fDx+fn5ER0dz8uRJZsyYwfvvv09wcDDh4eGizdy3336LWq1m1qxZopCoLZydnYF/K2LdzPVIkoSVlRVOTk7MmjWLDRs2EBISIhrB7N27lz/96U8EBgbe9DNJTU1l9erVvPnmmzflDXRUgwB3kFGQv+gNDQ0YDAa2bNmCTqcT67XKykqCg4PJzc1Fp9OJL71arebkyZM8+uijDBkyhD179mBhYUFxcTFHjx6lX79+ouDI3d2dhoYGDh06xGuvvSY8grKyMgwGA+np6WRnZzN06FACAwMxm80sWLAAd3d3KioqRCPVy5cvC4nxyMhIMjMz8fDwIDs7m06dOmE2m7GxsRFG5osvvmDSpEksWbKEBQsWcODAAeLi4mhqampVPSnfB5VKxZYtW7j//vtZu3Ytzs7O1NTU4O/vj0aj4dy5c2RnZxMaGoqVlRW+vr6UlpYKCnhYWBjZ2dmiEUxdXR0bN24kICCAM2fO8OKLL7J9+3bGjBlDU1MTSqXyGqPS8rm03Qa0MrBqtZpVq1bxxRdf0LVrV+rr6xk4cCBwtV9DRkYGs2bNorGxkdDQULKyslCpVEyYMIHU1FT27duHl5cXOp0OOzs7rKyssLKyEvevsbGRmpoaVCoVOp0ODw8PysvLaW5uJiIiAkdHx2sCjUqlkvr6elasWEH37t3ZtWsXr732muhqXV9fz549e/D29iY/P5/U1FTq6+sZNWqUaITr5+dHQ0MDZWVlBAcHM2LECKytrXnuueeIj4/ns88+47333sPe3p7q6mo2bNjAgw8+iK+v711P4deAzERbt24d3t7eZGZmMnv2bPbt28eMGTM4fPiw0NPLzMzE0dGRHTt28Le//Q21Ws2QIUMA2LVrF4MGDQKuphdTUlJ48MEH+eqrr4iLi0Or1TJy5MhWM091dTU7duwgICCAwYMHs3btWl555RWMRiNVVVVUV1fTpUsXxo8fz+rVq1m8eDGzZ8/m6NGjNDQ08OabbzJ9+nTKysrIzMxk//79zJs3j4KCArHWNhqNojZfrrlvqy8I/x6EP/74I9bW1kyZMoW5c+dSUVHBxIkTxX7BwcGkpaWJxibffPMNLi4uhIWFUVtby3fffcf777/P999/j6OjIx9++CH79+/n+PHjwL9TZ79US9LCwoKwsDC6du1Kfn4+SqWSjIwMMjIyeOGFF9izZw9ubm6cPn0anU7HyJEjCQwMZPfu3RgMBmpraxkzZswtD6Lg4OB2t8vH6NevH/v27RNcg65du7Jo0SJsbW3Jy8sjIiKChoYGOnXqhL29PdOnT+fll1/m1VdfFfdj586dDBgwAD8/PywsLDh9+jT9+vXjpZdeora2llmzZuHq6sprr70m2v45Ojq2uo6OiDvGKMg3sby8nNTUVJycnHj55Ze55557WLBgATqdDh8fHzw9PdHr9aSnpxMVFcXatWvJysoiODgYvV4v2oLJeWe1Ws3jjz/O008/zdq1a5kwYQJ6vZ7y8nLc3NyQJImwsDB27NjBhAkT+OKLL/jxxx9xc3Pj3LlzpKen061bN44cOYKPjw9r1qzh0qVLnD17ltraWhYuXIjBYODkyZO4u7uzefNmVCoVp0+fpr6+np07dxIXF8fJkyc5ePAgFy9eFAy6cePGUVZWJnLeRUVFBAcHU11djVqtprS0lH/9618UFhYSFBTECy+8gKenJxEREXz//fc8++yzODk5sXXrVmpqaujUqRMODg4cO3aM2tpaTp06hY2NDV988QWzZ8/mhx9+4MiRIxw6dIhvv/1WMA5b6kDIabXGxkax7Kmrq8PJyQmz2YzZbEaj0dCvXz/gqjFPTEykqqqKrKws9uzZQ3h4OPX19VRXV3PkyBFcXV3JycmhtrZWyK6fO3eOr7/+mo8++oh9+/aJ3pNyE1+5dkTWuEhNTWXw4MGitgCu1lxERUXh7Ox8jadw6NAhwsPDyc/Pp7y8XNCpPTw80Gg0GI1GkpOTsbOzE+dqampi69atODs7C+q6LKGfkZFBVlYWy5cvJycnBzs7Oy5fvkxKSgoZGRkolUry8vLYunUrDz/88F3y0q8B+Qa+8MILv/qx58+fDyBqFlpC9lCys7P57rvvGD9+PKNGjcLOzo7Ro0dz6NAhnJ2dRbR8zpw5PPbYYyQnJ9Pc3IyPjw/FxcXMnDmTGTNm8OyzzxIfH09xcTHff/8977zzDmfPnuXhhx9mwYIFKBQKpk6diqOjI4sXL8ba2ho/Pz+6d+/O6NGjxZfa29ubsLAw8vPzGTJkCEeOHCE+Pl64xY6OjiJfrlarCQ8Pp6SkhMuXL/Puu+/Sr18/nJ2d+ctf/sKGDRv48MMPqaurQ6PRUFdXJ/oULF++nKlTp/J///d/xMbGEhwczO7du/Hy8mL27NksXLiQWbNmXRNkbfncevToQXBwsBAyjY2N5euvv0av1+Pi4sKLL76Is7MzZrOZ7du34+Pjw9y5c5k3bx5vvfUWf/7znzl16hQXL16ke/fuNDY2CrXkxsbGW6I7y3UR3bp148qVK7zwwgskJiYyduxYQUs3Go34+PiILlJffPEFvXr1EiXRZ86cwdnZGT8/PyEX/9JLLzFu3DgsLS1JT0/HaDTStWtXGhoamDp1KomJiQwePJhu3bqJ+9JRlxB3jFGQcb1ip1871ddSug2udsaeOnUqxcXFHDt2jCFDhpCamoqXlxcnT57kwQcfJDAwEBsbGxISEvD09BRiL0FBQZhMJmbPno2npydarRatVktERAQODg7CPX7zzTdJSEjAwcGBuro6hg8fTkVFBWq1mh07djBnzhwxw/zjH/9g+PDhTJgwgTVr1jBw4ECSkpIACA0NZfDgwaSmpop4yc6dO/Hz88Pa2hp7e3sx48+ePRsrKyteeeUVdu/ezfTp00lLSxOFXNOmTSM/P58RI0Zga2tLZmYmDz74IE5OTphMJjp37kxmZiZ+fn6CbQitYwoVFRWiUrKwsJCamhrS0tI4evQoJSUlXLx4kerqaoqKimhubqagoID8/HwqKio4deoUr776qojsHzx4ECcnJ0aPHs2qVasYP348Bw8epLq6GrPZTFhYGFVVVZhMJoqLi7nnnnvw9fVt5SmoVCr+9a9/4efnx969e1m+fDlGo5G6ujqKi4sJDw8nJyeHe++9l71794pz19bW4u/vT11dHSqVioSEBLRaLWPHjmXTpk2Eh4djZ2dHSkoKkiRx4cIF3N3dWbx4MUuXLiUxMRG9Xk9sbCzNzc2UlZVRUFBAr169OpRxuOP0FP7TOHnyJDt37uSVV15Bo9EI5aeamhoGDx6Mj48PCxcuZNy4cURGRgq30c7ODgcHBywsLNi5cyeOjo7079+fI0eOiC/Hs88+C1xtYltXV0ePHj0wm8307dv3GndTlhiX8+NysxW4GgPZvXs3U6ZMEW6uHNyUpczkHonl5eWo1WrOnTtHXFwcALm5uZw5c4Zt27YRFxdHZGQkUVFRbNmyhW3btvH666+zZcsWpkyZgouLC/v37xct7dvCZDKxc+dOnnnmGZYuXUptbS12dnZCg1IuYZcDgzU1NSgUCkJCQmhubsbR0ZG6ujqcnZ3RaDSiTd9XX33FX/7yF4qLi3FzcxMNd9atW4fBYOCBBx4gJydHdKdqu3wYM2YMarWaJ554goqKCvz8/IQ+h6WlJSaTiYqKCiIiIsjLy0OlUpGVlYWPjw8pKSn07NlTdJCWKzPd3NyoqKjAxcUFvV7P3//+d+677z7Wrl3L4sWLWbx4MePGjSM0NBQLCwu+/vprBg4cSEBAwE0Zhd9LT+GO8xR+b8iputWrV+Pg4IAkScLSnzt3DkmSBAX60KFD9O7dG1tbW9EZaeTIkXz22WcMHTqU6Oho3N3dcXZ2xsXFRayr5XRYTU2NaCzj7OwsmrvAtYEpSZJ47733sLCwwNvbW7ioVlZW+Pj4YGNjw8mTJ7l8+TLh4eHs2rWL5ORkqqureeaZZ7C0tMTd3Z0LFy4QFxfHpUuXiImJoby8HIPBgIODA5MmTcJkMhEVFUV+fj62trZ4e3uTmJgIXO1OJQfjAgMDOXfuHFFRUa0MmIWFBWPHjmXdunWYTCbWrVtHTEwMBw4coFevXlRUVDB8+HAOHjwIQFFREU888QQuLi5IkkRxcTFBQUEiJrJ+/Xqqq6tRKBRs27aNIUOGkJGRQUJCAikpKaxZs4a0tDQaGhrw8PC4rgcZGBgoUtEXLlzAy8uLbdu20blzZ9EZSq/Xs3nzZnQ6HTNmzCApKYmRI0eSmJhIXl4eSUlJxMXFiUa+paWlooOUJF3tbH348GHKyspISkoiOjqao0ePsnv3bmJiYpg6dWqH1Fa4oaegUChWAPcBpZIkRf60zRn4DggEsoEpkiRVKa7+dx8DY4AG4BFJkhJvdBEd2VOQjcJ3333HxIkTRbfj9rQc2r7eLNpyKm72899//z3x8fE3JDDJx9+4cSPFxcXce++9dOrUqRVf4Wb4G7dybS33NxgMLFq0iHHjxpGXlyfStSaTicrKSnx9ffHw8KC0tJSTJ0/i5uaGXq/H09MTT09PvLy8uHDhgmjQIlOdZYEVOzs7DAYDNjY2WFtbU1VVJQKOXbt2xdXV9RpPoUePHgQGBvLcc88BYG9vT2VlJQ4ODmRmZuLi4kJzczN9+vRhyZIlPPHEE7z55pvMnTtXHKepqUmoMOl0OoxGI76+vqxdu5bw8HASEhKYMGECBoMBPz8/wScpLi5m6NCh+Pv739K97EiewkrgU2BVi23zgX2SJL2rUCjm//T3PGA0EPrTTz9gyU+vdyxkQk9Lkc3raTm0fb1ZtJ0tbvbzcgryRvvLxx8/fjxAK6JUyxm9Ja63/Vb/N0mSyMrKoqmpiYqKCl555RViYmK4cuUKmzdv5u9//zvx8fFMnjwZd3d3IiMjaW5uFsVSISEhrFy5kscee4zRo0cLPkLL65D5HLJhdXNzE+e2t7dv95p79OhBz549Afj88895+OGHyczMZNy4caxcuZKhQ4fyr3/9C09PTy5duoSjoyOdO3fGx8cHnU4HwIkTJwgNDaVTp05UVlaybNkyQkJC6N27N5cvX0aSJNLT04mMjOT9998nKiqKxx9/vN2JpSPhpmIKCoUiENjawlNIA4ZIklSkUCi8gIOSJIUrFIqlP/3+Tdv9fu74HdlTuItfBnlGff3114WSsVarpbCwkICAANLT0+nUqZPQp6irq8PKykrEO9zc3PD09OTYsWOYTCbCwsIICgpqxRq8ePEiXl5e1NTUoNVqaWxsxGAwoFKpiIyMvCbQqFAomDx5MjqdjilTppCYmMjzzz+PSqWiuLgYS0tLjEYjJpOJkpISQkJCUKlUVFZWotPp0Gq1FBcXo1QqsbW1pbS0lL59+7J+/XoeeughFi5cKDI1ACUlJUIfIiIighEjRtxWSrIjeQrtwUMe6D8ZBveftvsALWWR83/ado1RUCgUTwBPwNXI/l389yI7O5t7770XtVpNdHS0oInLgyY2NpZt27aJDkx1dXVMnToVuDqIjx8/TkhICKNHj8bGxuaaGTYiIuKmr0VOSUZHR3P48GE6depE9+7dCQ4OZunSpTz00EOsX7+eMWPGcODAAfr27cuGDRuYPXs2Xbt2BeDy5cuEhobi4uKCUqlk7NixxMbG8uKLL6JWq5k7dy4Gg0EIvzY1NdG/f38uX74siHMdlaMAv36gsT1/qF1XRJKkZcAyuOop/MrX8bugIxNQOgpkkZWVK1cSFxfHBx98wLBhw6itrcXS0pKsrCwaGxvR6/VipnZ2dubrr7/GbDaTnJzMwIED0ev1bNiwQcRB5L6PYWFhnD17tl2lZIPBwMCBAwkLC7smJXn48GEGDBjAmjVrcHR0JC8vD6VSyfHjx1m6dClubm6UlJSQnp6Ok5MTu3btwsrKiurqapycnGhqahKp3UWLFpGcnMz58+dxcnJixYoVREVFsWTJEsF/GDhwICdOnKCoqIj4+Pjb/u78Ht+32zUKJQqFwqvF8qH0p+35QEsWiy9Q+Esu8GYhS7//Gl2cbwZ3DcLNQaFQCAbko48+SteuXYmMjOTzzz8nIiKCnj174uTkxCeffEJgYCCPPPLITa+3ZdZkVFTULV2PyWTiscceE+pPjo6OuLu7U19fz8iRI0lOTqZnz54UFhYKodlx48Zx7NgxRo8eLRTEk5KS8PX1xdnZmYiICDZs2CBSoKdOnWLs2LF06dIFZ2dnbG1tcXd3p0+fPsDtD25ra+vf/Ht3u0ZhMzALePen100ttj+rUCi+5WqAseZG8YRfCy1FMX9ryHGYhIQEUadwF+1DkiQaGhpwcXEhMzOTnTt3otfruXDhApGRkTg6OoqCpczMTGpra4XAqzwrSz/13bC2tsZkMomKyYaGBtzd3ampqcFgMIj3JUkSLeWsra3RarXXCK34+vpy7Ngxpk2bxltvvcWwYcPYs2cPMTExFBQUUFZWxsGDB+nSpQvFxcXU1taSkZFB//79RdwhNzcXlUpFc3MzjY2NnDhxgvr6eqysrLh06RL5+fkUFhayfft23n//fbp06SLiJLcLma36W+KGRkGhUHwDDAFcFQpFPvAGV43BWoVC8SiQC8T/tPt2rqYjM7iakpz9a19wy8Boy9JkeXaRrWjLsuaWM88vyQvL3sHChQuZMGEC/fv3F7z465VFt7zO9rgGLUuc2yv1vtNhYWFBREQEnp6eQrKutLSU6OhoQkNDKS4uxtHRUVQ2Ll++nP79+zNgwAB8fHxu6hy3I3F24MABHnjgAS5fvkzPnj3p2rWr0EAYMWIEO3bsoGfPntja2hISEoKXlxeurq6UlJSQmJhIfX09qamp2NjYEBkZiYWFBe+++644/uTJkwVfwcPDg7y8PIKDg3F1db3la20JufvZb4kbGgVJkqZd561h7ewrAc/80ov6ObQcWO3V/8tG47e4cRYWFpSUlPDoo4/i7e0tOAzydbQ0QvIAbzvQ21t2XK8PxH8TqqqqqKmp4fPPP2fQoEHo9XpCQ0PZsmULarVadPhKTk5m3bp1dO3aVaRO5Xva3NyMRqPBZDJx7Ngxhg4dKoRM5PsscwfkZ2BpadmuFxkcHExqaiomk4nq6mqSkpLQaDRcunSJ+vp6UfDWo0cPDh06JFSV7Ozs2LlzJ2PGjOHKlSv06dOH+vr6VkVYKpVKdMZat24dU6ZMITo6mu+++477778fa2vr27qHFhYWREdHi9Z6vxWUb7755m96gpvBsmXL3nziiSd+dh95Nk1OTiYjI4OLFy/y5z//mYKCAk6fPs2iRYvw8PDA2dmZAwcOkJOTw3PPPUdxcTEBAQFkZGTw8ccf4+fn16pq7kaQB7pOp+Odd95h4MCBvPbaa8TExGBjY8Onn35KcXExdnZ2PP/883h7e/Pll19SWlrKqlWrCA0NZcGCBTg7O7NgwQKhGaBSqXjvvfcYNGgQa9euJT8/nx9++IGgoCC0Wu2vcVs7DBobG9m0aRNTp06lrq5OZAu2bdvGpEmTRGVrYmIirq6uhISEcPDgQSoqKkSz1tzcXHx9fdm+fTvh4eFCG1Gj0YiBb2lpiZWVFZaWlmJbe1L6shqUpaUlM2fOpLGxkZEjR3LgwAF69OghUptKpZLa2lr8/PyoqanB3d2duLg4Jk6cSJcuXZgyZQpdunQR5255fo1Gg4+PD927dycjIwMvLy969ux5jTzcrcBsNpOQkCAUr28VCxYsKHrzzTeX3Wi/O4bmLHsABQUFlJeXU1NTg5eXFxYWFmRnZwt22MqVK6msrESj0dCtWzdqa2t55JFHGDhwIGq1WvQ0vFnIs5CdnR3/93//h6WlJWFhYTQ2NpKZmcmoUaPYtGmT4Mv36tWLAwcOoFarBfElNDSUvLw8RowYwdmzZ+nZsydarRZJkjhx4gTNzc3k5uZSWVlJfn7+TbvNdwrknopnz55l48aN9OvXDxsbG4KCgti7dy9+fn4kJSVRWVlJZWUl1tbWlJeXk5+fz7333ou1tTWbNm1CpVIxZ84c0WxW9ghsbGzYvn07Li4uwpWHfwu8tDcQKyoqyMvLw83NjV27dhEeHo6vry9nzpwhIyODIUOGYDAYKC4uJi0tDVdXVzw9Pamurkar1bYq0W45wZjNZqysrDCbzYLtGBMTg0ajoba2FqPRyMmTJ4mKihI1EzcLhUKBl5fXb+4p3DEFUbLbnZiYSHp6OnA14yCr6FhYWKBUKsWDkINRNTU1FBcXo9VqMRqNjBw5ki5dutzW8kKSJNHdWm4iamlpiU6nE9LjarWapqYm7Ozs0Ov1QpbNZDKhVquvWVK07GcAVx/87bqXHRFms5kzZ86wZMkSXF1dCQ8Px8XFhdzcXBwcHAgODhYDJjMzk7S0NAYPHkxeXh4ajYaoqCgcHR2pqKggOTmZmJgY6urqMJlMohforl270Gq1oumvvORobGzE2dlZULpbXtNf//pXvvnmGyGE0qNHj1ZeR0NDA8nJyfTo0YPa2lpxLll1Gq4qRTc3N7fSnHB0dGTp0qU4Oztz9uxZpk6dio+PD0qlEq1Wy/r165kxY8ZtNcs1mUzs2LGDuro6pk273qr++vivK4iSH0R0dDTR0dHCrZcfUtu6gZZBPJnDL0nSL9IhVCgU5ObmUlJSQs+ePUX6Uw7+yP0c5DWsLOctz1RtG8pK0r8b5P43Bhnh6nPr06cP33zzDY888girVq2iurqalStXsmDBApKSkoiJiSE9PZ3a2lqcnZ3Zt28fJSUlWFlZYWdnR25uLiaTiQMHDlBbW4uLiwvDhg1jxYoVBAYG8vLLL9PQ0NBqqSAbX6VS2S4t3dPTk6eeegp3d3f++te/Mm/ePLRarRDQ6dWrF7m5uZSXl9OpUyf0ej1ZWVk88sgjODo60tTUxI8//oiPjw+hoaFYW1vz8ccfExAQIDQYZs6cSUlJCSkpKbi6utKnTx/++Mc/3nZ3MIVCgY2NDfX19b/omdwId4xRkAd5RkaG6MBUUlLCiBEjKCgo4IcffsDOzo7o6GhycnIIDg5mzZo1PP300yxatEhoAJpMJuLi4m55AEqSxN69e8nPz0ev19O7d28kSeLYsWMEBgayd+9e1Go18fHx1NbW4uDgIB6+LMQSFhaGpaUlq1ev5qGHHhJf1vz8fBwcHPjiiy945ZVXSE5OFuy5Ox2SJFFdXU337t05e/Ys3t7eODk5odVqOX36NHq9Hg8PDwoKCjhx4gT9+/cXzVwCAwMxGAw4OjpiaWnJ8OHDcXNzY8eOHWi1WkEsWr9+PZ06daK8vBylUonRaKSoqAiDwUDPnj3p1atXq+etUCiwt7fn8uXL2NvbCyWkqqoqXF1dsbe3JzMzE51Oh5ubG7m5uTQ2NtLc3MymTZvEpGNraytUui5fvkxYWBhqtZrMzEyGDBlCbW0t6enppKSkMGDAACFD11I2ryPijjEKMqysrGhsbCQ/P5+3334bo9HIO++8wz333CMq6lJTU4mMjMTDw4OPP/6YKVOmYG1tzcaNG3n++efFzCzjZtZ1BoMBtVrN7NmzefXVV1Gr1WJ9OGfOHCIiItBoNEyfPp0FCxbw6KOPcuDAAR5++GE2bdrEsGHDOHLkCFFRUXh6enL48GG6deuGo6Mjr7/+OoGBgfTt25eysjK6du1KSUnJTSsUd2QoFFf7PlRVVfHCCy+wYsUKwsPD6datG48//jgZGRkEBQXh7OwsJODd3d2ZN29eKw9KzvTs2LGD+++/nwceeIAJEybcdsZm+vTpzJgx44b7/RyRqmWqOTY2tt19Jk+eLI4j34+OjjsupnDgwAE2btwoxDg8PDxITEzE39+fgIAAbG1tRS+Ajz76iEmTJnHkyBGeeOIJUlNTmTt3rtA0NBqN2NvbC4LMjR7Yhg0bMJlM+Pr60qdPHyF1dubMGfLy8ujbty+enp58/fXXPPbYY9TW1gL/1h1QKpV4eXnR2NiISqUSWoxyzOHixYsEBwfT1NSEra0tDQ0NhISEdOiKuhtBrhR8/fXX8fLyQqvVYmlpyaFDh5g8eTLp6en06tWLkydPUlRUhI+PD87OziK7cODAAWJjY9m0aRM6nY7HH3+c2tpaEeizsbHBaDRSXl5OSUkJ3bp1o76+Xqg8R0dHX+Mp3Kkwm80cPHiQsrIyURtyK/ivjSnExMSQkJBAdHQ0e/fuJTAwkCFDhlBYWChyz+Hh4QDs2LGDoqIi3N3dmTNnDt9//z0Gg4GKigpSU1PJzc3lqaee+tnzygNy9erV+Pr64uTkRH19PVlZWYSEhHDy5Elyc3MZPHgw3377LZMnTxZah0lJSaJlmlqtxtHRkZycHMLDw5EkiYsXLxITE0NJSQmSJLFq1Soeeughhg8fTlVV1Q3jHy3jJ9BxZyErKysGDBhA//79KSgoEDqLkydPxsLCAicnJ+Ed+fr60tjYiCRdbdcWFBREnz59SEpKYtSoURQVFeHg4CDKqMvKyjAajZw+fZqJEycKYZWWfJXrGYS2pLKW8af2Stnb9hhpa6xbPouW792OVsZ/EneMUZAfSEJCAsHBwRw8eFDM1hs3bsTS0pKAgAACAwNJSEjAx8eHzz77jN69e3PmzBn0ej1pCMKtQwAAIABJREFUaWkUFBSIct26ujrRJ+B6kB/0jBkzaG5uJj8/n6NHjzJnzhyys7MJDg5m3759NDU1ERAQQHNzM2PHjqW8vJzo6Gjy8/MJCAgAICgoCEm62hTV1tYWBweHVsuEjz/+mKamJk6cOEFwcDBFRUVYWlq268nIqkReXl4UFxfT3NzcqkS4I8Ha2pp9+/aJXo2yBuOePXvQ6/XU1NRQUFBAUVER1tbWNDU1cenSJTp16iQGvslkYt++fVhaWlJTU0NiYiIDBw5ky5YtPPzww9jb27Ny5UpKS0uZOnUqp0+fRq1W4+7u3u4yw2g0kpWVhYODAw4ODlhaWpKZmYm/vz8FBQUiCCw3F5YkiYyMDMLCwrhy5QoqlYqmpiY8PDyora1Fr9fj7+9PXl6e4LU4OzvT2NiIQqHA19cXtVpNfn4+/v7+Hdo43DFGQba0AwcOxGQyER8fLzIP8+fPb8UklK3/3/72t3aPJe/XMhtxM0IlX331FS4uLkRHR5OVlUVQUBDnz5+ntraWsLAw3n//faZPn87nn3/O1KlTOXv2LMOGDeOdd96hT58+7N27l+joaC5evEhISAgajYaCggKSkpIoKSnBzs4OR0dHhg0bRlVVFW5ubjg5OZGQkEBqairx8fGYTCa0Wi2JiYlUVFTg5eXFP//5T7y9vZkxY0YrdmRbT+JGaDmztd3e1htpOxO2PV/L++rm5ka3bt1QKBS8/fbbZGVlUVJSQkxMDGazmcbGRsrLy0lISGDWrFmielKWpLO2tubYsWOsW7eOsWPHUlZWhk6nIz8/n3/84x+iNqK6upqXX35ZEMTkdHXbZ2symVi9ejVbtmzhww8/ZN68eXz11Ve8++67fPnllyxevJigoCBOnTrF9OnTcXFxwdLSkt27d1NZWUlWVhZpaWmkp6czefJkTp48yahRozhz5gx+fn7k5uaSk5ODjY0N4eHh7N69m6ioKMFv6ehG4Y5baMldnxQKhRDrlOsP5PdlyGlIuUhG/lt25252nbl7924WL17MlClTGDp0qOBClJSU4OTkhIWFBUlJSZjNZnQ6HR9++CEZGRli/Wdra4tOp+P7779n48aNVFdXs337dv7f//t/qFQqzp07R+/evfniiy+oqqoCrpJr5Jbn69evp7i4mPz8fDIzM0lJSeGHH35o1QfBz89PyNG35G3IrzfzI9+T9ra3t0/b31u+tsXw4cPp06cPO3bsoKysjL59+2JjY8PmzZupra3l8uXLWFhY4OLigrW1NTU1NRiNRjGLHz58GIPBQGxsLGlpaaLTFMD69eupqKhg9uzZqFQq7O3tcXFxwdnZud26CIVCQVBQECNHjiQ7OxtHR0cuXbrEoEGDqKqqIiQkhLi4OOLi4igqKhL/z8CBA8nMzCQ2NpaQkBA8PT1paGjA19eXbt26UVJSgr+/P/feey9Dhw5FoVAQERGBj48PdnZ2eHt7C45NR8YdE2jsKCgqKuLFF19k2bJlaDQaNm7cyKFDhxg2bBg6nY7u3buTlpbG+PHjSUlJwdHRkbS0NJRKJWvXrmX+/PmcPn2a0NBQwbd44403KCoqYvny5QC8/fbbIi7h7e3No48+itlsZurUqbi7uzNz5kyKiooYOnSoSIvZ29tTVFQkyFAymUpucXYzsLa2prm5WQQ+ZdjY2IiAqEqlQqlUotfrRfs2ubmq0WhEo9FgMBjw9fVtdeyZM2fyxhtviGvJzMzE19cXs9ksOkZXVlaKfpyyVoGVlRVfffUVs2fPFhLyVlZWIhvU2NgoMlJNTU2CGyJDqVReU05vMpl49dVXOXfuHPPmzRMeQ2ZmpqitePXVV5k/fz6enp689tprLF++nL179zJ8+HBxX2XSkkKhQKPRsGfPHlQqFbGxsWKSkiePPXv2MGjQIKHidDtewt1AYwdCy94JRUVFhIeHU1dXJ6THZSnxxYsXk5OTw8KFC9m3bx9btmxh2LBhbNu2DXt7e7RaLQaDAU9PT3JycggKChL9E8aOHcsPP/xAnz590Ov1BAQEiJp/uYy3c+fOmM1mkTfPzc2lW7du2NvbA1elxv8TuJkqxaioKI4fPy6WP3IDmvT0dNRqNVZWVnh5eQnC2fnz59FoNKSnp/Pkk0+K4iYZMkFMlmWTiWM3A0mS8Pf3p6GhATc3Nzp37ozRaGTt2rV4enpibW1NREQEixYtYsyYMYSHh2MwGIiOjgauGk+z2czZs2exs7MjLCwMgHPnzjFjxgzhxcpdrY4fP86jjz56x2RA7hqFm4Bs1RMSEpg/fz5//etfycnJwcnJCSsrKyZOnMjp06d58cUXhfSYn58fPXv2pE+fPmi1WjQajVhrBgQEYG9vLwgzPj4+ODk5MWjQIJRKJQMHDkSSJMrLy7GwsECj0TBixAj0ej1+fn5ERESQkpJCVFTUNWv7/8S9ae+8La+pubmZH3/8kfvvv1/0k1Sr1WzZsgUPDw8OHz5M7969hQKTHKh76623mD17NkajEbVajUajIS8vD3d3d4qLiwkMDMTJyUlQy7OysggICECtVmMwGLCwsMDBwYHOnTtfkyXIy8tDr9eze/duUlJScHNzIzIyEhsbG4qLi/H19aWhoYHq6mqSk5PZvn270HTw8fGhoqICW1tbLl68iNlspqysjF69evHDDz/Qv39/CgsL0Wq1mEwmbG1t2b9/P+np6fTu3VsIrXRU3DUKN4BMmtm+fTseHh6cOHGC7t27M2DAAEpKSujcuTN79+4lLi6Od999Fw8PD86fP8+iRYu4cuUKu3fvxmw2Y2dnx7Fjx0Twydramtdee03wECwsLESVpE6nIzk5maFDh2I0Glm4cCGXLl1i8+bNNDc3o1QqRcaivdTZ742fO688az722GPExsZy3333MWDAAIxGI0OHDqWsrIwnn3yS8+fPs2bNGr788ktMJhOrVq1i9erVounuV199xd69e1m6dCkLFizggQce4OLFi4wcOZLly5cTGBh4Sy51XFwcu3btws3NjfHjx2Ntbc3hw4eJjY3FZDIRGhrK8uXLmTZtGsuXL0elUpGdnS0ySQqFggULFmBnZ8fUqVOFcZYb6sjYunUrDg4OhISEMHz48Nu4u78/7hqFG0D+wvv4+NC7d2/c3d3ZsWMH8O9ipoCAAEpLS5k2bRrh4eGkpaXR1NREeHg4gYGBwu3s0aMHSUlJWFlZ4ejoyB/+8AdBwLp48aL4UiuVSvz8/DAajdjZ2TFs2DAee+wxAEGd/iU1HP8JbNy4kU6dOuHl5UVYWBiVlZWcOnVKzKSyuvOlS5eoq6ujc+fO1NTU8OOPP+Li4sLhw4eZNGkSy5cvJy0tjZycHK5cuUJ2djZpaWmMHj2aCxcuoFQqqaurw87OjrNnz+Lk5MSYMWNaXYskSWzdupWkpCRmzpzJ559/Tnx8vGjs4u7ujl6v55FHHsHPz49Lly4JfkJycjJms5n6+no8PDzo3r07ly5dahWDkSFXS8oB408//ZRx48aJLtUdFXeNwg0gPzxZBzA3NxcnJyfg6hq+qqqKU6dO4enpicFgEIKfAQEBgjvf1NSEUqlkz549IhJtbW1Nnz59hPstp6kAevXq1WpZcO+99/5Hlga/JubMmUNYWBiDBg0S3ZfuuecejEYjSqUSS0tL+vXrx8mTJ6mpqWHatGk0NDQgSRJarZYvv/yS8+fP07t3b55//nkaGhqYNGkSdXV1vPfee6IdXcvljIeHR7vFRwqFgmHDhpGSksKxY8d4+umn8fHxIT8/n5CQEAoKClCpVAwePBij0dgqg2Vtbc2yZcvIy8vjnXfeoaGhgebmZnHcludXqVSYTCZ0Oh1bt25lwoQJIlvVkXHXKNwA8uCsqqri9OnTjBgxgnfeeYdFixaxaNEivL29RbDvu+++IyYmBltbW7Kzs4V6kFz3L7dglxuUmM1mGhoaRLDs55YCHTWnfSNIkkR2djZ//OMfeeCBB6iurmbu3LlUV1dTU1MjZN43bdpESkoKU6dOZe/evbi7u2M2m8nIyODEiRNkZWXxwgsvUFBQIJr3ylH/+vp6zGazSEXa2Nhw+fJl4ck99NBD11xXUlISNTU1BAUF8eKLL4ps0ZNPPsk333xDZGQkdXV1VFZWCq5DZWUl9vb25Ofnk52dTWZmJlVVVRQWFlJRUYFGoyE0NBSj0UhFRQU2NjakpKRgb29PYGAghw8fJiIiQqRjOyruGoUbQB6MTk5ODB06FLhay7BixQq0Wi01NTUUFhbSqVMnXF1dRY/Ibt26oVQqKS8v58yZM6LXgUqlwmAwYGVlxbp16wgICGi3gex/C2ROQFxcHBqNhqlTpzJhwgQKCwtpaGggKCiIqqoqXnzxRSoqKkhPT2f48OEcPXqU/v37Ex8fzx/+8AfRtXrXrl2MGjUKCwsLkWpsSaySJdw8PT0xGo2ixVzbaxoyZAhHjx6luLiYCRMm8Oyzz7J69Wq6dOlCdHQ0Xbp0wWQy4eHhQVlZGXV1dYKA9ac//UmkjN3d3fn222+Jjo5mxIgRwthHRERQX1+Pp6cnarWajRs34uHhQY8ePa5Jm3Y03DUKNwE52Dh37lweeOAB4uPj0Wq15Ofn4+vrS3R0NI6OjvTs2ZMTJ07g7e1NRkYG69evZ+TIkdjb26PT6aisrCQiIkJ8mQcMGCAIOHeqJ3AzkBmHvXr14quvviI4OJiEhATGjx9PcXExfn5+HDlyhLS0NAICAti+fTtKpZKEhATefvttTp8+zebNm3nuueewtrbmww8/JC4uDhcXFwwGQ6tzyT0ZdDodSqXyuhTx3bt3I0kSZWVlpKSksGPHDmxtbdm9ezcqlYoff/wRs9mMk5MTV65cITY2lvz8fCRJIicnB6VSKVLVrq6ulJWVkZaWBoBer8fGxobGxkbgaofwUaNGUVpayvLly3n55Zd/v5t/G7hLXroFXLx4kcjIyBvuJ38JKyoqRMFPWypwy/3+myHrKcyfP59OnToxc+ZM8vLyyMvLw2Aw4OTkRFlZGb1796a8vJz6+npcXV2xtbUV3oGNjQ22trYcO3YMT09P/P39KS8vF+pWLeHk5ERzczN1dXWCBBUYGNjqPptMJhYuXEh9fb1oU3///fcLUpJKpRI1F1qtlqamJrRaLVqtllWrVjFz5kzS09MFQcvR0VG0mZMkiX/+85/MmjULQLBMjx49SkVFBZMmTRIanbeKu+SlDojIyMhWCk7yoJaZdi2XAJIk4eLiAtAqMt12ifDfbhgUiqvNYMxmsyiRliSJtLQ0hgwZgre3Nz179uTAgQMsWrSIl156ia1bt/Lpp58KVuCKFSswm814eHgwZMgQABGLuF0EBQVRWlpKUFAQDQ0NREZG8sknnzB27FiOHj2Kq6urqF/IzMwkPj6empoaOnfuzNmzZ7ly5Qrjx4/HbDaTnZ2Nj4+PENzt06cPR44c4Zlnrgqbf/LJJ/Ts2ZOYmJhfdM2/F+56Cnfxu+DZZ58lNjZW8DwCAgIoKSnB29sbtVqN2WympKSEzMxMBg0ahMlkIiAggNTUVEJCQlCr1WzevBmNRkNCQgJdu3YlKyuLP//5zxQVFeHq6sqGDRuIiYnB2tpaGGmZbAStC7cKCgpE0LKqqgqtVouNjQ0Gg0EYfFlXUzb6LetlmpubRRDSwcFBeAky89Le3p7S0lLhrdTU1IjPyhWTt4q7nsLPoL0mMC1f5Zxyy99ltFfzfqszdcvAVtva/bbv3Ql6B78Hhg4dSnR0NN26dePIkSPs27cPV1dXYmNjRUn1/v37Wbx4MWazmb1795KZmSkIP8eOHWPZsmWcOnUKo9HIAw88wMqVK3FxcWHNmjU4ODjQr18/unbt2u59lr24y5cvExwcjK+vr3D/ZULSrcLPz+9n329J//6lTWB+T9yRRkEeyHLjj8bGRjQajSimkUuqZWsvW/ympiYhomFpaXnbrnvb1GF7qcSWx/5fNgYy0tLSmDhxIh999BHnz58nLy+P/v3709DQwJ49ewgKCqK6uprCwsJWDVWys7NRq9Xs2LGD+fPnc+rUKVJSUvDx8eHEiRMkJyfTuXNnLC0t6d69OwUFBYLmLBdDOTo6olQqKSwsFOI18tJERnvPqOW2lvvfKEt0I++7o38f7kij8PzzzzNixAiUSiVJSUlMnz6dZcuWMWPGDL755huGDh3K5s2bgavCJX//+9958sknWbZsGS+//DIffvghgYGB+Pv7C+mvmzEQ8j7z589n3Lhx3HPPPezfv58PPviAmJgYOnXqRFlZGbm5uURFRREaGkrv3r15/fXXSU9P57vvvvuvjyFcD5GRkZSXlxMQEMDw4cPJysrCyckJnU7H0KFDSUxMJCYmBp1Ox4ULF6ivr8dkMuHl5cXRo0cZNWoUp06dEhoTY8eO5b777kOhUKDX6+nVqxczZ85k1apVfPHFFzz11FN88sknDB48mIMHD2Jra8uoUaPw9PRspYQkV3+25A3Iz+jbb78lPj6eJUuW8Oyzz7J//366detGQkICa9as4Y033uD06dP4+/vT2NjI8ePHCQoK4pFHHvkP3eVfB3eMUZDdvzNnzhAVFUVTUxMXLlzgnnvu4b333qN3795s3LiRMWPGcODAAZEG3LVrF3//+98JCAhg27ZtdOvWTSgtf//99zz99NPAzQX8FAoFRqORe+65B2dnZ3Jzc9Hr9UyfPp3GxkYuXryIk5MTnTt3JicnBx8fH86fP39dma7/JZw+fVp0Udq8eTOpqalYW1tz//33o9VqSUtL4+zZs7i5ufHBBx/w+OOPk5mZSUBAAIcOHUKj0RAcHIxOp6OoqIji4mJRPm00GlmyZAnh4eHs3LmTK1eucOnSJQ4fPkyvXr2EqG9LOTVZ6Wnr1q089dRTlJWVidLx5uZm1Go1ly9f5rPPPiMlJYX58+eTnp6Op6en4JYkJyeTkJBAdnY2Tk5OODo6UlVVRUFBASaTSXApzGaz6Iou163crsz774EbBhoVCsUK4D6gVJKkyJ+2vQk8Dsitav4kSdL2n957FXgUMAF/lCRp140u4k4LNP5cw9iWs9BddAy0NcRLliwR8u5arZaXXnqJ5uZmvvzyS/r160ddXR2FhYWEhITQ1NREdXU1RqOR/v374+HhIURkO3XqRFJSEg4ODqKZTFlZGf3798dsNpOeni40JGNjY1GpVHz77bc8+OCDgvtyK5ADjeXl5UyZMuWW78OvGWhcCXwKrGqz/UNJkha1OWkX4EGgK+AN7FUoFGGSJF1bLfIL0NaQtVc+fL1y3raBydsJNF5v0N/Osf5X0F7BUFu0fDbyTNryc0qlUmQCbkVirq1oanx8PElJSezZswcLCws2bNjAsGHD8PX1pampiaamJmpqaqisrEStVlNXV4eFhQUNDQ2YTCYhQnPw4EFqamoEx0Iuoe7SpQt2dnZYWlqSl5dHQ0MDCoUCW1tbnJ2dxXXdLn7rjOHNdJ0+pFAoAm/yeOOBbyVJMgBZCoUiA+gLHL/tK2wHP1cXcHdQdkz8nCGF1sZcqVTyt7/9jYEDBxIXF0dWVpZoxzZv3jwSExNF5WlbQpiMtgNHXjo0Nzfj7OxMVlYWgYGBuLq6MnLkSBFTiIqKwtLSkoEDBwplrUmTJqFUKsnMzESpVOLq6oqjoyNTp05tlaZsyV2Bq1wIg8FAWFjYNd7lL/Emf+vv+C9Z2DyrUChmAqeBuZIkVQE+QEKLffJ/2nYX/8MwmUyimrCpqalVVkYuNpJFUWSugE6nIysri6ysLI4dO4aPjw89e/ZkyZIlaDQaOnfujE6nE9JmMlmspqZGSMTJhsHNzY3Tp0+TlZXFvffey3vvvUePHj1QKpUcO3YMPz8/BgwYQG1tLSkpKezduxcnJycqKyvp37+/IB8NHDiQnJwcAgMD2bRpE3FxcSIrcb1MU3h4eCtv5Zfi95j0btcoLAHeAqSfXj8A/gC0d8Xt+joKheIJ4AkAf3//27yMu+jokOMsS5cuxdbWFnd3d1FKLreES0lJISIigoaGBnbs2MGIESNIT0/HysqKyMhI7rvvPuAqzbxLly7Y29uzceNGAKHF4Ovry/Hjx+nduzebNm1i9OjRYs0uFyDJYihvv/0227dvZ8WKFbz55pu4ubnR2NiIr68vRqORl19+GZ1Oh6WlJY2NjfTt2xcLCwssLS0FEWratGls27aNsWPHCuJSezGCX3sQt+TF/Fa4LaMgSVKJ/LtCoVgObP3pz3ygJaPDFyi8zjGWAcvgaqDxdq7jLjo+FAoFKpWKyMhIunbtytq1a3Fzc8NgMODv70/v3r0ZPnw4O3fupLa2loCAAC5evMjrr7/O2bNnmTRpEsuWLeOJJ55g/PjxGAwGUlNTGTFihOAzzJkzhzlz5mBnZ8fQoUOpqqpi2rRplJaWYmtrS0JCAsOGDRMeS1FREbt37yY2Npbu3bsDVwfbkSNHiI6OJikpie3bt2NlZYWnpyfl5eV4eHgwYMAAKisrAThw4IBQZ7KxscFkMvHQQw/95kFmGxuba4Rof23cFM35p5jC1hbZBy9Jkop++v0FoJ8kSQ8qFIquwNdcjSN4A/uA0BsFGu+07MNd3BokSeLrr7/GxsaG7du3ExgYiFarRalUYmdnR01NDY6OjhgMBurq6tBqtej1eqqrqwkMDBRko6amJvz9/amurkahuKrj6OLiIlrFe3t7U1dXR3V1tVB31uv1PPnkk63oySUlJbi6ulJVVYXBYBBZCJnYptfrMRgMQqHa0tJS0JJlkpzcmtDCwkKoSFtbW/+m99FsNnPmzBmKi4sZN27cLX/+V8s+KBSKb4AhgKtCocgH3gCGKBSKHlxdGmQDTwJIkpSsUCjWAilAM/DMr515uIs7DwqFQjRzfeCBB37Xc7cNQqpUKrEE8PT0vGZflUqFnZ3dz6pDazSaVvUUcq3F7wG5/8ZviZvJPkxrZ/P/+5n9/wa035rpLu7id8atDNZfSnn/PSA33Pkt0XFpVXdxF3fRCgqFAi8vr3bVpH5N3KXe3cVd3EH4PaQOOrRRkKWvCgsLr3sz5ErIjo7bfZgdQe/iLjoOfo/lSoc2CgqFAj8/Pzw9Pdu9GXIQSRZILS4uvqXjyzlfqUWD2l8bZrNZsNmqq6vbfb+93+W/r/cluB1jcaPPyKpSd/G/jQ5tFIAbdoe+cuUKW7Zs4bHHHmPXrhvWXgEIsok84FpWz8mQDYX8I2+7FZhMJurr65EkCb1eL8q5W3o2MhuvrZqzXFiVkpIirrElfumMIZ9T5vIDQgn5Lv630eGNQnuQB9WKFSsIDg4mOTmZjRs30q1bN1JSUq4748nbNm7cyF/+8he6dOki8uGXLl2iqqqKxsZGkcs+c+YM//znP3nrrbcAOH/+fKvjXc+7kJuD7Nixg/vvv58lS5bw1ltv4ezsTGJiouDIA8ydO1cc+8KFC+I633vvPTZv3kznzp0BWuXZ4apORNtruNH//ac//Yna2loA8vLyOHv2LC+99BKHDh3CbDbzwQcftNr/Lv43cUdmH5RKJUajkYaGBj799FPi4+OZPXs2999/P2azmS5dulx3cCgUCuzs7LC1teWvf/0rGo0Ga2trXFxceOGFF5g/fz579uxh69atNDQ08Nlnn+Hh4cGBAwcYPHhwq+PJBTYyf1+GSqVi8+bNrFu3jocffpjs7Gzuu+8+zGYzly5dIjo6msrKSpqbm3nyySdZv349Go2GyspKnJ2d+frrr8nMzGTMmDGtjisz+NasWcPzzz8vvInMzExWr15Nnz59GDJkiCjukX5qxFJcXIyzszNxcXFCXPS9997D0dGRQYMGCXWjuXPn/s/qPdzFv3HHeQpms5kLFy4QGhoqGG4rV65kxowZdO7cmUmTJrFmzZpW+oktlwKAkPaaMGGC8Do2b97Mhx9+iKOjI/n5+UybNo3NmzdjYWHBwoUL6du3L83NzSKwKf0kXQ7/DnbKHYmefPJJtFotzzzzDGq1WnDoV69eTXp6OjNnzuTMmTMMGjSIy5cvs3nzZrKzs5kyZQpr165l4sSJLFmyhC5duggXv7m5mR07drBq1Sq6dOnCfffdR//+/fnqq684ceIEb7zxBiNHjkSj0Yj/af/+/bz66qtCwkym+sLVXgTz5s1j//79bNiwQcjbtZSwu/vz+/x0OLQcOP+pn169ekk3i+bmZunpp5+Wli5dKlVXV0s1NTXSrFmzpG3btkkVFRWSJEnSqlWrJEmSJLPZfM3nq6urpbq6ulbv5+TkSEOGDBH7vPbaa5IkSZJer5feeust6ZlnnpF2794tNTY2/uy1mUwmSZIkKTs7W5IkSSouLpYkSZI++ugjadWqVVJdXZ1UXV0tNTQ0SEVFReJ4n3zyiXTy5EmpoaFBunjx4nWP+/jjj0uHDh2SLl26JG3atEmSJEn65ptv2v1fzWaz1NDQIG3dulXcN0mSJJ1OJ/3xj38U16jT6aTS0tKf/b/uomPAbDZLJSUl0smTJ2/r88Bp6SbG4x0j8S795NbqdDoWLVpEQEAAjY2N2NvbC6ppcXExTk5OeHh4kJqaKoJoGo0GKysrvLy8OHz4MPfeey81NTVUVFTg7+/P+fPn2bRpE8899xwajYbCwkI8PT0xma42By0vL8fLywsHBwcxmzY3N2NlZUVTUxNVVVWYzWYaGxvF+WTevZ2dnSjvlRvOym3kKyoqqK+vx8nJifLycrp27Yparaa+vr5V3EH2elJTU4mMjMTKygoLCwshWNvQ0NAqtiAL16pUKiwtLamvrxdCtSUlJSQnJzNs2DAUCgXHjx9n2LBhFBUVodFornv/FQqFEAu5i18PZrOZkSNH3lQrOUm62tEqJyeHPn363PK5brb24Y4xCoBQtpGlsxUKBc3NzTQ0NIg2YW33l4tp1Gq10PDX6/VYWlqiVCqpqqrC3d2d+vp6oSAsdwmqq6ujpKREqANLkoTtjl3UAAAgAElEQVSdnZ2o45dThvJ5lUolTU1NGAwGSktLMRgMuLq6YmNjQ3NzM1qtVpTY6vV6NBrNv61zGzWh+vp60XhWhrwfXM26WFtbU1pair+/P25ubuTm5mI0GgkKCqKiogKtVktjYyN6vZ7CwkK8vLyor6/H2tpaXHPLY14PSqWSyspK4uPj78Yc/oP4vYzCHRVotLCwELOsDI1Gg62tLW5ubu1+5kZfYvl4jo6OHDlyhKKiIiZPniz6EHZUrYeePXtes61bt26/6TlloyW1k0K92c+bzWZUKtVvkuGQxVLbnhNuTumo5STC/2/vvOOjqtL//76T3hOKJCAIItIUVIoFBMGC7m+b4qIIisiqiICLhVVEdvlKVUCFRRQEgygdBAEhUhJ6L6GFGkoI6T0zmUxm5vz+SM7ZO8OkoECCez+v133NnVvOee455z73nKdSsdrX6XSSn59PSEiIy8dIlnHixAlatGjhkSZPddYk3HSCRk+Dyel0cvHiRSWQk2q7n3/+WWUKkgMSYPXq0vAPcnkhGcfKlStV5mD5BdfbKlS26XX+cXFxrFmzhpKSEiVQ+jVlVXReCjdLSkpcjunrk/uyXUpKSlTew6vd9DEt5cCXbVeVDUo1MwkJCVW+p6qbZDbz589Xti0mk0l5FVZ2v3yOVatWMWPGDGWzUV5dXl5eLF68WC0N3Z9z1qxZAFUqJyUlpdyxXS2oiuDhem9XI2j0hM2bN4t9+/YJIYRYvny5+Omnn0SbNm3EuHHjRHFxscu1UojocDiE0+kUJSUlQggh5syZ43JciFLBjtPpFHa7XR2zWCxX1C/PDR48WMybN0+MHTv2ino9Xa+Hw+FQ29UgOTlZHD9+XAghhM1mE0IIkZiY6FKmEEKUlJSI8ePHixkzZlRYnhRI6umQx/T7I0aMUM9RGd3y3OjRo1U/CVF+O+jLdTqdori42IUGPeS1q1evFu+9955Ys2aN6Nmzp5g/f774/vvvxSuvvCLMZnO59UkcOnRIjBkzRvWvpNlTOyQkJIiJEydeUabdbhcxMTFK0C3PO51O9Sz6MbVz504xa9ascmny9Kw3QtB4080U9LDb7UydOpXJkycrq8ZBgwbxn//8h0WLFmGxWPD19WXlypXExcUxceJEHnroITZu3KgsGL29vVm1ahWXLl1SU2L9lyM2NhYvLy9yc3NZv349PXv2VCnGRRlnP3XqFD/++CPe3t4sW7aMESNGkJeX51HdJMtduXIlBw8eZOvWrZw6dQqLxYLJZOLkyZPs3r27UrPr/fv3s3DhQvr06UN0dDR79uxRgUDkUkqIUt+RRYsW4e3tTaNGjRg4cGC5XyT55crPz8dkMqnZhpxSy/2YmBjGjh3LsWPH2LBhQ4Xm2FD6tczJyaFPnz60a9euwum5yWRSX06TycTOnTuZMWPGFSnnJb2apjFlyhTWrVtHZGQke/fu5fLly+r5Z8+eTVxcnEe65Evw3XffMX36dLp06cLhw4dJSEhQUZ7dUxCePn2azZs3M2jQIJelqcPhUMFdX3zxRQDOnj2LzWZTMRrPnTunxpaXlxfbtm2jT58+NWeGUIabkik4HA6VIm7Tpk3UqlWLhx56iH379jFv3jz+9a9/cezYMbKyshgzZgzTp0+ncePGRERE0KpVK+rXrw/A6dOnmT9/PikpKYwYMUJ1fnJyMpqmkZCQwIIFC3jppZeYPHky48aNY8CAAfj6+rpYDwYEBPDJJ5/QtWtXnn32WYYNG0bHjh2ZNm0adrvdZdovhaPLli0jKSmJJUuWEBYWxqJFi0hKSmLOnDnk5+e73CN0yxi5X1hYyDfffENsbCwff/wxbdq04ZlnnmH8+PEEBwcrBvftt98ye/ZsFi5cyAsvvKCWVh6/ECYTI0eOZOTIkXzxxRfk5uZiMpn46KOP1HR87969bNmyhf/85z889thjxMTEMG/ePCZNKo32L2mUbeN0OsnKyuLjjz8mIyOD/v37s2HDBjIzM0lPT3ehRdqgjB49mpKSEnbu3Mn27dvp3LkzgYGBLubm8vnS0tJU0pc//elP2O12Fi5cSOvWrXn88cd5++23XczZJWQZmqbxyiuv0LBhQxYvXszIkSP5+uuv+eCDD1ixYgWbN29WwWa///57PvzwQ5o2bUpwcLCLibqXlxf79u3jqaeeIjMzk+joaGbPns3+/fuxWq0sW7aM4cOHk5iYSHJyMjt27GDQoEE3NEBLVXFTaR8AbDYbv/zyC8HBwaxcuZJ69eoRGhrK7t27GTp0KMuXL6dp06acO3eO+++/n6+++oq6devSpUsXwsLCCAsLIyEhgVatWrF06VJee+01hBBYLBYsFotSX/r7+7N//35at25NQEAAtWrV4tixY0RERKgYeaJMTXjgwAE6derE5cuX6dy5MwcPHuSpp54iPT1dvYRQGl9vz549nD59mmeffRabzcbp06dVZOI6depgMpkoLCxUwimpWpSMUKpgP/vsM4YOHarOe3l5YTabufPOO0lJScHb25s9e/bQvXt3zp49S2RkJCaTSWVVkipPaR0aERFB//79adeuHQMGDGDHjh34+vpy6NAhOnToQEFBASkpKcTExNCnTx8iIyNp3bo1eXl5nDt3jp07d/LGG2+4fNHlWj4hIYH27duTnJzMrbfeytmzZ2nUqBEOR2nMRCEENpuNwMBA1q5dS4sWLVixYgUNGzakdu3aPPLII+pLLFWrgYGBxMbG4nA4aNOmDXXq1OHIkSO0a9eOr7/+Gj8/P2655Rb++Mc/smrVKnr06OHSrv7+/mzZsoXdu3eTlZXFq6++SqtWrbBYLGRkZJCdnU14eDiRkZF89tlnREVF0bJlS+Li4rjrrrt48sknMZvNQOmM54MPPiA1NZX333+fDh06qD6yWCx06NCBwsJC1qxZwxNPPEHDhg3p3LmzSjITFhZWoTpYQhgqSc9wOp1s376d4uJimjRpgtVqxcvLi+PHj9O6dWsyMzPx9vbG39+fQ4cOUadOHfWVDQgIID8/n6CgIOx2Ow6Hg7CwMAoLCwEoLi4mODiYoqIi/P390TQNHx8fJaSTacX0X5ySkhKCgoLIyckhKiqKwsJCNK00ZLl7ajAhhDKrzsvLQ9M0/P391TNIGwi9jYJ86Z1OJzabjeDgYC5evEj9+vWVXYYQgrp165Kamkrr1q05dOgQhYWFhIaGUlhYiL+/Pw5HqRWmVMcGBwdjtVpp1KiRmtaazWbMZjNRUVH4+vpiMpnw8/NzmbnItOt2u52ioiLCw8PVMq2goICQkBBlz9CgQQPsdjt5eXlcvnyZ8PBwHA4H/v7+mM1m1bb16tXDYrGQl5dHcHAwWVlZhIWFkZubS5s2bQgICCA7O5vAwEAiIiLUs0jVqtVqxW63K1ojIiIICAigpKSEgoICHI7SBMP6sS6E4NKlS1gsFpo0aYLNZsPHx0eNE3m/zWZTY0GWI21O9Pke8vPzOXfuHB07dlTLr8TERIKCgmjcuDEOh4OUlBQiIyPx8fGhsLAQHx8frFYrzZo1IygoqFJNmcEUKoCn9bac/rp3fFXKkoOhsuulxNi9nt8COfUsrzz3geJuzyCPyWv1a2C73c6PP/7IrbfeSufOnV00LeXVJVVoshx92b9lmitprmzQw3+9Vj1d7+n53c/pr5Evsye7jIpkG+XVU17765dgsg5Zvr5PPPVlVVW7N4op3FR2ChIVNeLVDFzJEGJiYggKCuKhhx66wn1ZX6ZUexUVFV0Rude9w/UDory6pQBKf51+oP7al1DKLfz8/Ni7d68KllrZ4JPt4V7vtdCl61/MiuoHlMC0PFTULvKce59B6axOX3Zl9JRXT3lMxH1fX/7VlFXduCkFje7QC+Wqcq1eUDV16lRGjBjBbbfddsVLrWkaWVlZwH+/wufOnXMReMlfTdPIyMhQ95pMpnJj6cn7zWYzs2bNoqCgQJ3Tx49wOp1cuHBBaTsqg17A5+3tzbx585g4caKynKwMJpOJDRs2EB8f79KW1yJQaEUvoOwPWdfWrVvV8V8LfR/HxsZWSsOvrUMvJK0Js+5rgZuaKUgp/JEjR9i9e7eKMVARpk2bRl5eHvPmzWPZsmXcfvvtTJ06lYsXLwL/HYg7duxgzJgxfPvtt4pB/Otf/yI3N1fNEiQTsVgsvP/++xQVFbF27VrWr19P/fr1+fHHHz2qJU+ePEnv3r0ZOnQor776qgonPmXKFIYPH87IkSOZMWMGa9as4bbbbqs0+YcQgpKSEr777jvGji0NpL1gwQJefPFFNE1TarHyIIWhQ4cO5ZFHHqFt27aqfQHOnz/vUSWoh/6l0L/kTqcTu93OuXPnyr03KSmJmJgYXnvtNaZOnUrnzp2vmIJ7qg9QDFXPEIUQmM1mvvrqK7Zs2UK3bt3Iz8+nsLAQu92O1WqtlP7KUFxczIQJE1i1apUSIp45c+Z3wRhuyuWDXg0UExPD2rVr6d69O0eOHCEnJ4ewsLArXgKHw8Hq1auJiYlh165dTJw4kcTERPz9/ZkzZw6+vr7Ex8ejaRp//etf2bBhA506deLAgQOYTCY2btyo8hnq6bDZbHz11Vd06tSJV155hZYtW3LixAnuvfdebr/99ivoSE1NZfLkydSuXZuAgACVbAQgODiYnj17EhAQwKFDh4iJieFPf/pThet5OSX+8MMPadeuHe3atWPmzJk8+OCDTJs2DYvFwssvv6zUqLVr176iPG9vbzZv3szUqVMBWLNmDXfccQeBgYFkZ2dz9913V8hU5Bf5+PHj3HHHHVy6dIl69eqxbt06HnjgAaKioq7IsaDvl2nTphEcHMw999zD4MGDWbJkCZ07d+aXX37hscceIyUlBafTSceOHdV9JpOJ5ORkvvvuO1544QU2btzIQw89RFZWFpGRkSxfvpw///nPNG/enFWrVrF48WJ69erFmTNnaNGiBU888YTLzEEmglm+fDmNGjWqcM2elZWl1KpJSUmsW7eOY8eO/aoELTURN62g0WQycfDgQZURaMGCBfTo0QNN0+jbt+8V9ugmk4l+/frRo0cPevbsSXZ2NmPHjqVu3bpERkZy/vx5vLy8GDlypEpc8uijj/LHP/6R0NBQevfuzdq1a10EjZqmMWbMGNq3b8+hQ4cIDw9n4MCBfPnllwwaNMhFYKbHd999R9euXaldu7aLTUG3bt1YtmwZMTExHDx4kD59+tC2bdtKhXyrVq1i5cqVvPjii+zbt0+pxZ544gmVnm3p0qVs3LjRY1vu2bOH5cuX4+/vT05ODqGhobzzzjv87W9/w+Fw0KNHD7p27coDDzxQ7lJi3bp12Gw2PvnkEzp37kyrVq3w9vamVq1amM1m6tevz4MPPuixH3/55Rf1gqWlpeHt7U1JSQmNGzemdevWbNu2jeeff15FoRJCkJiYyNtvv02TJk1o2LChUttu2LCB4OBgWrRowYEDBxRji4iIIC8vj2bNmjF16tQrlhKHDh1ixYoVrFmzhrvvvpsuXbrw8ssve+zDFStWsHv3brKzs4mMjKRu3boMGDDgumeIMrQP5cDpdKrgJ35+fnh7eytXY71aSQ9NKw0g4ufnR+3atbl06ZLyWPT19cXhcKjUY/IaqWq8cOGCyhoUFhZGUVERXl5eyr26pKSE/Px8IiMjSUlJISkpSS0HbDaby4AKDg7GbDarJYWmaUqddfDgQZ588klKSko4fvw499xzDzt27KB9+/Zq6h4SEkKTJk1ITk5W3qLTpk3jueee4/HHH+fixYvUqVMHPz8/4uPjSUxMpH379tjtdurUqaPUsA6Hg5CQEJxOJ8XFxYwdO5Y77riDN998k9mzZ5OQkEDv3r25dOkSLVu2pEWLFhQUFJCenq6yJ5nNZrWsSUlJYf/+/bRo0YKlS5fy7rvvKiFqZGQkU6dOpXHjxmogS1VsbGwsqampPPzww9SrVw+bzUZBQQEWi4WYmBiee+45LBYLYWFhLtmlpYWln58fBQUF1KpVSy2RHA4HgYGBlJSUEBwcTE5ODna7HU0rzWnp4+ODxWIhOTmZ7OxsAgIC1KxI0iyTy1qtVo/MWNLg6+tLWloakZGRSkUp64uKisLpdGI2m1UkLLvdTnp6OmFhYYSEhFBUVISmadx1113qmopgMAUDleL8+fPUrVuXoKAgly+aXv0lNRHuQVndVY1Op5O4uDgsFgtJSUm88cYbVwgbpWxFr/rTlyEhbQCSk5OJjIzEarWqr7weMm28NNxx/yrrl4nu0GuGPNUvfz15TboLlN1VzJ7K9ISqqFmvJW4UU7ipBY3ukLp5PeTAloLE8lAVzUVF98qtpKSEGTNmMGrUqKsux11Y9vrrr7vQJs/JL92JEyfUC5WXl0dCQoK6Ts8EvL29r/DWk5D7p06d4sSJEwQHB/PGG29QUlKCyWRiyZIliiHoy/RUhh4Wi4XGjRuTnp7ukSEAhIaGuljy6bUu0iuzPI2B/jk82TLo1b36NtQzMkAFstW3jb4fKoIsqyItkyfthDS+ulpomkZISAiNGze+6nuvBr8LpiAdd+QU0f0Lt2nTJj788EOXe6Shjuwcm83mMS9DZZAvS25urgrIkpKSwv/93/9V2XhKQtM01qxZw+nTpxkyZAitWrVy0V5omobVamXSpEk0aNCAJ554Qq2/P/30U1q2bFmuHMOdWbpjx44dvPDCC8qk2MfHh6+++kppDSr6GupdxuW1zZs35+zZs6xbt44DBw6Qnp5ertGVHpKhSYMuve9IZdCrm92PS8amrzs3N1dprPSGU5Kh6I+5P6/+Whm63923orCwUFmuyk3OfDRNIy8vr9Jncoe3t/d1l1246Fo9bUBDIBZIAI4Bb5UdrwWsB06X/UaUHdeAqcAZ4DBwX2V1/BbXaafOdTU5OVm5RjvL3FUvXrwo3n//fZGZmeniuirv07sCCyGu2nVZCCEuXrwohgwZIs6dOyd69eolTp48KVasWFFl2p1lrrTHjx8XI0eOFEII0aVLFxd67Ha7sFgsyv3Y4XCIkpISYbPZxKRJk8SuXbs8uhfL++Pj46v0fJmZmeL48eNi+PDhYsqUKVV+Blmus8wdfe/evWLixInCZrOJkydPirS0tApdlyWsVqvYtm2bWLRokXIFrwoN+vr1x5xlsSplf0j6hCjtc9mWeqSkpIizZ8+61G+3213cuq1WqxBCiEuXLomcnJwr6hZCiCFDhojJkyeLoqIiERMTI7755hshhBBz584VycnJ4tixY1V6Pv1zZmZmiiNHjlzVfRJcQ9dpO/COEKIl8ADwpqZprYD3gY1CiGbAxrL/AE8Bzcq214AZv41teYbkyt26daNZs2Zs27aNhQsXMnDgQAYPHqy4/cyZMzl79qzKB5GWlkZqaipffvklr7/+OkuWLGH69OnK3biq60NR9hXp2rUrH3zwAV5eXkybNo26deuSnp5OUFAQ06ZN4+jRoy706pGUlKSS2MTFxam8C+PGjaNz58507dqVsWPHsnz5co4fP05xcTGDBg2iTZs2KkZjQkIC77zzDu3bt/cYjq64uJjvv/+eU6dOKa9HSbuE/PL9+c9/ZtOmTaxatYqnn36a5ORkFcG6vOd3Op306tWLHTt2AHDp0iUOHDhAamoqgwYNYuHChdx5552kpqYqByJP5cmZzIIFC+jUqRNPPvkkMTExPPDAA2RnZ/PMM8+QkZFxxb2iTC08d+5cHn74Yfr06cP06dPJyspi/fr1aJrGF198gcVioU+fPpSUlPDTTz/Rt29f5QAm3cQBZs6cSWpqKunp6bz//vukp6fz0UcfMWPGDLZv386uXbsYNWoUmzdvZubMmWRnZ5OcnHxFu7/66qukpaXRsWNHTpw4waZNmwCYP38+R48eZevWrbRs2fKKdqgImqYRFhZG06ZNr+q+q0VVUtGnACll+wWapiUADYC/AI+UXTYXiAP+WXb8uzLOtEvTtHBN06LKyrkmEGVTzNzcXB555BFOnDjBiRMnuOeee/jpp5+Ij4/n8OHDREdHc/HiRbp27cqcOXMIDAxk9erVFBYWcttttynnnvr163P27Fm1jvU0aCX0a04vLy8GDBiAzWbjmWee4fDhw6SlpTFo0CAKCwvp1KkTQ4YMcTHkkffGxMSwatUq8vPz2bRpE/fffz8ff/wx69ev55ZbbmHlypXk5eXx4YcfsnHjRj788EMeffRRLly4wJQpU5g1axbbt28nOjoam82Gl5eXy1JDiNJYER999BG7du3itttu49lnn1WSeD1k2r1//etfrFy5kjvvvJN33nmHGTNmqFiV7i6+mqaRmprKuHHjePnllxk+fDjz5s3j66+/Jjc3l4iICLZs2YLNZmPr1q3s3LmTI0eOeKxfmlcvW7aMl19+mQMHDtCsWTPi4+OZO3cuK1as4O2336Zu3boen3Hy5MnEx8fTvn177r33Xs6fP8+LL75I27ZtOXXqFKdPnyY2Npann36aixcvsmzZMn744QcV8Fb2txCC1q1bM2bMGP74xz/SpUsX4uLieOmll/jpp5/Iyclh3bp1NGzYkAYNGmC1Wjl48CAvvviiWop6e3uzZcsWHn74YTp16kTt2rVJT08nICCAxMREDhw4wMsvv0zdunXVcuJqTdorGp/XAldlvKRpWmPgXmA3UE++6EKIFE3Tbim7rAGQpLvtUtkxF6agadprlM4krjoOolyXvf766zRt2pRPPvmEFStW0LJlS6ZNm6bWsdnZ2cpCb926dZw9e5aHHnqIVatW0blzZ3x8fBSjyMvLY+vWrTzyyCOV1i8ZwpEjRwgLCyM8PJzg4GAeeeQRFixYwMGDB1m7di1t27bl3LlzBAQEKOMdUSbVnj59Om+//TaPPfYYEydOpKCggM8//5xRo0bx9ddfM3nyZNLS0hg7dixr1qzhhx9+YODAgfzzn/8kJyeHMWPGMHv2bBwOR7mRgBMTE/nrX/9KVFQUUVFROByOKzw3JU0//vgjTZs2JSIigt69e9OsWTPVLzJ2gDs+/fRT2rVrR3R0NGvXrqWoqIjmzZvTs2dPtm7dir+/P48//jgDBgzg888/Vy+NO7y8vDh8+DDZ2dkAbNy4kezsbLp3707z5s35+uuvldpPqntlO5rNZho2bIiXlxdRUVH4+PjQqlUrQkJCGDZsGMePH2fIkCFs3ryZyMhIYmNjmTVrFkIIFzWgEKV5PI4cOcKAAQNo1qwZd9xxhzo/bNgwTCYTISEhdOvWDYCYmBjFDPSztAcffJAuXbqo4DwRERH069ePRo0akZ2dTZ06ddSLfS1MyK81qqyS1DQtGNgMjBVCLNc0LVcIEa47nyOEiNA0bQ0wXgixrez4RmC4EGJ/eWVfrUpSDgj9vuT40s1ZWvBJRxyp55ZuvXKAyk26/5anm/ZUv6aVulYXFBTg7e2N3W7HZrNhs9kICgri1KlT+Pj4cPfddytX2fz8fBwOBxEREWiaRkFBgfrKS3fmwMBA0tLSlD7fZrOpTFRyliTdj8sbVEII/P39lZDNarWydu1a+vbty9ixYxkyZIgKHiL9LWQ8SWkHUFFuSVm+nEnoXwyX9anJRFBQEEVFRUoIqBcGSwbv6+uLzWZzUSPKPtX3pR5Op5PAwEBlDyJdkvUCPf34kIJoqaLVl5OamkrLli1d+jIgIEAJXZOSkli8eDEDBw5UTLi4uJi6desq/5jCwkJCQkKUDY2maeTn5xMQEKBc5i0WC15eXvj4+ChX+aCgoEqdwCSsVitms5natWtX6Xo9qqqSrFToUMY0fIAY4G3dsZNAVNl+FHCybP9roLen68rbfo2gUQqSpPCnMgFaeUIu/fGqCMKuBuUlaikPV1O/THxTVTidTmE2m0VsbKwYMWLErxKoXgvY7XYVv1I+r4yhWJNhtVpFfn5+dZPxm8C1EjRqpZ+K2UCCEGKK7tRPQL+y/X7ASt3xl7RSPADkiWsoT9DR5eL3P2/ePBYvXqx09Z6u10OvjnTXYVcEeY+878KFC/z973/n8uXLLudGjRpFZmZmlcqVX8AJEyaQlJRU6XWfffYZtWrVqpKaTtJ05MgRRo0axS233MLYsWPV19NdnVgZ3K8VQnDmzBleeeWVCusfNmwYw4YNY8OGDerLr2kaH3/8sUuoNYDc3FzlGVpQUMCQIUNcnl/SoW/vq4E+hqMsS9ZfnprQz89PWZZ6qld/7OLFi+Tm5l73tf/1QlUWNJ2AF4HumqYdKtv+AEwAHtc07TTweNl/gJ+BREpVkrOAQdee7FLIQW0ymQgODqZXr160aNGiUuMTObWUA0u+tBV5AsqBI01p5fT6888/55///Cf169dX5yZMmMDdd9/N4MGDgYqNVeSy4OTJk7Rs2ZKGDRt6HPCS5tmzZ6tQZpWtR4UQnDt3jvj4eNq0acP999/vYvsg7QGuJsiHPmCIEKW2HtOnT+eVV165gmGUlJRgt9uZPn063t7e9OzZkx49eijDqKVLl9K4LCqRnga73a60Gd9++y09evQAXJmru/WmnsbyaBdCsG/fPoYNG6aO6+uW1oLgyvxkjtDo6Ohy69AvZydNmoTVanWfbav63MuvcajKdOJ6b781xPvChQuFEMLF/sAd7nkg161bJ9LS0kReXp5YvXq1KCkpEWlpaR7vlUsUq9Uq8vLyVB2ZmZni1KlTQgjhEnb7s88+Ezk5OUq3LWkrDzt37hSPP/64qkv+ui+NvvnmGzFr1qwKw8dLyPo6dOggLl68KNatWyeEECpc/aVLl8TWrVtFdHS0OHbsmMqvWR4cDoewWCwiLi7uijDwu3btEnFxcSo8uqx79+7dYu3ateK9994Thw8fFhaLRU3BT548KYYNG+axHnn/okWLxP79+5VNgL7sb775Rvz888/qmLT1qAjFxcXirbfeEhs3bnS59ujRo2L79u0q/L2+3yS2bNkixo8f73HZVVBQIMxms3A4HPctveEAABu3SURBVGLOnDli27Zt6ln0zyNEaaj9ynKSXi9QxeXDTek6Lbm7jBL8xRdf0L9/f+677z6OHj1K27Zt6d69Oy1atFAc2dfXV6Vy7969O/v27aN379707dsXk8nExIkTGT58uItJsVyirF69GofDwf79+3E4HJw5c4a8vDxCQ0NJTk7GYrHQr18/cnNz2bdvH6dPn2bXrl1ERkaybNkyioqKGD9+/BXCLR8fHzp06MAdd9xBQEAAmzZtYvPmzWp6nZqaygcffMDSpUuZP38+kyZNokuXLlWy8DOZTAwbNow9e/YwduxYnn/+ed566y369u2L2Wxm/fr1vPTSS+zYsYM6deoob83yylq9ejVBQUFMnTqVTZs28corr2AymRg8eDD33HMPQ4YMUYJN+XwdO3bkp59+okWLFpw6dYpevXoxcuRIHn30UQoKCpgyZYqL0M/hcLB48WIKCwtZtmwZs2fPVjMnd2vBRx99lOHDh7Ns2TL69OnDhQsXuPPOOxFC0KlTJzWrE2Wzm3379rF9+3beffddMjIylA1LWloaH3zwAfPmzaN79+6sXbuWRx99lAULFtCvX+nq+JlnnmHUqFHK0Uu+PHJfpiBcv349/fv3Jzk5mTfeeIPU1FQ6depEZmYmEyZM4OTJk2RmZtKpUyemTJnC22+/rcZkTcJN6xAlp+9Hjx7lrrvuUt5nU6dO5b333nNZFuiRnp7OmTNn2L17N3feeSfdunVj2rRp/POf//RYh9S1P/HEE0DpenfChAm8+eabhISEMH/+fJo3b05UVBTff/8948aNw2q1Kg/Cr7/+mtdff92j+fG8efMoLCyksLCQ+vXr88wzz/DOO+/Qu3dvYmNj6dKlC/v37yc0NJSIiAj8/Pwqja8A/3VIGjp0KJ988glxcXFERUURHh6OppUGld24cSMpKSk88sgj9O7du1zpt9Pp5Pjx4yxdupTnn3+e8ePH8/jjj9O3b1/27NnDkSNH6Nq1K02bNr2CpqNHj3L+/HkefPBBatWqBZROs5OSkmjYsKFHLZJ0Oz979ixNmzYt91ntdjuzZ8/mtttuo3379qSnp7Np0yYGDx7s0tZOp5P9+/czf/58mjVrxtGjR/n73//Ot99+yz333EOnTp1YtmwZdevWZdOmTQwcOJALFy5gtVp5/fXX2bVrFx06dKg0atOSJUs4f/487733Hlu2bFFLqzp16nDixAl69eqlloVeXl7Ex8fTtm3bcs3Srwd+116Sc+fOJTAwkNTUVBo0aEBhYSFBQUEUFBQQHh6uoul6amyn00lERATBwcHs3r1bud2azWYeffRRpYLKyspSGZtDQ0MxmUxKfVhSUoK/vz+BgYEkJSVRq1YtvL29SU1NJTQ0VMVHXL9+PU8//TTnzp0jJCTEhQ5fX1+2bNmCw+Hgsccew8vLi+DgYHx8fKhbty5Op5Pg4GBiY2O59957OXz4MHfddRd79uxh8eLF/Pvf/1ZqTj8/PxwOh1J52e125syZQ0REBM2bNyc2NpahQ4eq7NnBwcHs2rWLVq1aKS/K8mYJomwd3qJFCyIjIzl+/DgOh0O9YE2aNCE8PFwl4IX/CoELCgqUuk26NksZilRNyvZ0Op0EBQWpAC1Op/MK1SGUxm8MDQ1Vqjlpv+Dt7c327dvp2rWrUj37+/uTl5dHnz596N69O1OmTOHLL79kyJAhjB49mubNm9OwYUPmzZvHiBEj2LVrF3/4wx+4cOGCisGQmJjIfffdp+RNMm6DpE3me4iNjWX06NFkZGQQGRlJXl4eFotFhd1PSkpSM4rt27czZ84cvvrqKywWC3fdddf192fgGqskr/f2W2UK1Qm5XkxJSVH/CwsLxcyZM6+5itPAlXA6nSIjI0OcPHlSCCHE6dOn1XEhhJL53Oi+yM/PF8XFxWLJkiU3tN6KwP9C2ji4UhLs/r+8c7IB3P8fOHDgivPujaZX5WmaRmZmJn379gVKZyIBAQH079/f5XpRNp3U71fUMVJKvWLFCgDlg6Cv231fv8lgKvrN/R73c5Im9/vi4+NVGjxP95RXljst7vsyr4JMfKtPxlveJttPli2EoHbt2jRr1gyn08kdd9zB9u3b1ZJj2rRpql88tbGckcj21feX/h5Zn9VqvSKzlfvYACgqKmLx4sV07dr1irplne5jsKbgpmUK+hcW/qvqKc+3Xf9CQamaSUZBki/D22+/raa27v76+v3MzEwyMzP505/+xLPPPkt6ejobNmwAUCo+fQwDqcaLj48nJycHTSvNKHTs2DGXKExyWirL+fHHH/nrX//qYp5sMpk4f/68KlPW577JbMuesi57eXlx9OhRlyxRAB999BGnT59W90g6Tp06RVhY2BXlyaXA9u3bXc7pVZ16WmR7fPrpp5hMJtatW8eMGTNISUnh5MmTvPvuuy71upepV0PKttCrSE0mE8OHDycnJ0e9nDLupKRZPx5k7seUlBRWrVrlEodB/6tpGnv27GHEiBHMmzePW265hYKCApc2lVtJSQmJiYkcPHiQdu3aqXEgdILJjIwM5HL5anwebhRuSqYgGzgtLY1ffvmFy5cv4+XlxY4dO/joo48AVz2wdMKJjo7Gy8uLjIwMdu/ezbhx49QgNJlMtGnThrZt27p8CdzrBVi0aBF9+vTh008/ZejQocTHx3PixAmOHj3qkSnJAbt48WJV3z333MNdd92Ft7c3QgiVA/GHH35QvvaHDx8G/huaXD7TypWldmIVGdPoj0ttTV5eHkIIRo8eTZs2bUrVT2XxGEwmE/fddx933nmn+op5eXmRnJys8ka4w9fXl7179/Lwww9X+sVzOBzs3LmTLVu2cPvttxMfH8+0adPYuHEjCQkJLF26lA8++IBFixYRHR3t0n+SSe/du9eF8S1YsIBffvlFCeuysrJ47bXXXGwv9HQ5nU727t3L999/r5zXSkpKiI6OZsuWLR7pll6VM2fOpKSkhFdffZXdu3fTpk0b9VyyjuTkZBYvXkz//v2pVasWLVu2VP4cJlNpxigonb0UFhbWyFkC3KRMQdM0UlJSqFevHvPnz+fTTz9l48aNPP300+qllBxYfmVXrFjBhQsXmD17NkePHsXPz4+DBw+yceNGtm7dyoEDB+jfvz9Dhw4lMjJSeUzqITm+3W5n9OjRNGjQgBUrVnDgwAHmzZvHzJkzr3BOkuWMHj2aCRMmEB4ezoULF3jhhRfYtm0bH330EefPn8fb25tDhw7xwgsvcPDgQb799lueeuopl5dDCrUiIiIwm80qu3F5QkI58/Dy8uLSpUsUFhYyadIkMjIy2L59O9nZ2Wzfvh0fHx/279+vhKFyBuF0Opk5c6ZiXBJCCLZu3cr333/PjBkz2LJlC8uXL1fn3CENr3r27Mn8+fPZu3evcpb64YcfMJvNjBo1ijlz5pCYmHiF0E3GTRwzZgxffvkla9asYfTo0URHR9O+fXtOnDiBzWZj/vz5KoirzFythxCCQ4cOqbSC0dHRpKam0qFDBx566CGPbWgymdi1a5dyYho1ahTfffcd33zzjTovx0l4eDg+Pj5MmjSJDh068M0335CTkwOU5vgYPnw4P/74I506deKxxx6rkc5QwM0paLTb7SI+Pl7s2bNHXLx40cV23ul0ioSEBGVII0Spcc22bdvEmTNnhBBCxMXFqWv3798v1q1bJ1JTU0VRUZESVEVHR7sYKknoy01PTxeFhYVCCCEOHTokhPAcxCQ3N1dcuHBBLFiwQHzyySdi/Pjxol+/fiI6Olp069ZNzJ07V6SkpAiHwyE+//xzsWfPnivqdTqd4uWXXxYhISFi1qxZ4ssvvyy3fZxOp8jPzxd/+9vfhBBCXLhwQXzxxRfiqaeeEsnJySI7O1uMHDlSGdGMGzdO7NixQ1y+fFnMmzdPTJgwQbz77rvi4MGD5Za/e/duceLECSGEEMOHDxdnz56tUJi3atUqYbVaxfz584UQQiQkJKggJseOHRNFRUXCZrOJlJQUER8f72L0deHCBRXwRR5ftmyZsFqtoqCgQHTu3Fn88MMP4sCBA8JqtYqSkpIrjLHkfd27dxeFhYVi/PjxqvyKYLPZhNVqrdAwSpaRmprqciwjI0PYbDaxadMmJQiVBnLVIYSmioLGm1IluW/fPurXr69UidJ92GazkZ+fz9atWwkPD+fee+/FarXi5+eHj48PAQEB5Obm4uvrq6ZvJpNJRf8tLi7G39+fHTt2kJKSQs+ePTGbzQQEBCiVm8y2JJckUVFRKsR87969lSpR0hYaGkpxcTFz587ljTfe4PDhw3To0IGNGzcSGhpKYGAgHTt2pKioCLvdTkpKCllZWS4BOJxOJyEhIbRv354vvviCv/zlL/Tt25dRo0bh6+vrMT7BhQsXKCkpoVmzZvj4+JCYmEhxcbEKWhIYGEhRURHe3t7ExMTw/PPPs2vXLho3bszu3bsJCAjgvvvuUya+7vKVM2fO0Lx5c2WT4eXlpTwAhbgyOKpMjBsYGEhoaKhKv6dpGkFBQVitViVfkV6KErKPZDxFQCWA9fb2JikpiZYtW6pwevoZnXsMCHnvqVOnlLm4/pweUkYgI35D6UfUx8fHY5KfS5cu0bx5cxXfQibMleMmMzOTyMhIFfxG+nyEhISoRMHXU8bwu7ZTyMjIUAIzaaMgjXLMZjPZ2dmsW7dO5S2QmYNltumcnByV0lzq6OVgF0KQlJREq1atKCwsxOl0UqtWLZW92M/PT+nALRaLyqScnZ2N2WxWYeZlNmQ5ICTTCggIUMxCrkf1GYx9fX3VC6OHpmn4+fmpwSYzZLv3n1YWxzEsLAwhBMXFxTgcDkaOHMl//vMfkpOT1Usmw8sXFRURFBSEr68vPj4+hIWFcezYMerXr6/SpctBGxAQgNPpxNfXl6ysLGrVqqUyW8ts2MXFxQQFBbnQJSXw0obD3cBIv9yzWq2qT8FzVGf9Pb6+vir0vntbuEMm4PHy8qK4uLjSl1Dvdi1p0buC6yFtTGw2GxkZGfj5+Sl3cE3TuOWWW7BarURFRZGSksKtt96KzWbDz8/vCmOu64HfNVOoiGa73c4vv/zC5MmT2bRpk8t6+/Lly/j5+REWFqYs+DyVJTvHbrcTFxfHtGnTGDBgAP/v//0/jwNPllET2rI8uEdm+l+Fvr+uRxnuFpr66/SzLXcGcCO0EFVlCjXL6LqK8DRdlnH2fHx8+PLLL7nvvvsA18g29evXv0K4U15nyCXJtm3bWLlyJevXry/XFLgmqpXcIYOnGKgZqMlj5qacKeghOa5kDOnp6Vy+fJni4mLuv/9+l+ukDEG/7wnSSeXcuXPUrVuX4OBgl5fqek/zDBi4HqjqTKGG6kSqjp9//pkPP/yQrKwsBg8ejNVq5dSpU4wbN47Zs2cTFxcHQHZ2Nj///DMAvXv3ZuXKleXaFGzfvp3+/fvz888/8+STT9KtWzfMZrMKwCEDudRon3gDBn4lbsrlgxTQeXt7c+uttzJw4ECee+45nnvuObZs2cLatWtp1KgROTk5dOjQgby8PMaNG6ekzn/+85+JjY2lY8eOREZGuqwDAbZu3UqvXr146qmnyM7OxsvLiyFDhiiHmnPnzvHWW28RFRXlIk/wtFa8XtDX5b5+vdlmMRWtzyuayV4L+UBNQE3rr5tq+SAH/6ZNm5QE29/fX5nS5ufn4+PjQ+3atYmLi+P8+fM0bNiQEydO8Prrr3PgwAF27txJYGAg3bp1Izw83OVr7+fnx9GjR3nggQcoKChg7dq1dOvWjfT0dJo3b05iYiINGjQgNDSUqVOn8uabbyp1lVR9Sk9NKO1sfcJbTxGYpBYFUIFUARVE1t/fX0nJJSP09vamdu3aKnlpcXExfn5+St0aEBDgslRyb0NZr/v/68VUpNBWGkFJVZ+Pjw9CCIqKipQ6UwaulUFhpVahuLhYaXZksuDw8HB1b1FREYGBgUplLKX6hYWFKoiqw+Fw8eZ0hxD/jY0g1bVSNSoD/0pI/4WIiAhycnLUUlSqr+U1etWv9AzVe4gKIYiIiFCu9tcTv0vtgxxQW7duVQNK/1Lr5QUXL16kcePGTJw4kdGjR6vBYbVaCQ8PVy7G7hJg6RZts9nUC+ft7Y3ValUDJjAwEKvVSkhICCUlJaSkpKg8FFarVVnkmUwm6tatq17qwsJCFXlYPou3tzeBgYEIURpiXA6UgIAAFdJcZtWWTMHPz48GDRqQm5tLWFiYYg5paWn4+/sTGhrqEs1YIj8/n7y8PKVmtdlsFBUV4efnR0hICOnp6WiaRpMmTcjIyFDu4WazmZCQENVmoaGhZGdnU6tWLY95HNyhaRo2m02pgaX6WDL2goIC5ZZuNpsJCwtTKlIZXdlisSjGW1xcrMLm5+fnk5+fT2FhIaGhoSrZrsViISgoiJycHEJDQ4HSSMh6ewh3Gh0OB7Vq1ULTNOU6L+003O1BpK1BVFQUqampymemadOmKjmMw+EgKiqKjIwMJQSXbubyGR1leUeCgoIMlaQe1zLrtBClgUSXLFnCiBEjiImJoUePHob03cD/PP5nmYKENJS5msCkBgz8nvG7tlOoCuRUu6YJcQwYqOn43TIFY3ZgwMCvw03JFGrCkudawZjJGKhpuCmZgvEiGTBw/XBTMQVpyrx8+XIVaflm1ShIewI/Pz8l+yguLnYJha7X7QtRGsYrKCiI9PR0nE4n9erVw9vbm6ysLHXt5cuXlboWSjNGFxYWeqRBmofLZLXSg/DXMl3pEar3EIVSZyzpHVqeA5pM5urn56eicXuC0+mkdu3a+Pr6EhERQWBgIAUFBSobtYTValWJeM+ePUuTJk1c6ktJScFsNhMeHq5UuFI1fC2haRo5OTnKy9T9nMPhICgoiGbNml3Ten8LfrfaBwMGDLjid619+D24AJf3NTaWRr8/VMUoqSb1e6VMQdO0hsB3QCTgBGYKIb7QNO3fwKtARtmlI4QQP5fd8wEwAHAAQ4UQMdeS6Jt1yWDgfxM16YWvCqoyU7AD7wghDmiaFgLs1zRtfdm5z4QQk/QXa5rWCngeaA3UBzZomnanEOLm/7wbMPA/gEqV+UKIFCHEgbL9AiABaFDBLX8BFgohioUQ5yhNSd/xWhBrwICB64+rsvDRNK0xcC+wu+zQYE3TDmuaNkfTtIiyYw2AJN1tl6iYiRj4HUIfHVh/zP28gZqHKgsaNU0LBpYB/xBC5GuaNgP4GBBlv5OBVwBPC6grel/TtNeA1wAaNWpUJRqkwCYlJcVF7VaToF8/yqxOdrtdedlJzziZL6A8oam73KQ6oz15ilvg7nrtfq1epSgZgFSBwn8tTm8Uc9DXI+nzFNZP386eonO5x1y8FvRLb9magipRommaD6UM4QchxHIAIUSa7vwsYHXZ30tAQ93ttwKX3csUQswEZkKpSrKKdAAQFRVVlctrLPQDrSabY7uHunM/B64p9fT3SJdqIYQLg5PX65mhpxfUEx3XGzW5L24kqqJ90IDZQIIQYorueJQQQqbheRo4Wrb/EzBf07QplAoamwF7riXRnrI33SzQx1KAiqMOVTckDZ5elspUqp6+fPp7rkaD5KmuXxMQxlNk5fLKLK98TzOFa4Ga0N8SVZkpdAJeBI5omnao7NgIoLemafdQujQ4D7wOIIQ4pmnaYuA4pZqLN6+15uFmV0ne6NDeNQHXI5qTHtfCFqAq/eJ+/PfYf5UyBSHENjzLCX6u4J6xwNjfQJcBAxWioKBAJdlxOp2kpaXd9MvKmoKaI90wYOAqIJPhQunX2j0prYFfD0OyYuCmh6ZpKliugd8OgykYMFBDIdW3Bw8eBG6cz4/BFAwYqOGoKDP29YDBFAwYqKGQquD27du7/L/eqDGCRiMFm4HriaraNbhbKLpn/aoJVrReXl7XddZQY5iCYU1mwEDNQI1gCmlpaXz++efVTcb/JIQQKgvU75Uxy8xfQgh8fHxcjsu0cNIgrqCgAKfT6ZKmT4a6M5lMKmNUdcFisdCvXz9atmx53eqoEUyhXr16/OMf/6huMgwYMEANYQoym5OB6sHvJXvz/wr+J2QKNc111ICB/2X8PheRBgwY+NUwmIIBAwZcYDAFAwYMuMBgCgYMGHCBwRQMGDDgAoMpGDBgwAUGUzBgwIALDKZgwIABFxhMwYABAy4wmIIBAwZcYDAFAwYMuMBgCgYMGHCBwRQMGDDgAoMpGDBgwAUGUzBgwIALDKZgwIABFxhMwYABAy4wmIIBAwZcYDAFAwYMuECrCQE7NU3LAMxAZnXTokMdDHoqQ02jyaCnYtwmhKhb2UU1gikAaJq2TwjRvrrpkDDoqRw1jSaDnmsDY/lgwIABFxhMwYABAy6oSUxhZnUT4AaDnspR02gy6LkGqDEyBQMGDNQM1KSZggEDBmoAqp0paJr2pKZpJzVNO6Np2vvVRMN5TdOOaJp2SNO0fWXHammatl7TtNNlvxHXmYY5mqala5p2VHfMIw1aKaaWtdlhTdPuu0H0/FvTtOSydjqkadofdOc+KKPnpKZpPa4DPQ01TYvVNC1B07Rjmqa9VXa8OtuoPJqqrZ2uCYQQ1bYBXsBZ4HbAF4gHWlUDHeeBOm7HPgHeL9t/H5h4nWnoAtwHHK2MBuAPwFpAAx4Adt8gev4NvOvh2lZlfecHNCnrU69rTE8UcF/Zfghwqqze6myj8miqtna6Flt1zxQ6AmeEEIlCCBuwEPhLNdMk8Rdgbtn+XOCv17MyIcQWILuKNPwF+E6UYhcQrmla1A2gpzz8BVgohCgWQpwDzlDat9eSnhQhxIGy/QIgAWhA9bZReTSVh+veTtcC1c0UGgBJuv+XqLhRrxcE8Iumafs1TXut7Fg9IUQKlHY+cEs10FUeDdXZboPLpuNzdEuqG0qPpmmNgXuB3dSQNnKjCWpAO/1aVDdT0Dwcqw51SCchxH3AU8CbmqZ1qQYargbV1W4zgKbAPUAKMPlG06NpWjCwDPiHECK/okurkaZqb6ffgupmCpeAhrr/twKXbzQRQojLZb/pwI+UTunS5HSz7Df9RtNVAQ3V0m5CiDQhhEMI4QRm8d+p7w2hR9M0H0pfvh+EEMvLDldrG3miqbrb6beiupnCXqCZpmlNNE3zBZ4HfrqRBGiaFqRpWojcB54AjpbR0a/ssn7AyhtJVxnKo+En4KUyCfsDQJ6cQl9PuK3Jn6a0nSQ9z2ua5qdpWhOgGbDnGtetAbOBBCHEFN2pamuj8miqzna6JqhuSSelUuJTlEpiP6yG+m+nVCIcDxyTNAC1gY3A6bLfWteZjgWUTjVLKP2iDCiPBkqnodPL2uwI0P4G0TOvrL7DlA7wKN31H5bRcxJ46jrQ05nSqfZh4FDZ9odqbqPyaKq2droWm2HRaMCAARdU9/LBgAEDNQwGUzBgwIALDKZgwIABFxhMwYABAy4wmIIBAwZcYDAFAwYMuMBgCgYMGHCBwRQMGDDggv8Ph+lWwakZeN8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import imshow, figure\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "i = 0.1\n",
    "j = 0.2 \n",
    "k = 0.1\n",
    "n = 0\n",
    "y_predict = np.argmax(np.power(p_t_test, i) * np.power(p_v_test, j) * np.power(p_l_test, k), axis = 1)\n",
    "for i_y, y in enumerate(y_predict):\n",
    "    if y==0 and y_true[i_y] == 1:\n",
    "        img_path = 'data/Tobacco800/images/%s.tif.small.png' % data_text_test[i_y][0]\n",
    "        print(img_path)\n",
    "        image = load_img(img_path)\n",
    "        figure()\n",
    "        imshow(image)\n",
    "        n += 1\n",
    "print(n) # 5 FN (handwriting,...), 16 FP (real 1st pages, tables/figures/complex layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LDA\n",
    "# features_x_train = np.concatenate([text_features_train, lda_train_x], axis = 1)\n",
    "# features_x_test = np.concatenate([text_features_test, lda_test_x], axis = 1)\n",
    "\n",
    "# without LDA\n",
    "features_x_train = text_features_train\n",
    "features_x_test = text_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "data_train_x = [features_x_train, image_features_train]\n",
    "data_test_x = [features_x_test, image_features_test]\n",
    "print(len(data_train_x[0][0]))\n",
    "print(len(data_train_x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_page_share = np.sum(data_train_y) / len(data_train_y)\n",
    "class_weights = {0 : first_page_share, 1 : (1 - first_page_share)}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 3s 3ms/step - loss: 0.0557 - acc: 0.9748 - val_loss: 0.8346 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7864145872148072 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 191us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.8166 - val_acc: 0.8958\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 179us/step - loss: 3.2591e-04 - acc: 1.0000 - val_loss: 0.8187 - val_acc: 0.8880\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 357us/step - loss: 6.3986e-04 - acc: 1.0000 - val_loss: 0.7835 - val_acc: 0.8880\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 262us/step - loss: 3.0395e-04 - acc: 1.0000 - val_loss: 0.7756 - val_acc: 0.8996\n",
      "\n",
      "kappa improvement: 0.7935495738549267 (before: 0.7864145872148072), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 234us/step - loss: 5.2975e-05 - acc: 1.0000 - val_loss: 0.7797 - val_acc: 0.8919\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 150us/step - loss: 8.6492e-05 - acc: 1.0000 - val_loss: 0.7788 - val_acc: 0.8919\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 253us/step - loss: 3.3555e-05 - acc: 1.0000 - val_loss: 0.7805 - val_acc: 0.8919\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 299us/step - loss: 5.2908e-05 - acc: 1.0000 - val_loss: 0.7787 - val_acc: 0.8919\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 206us/step - loss: 3.2837e-05 - acc: 1.0000 - val_loss: 0.7768 - val_acc: 0.8919\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 181us/step - loss: 9.2121e-05 - acc: 1.0000 - val_loss: 0.7726 - val_acc: 0.8996\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 174us/step - loss: 4.6403e-05 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.8996\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 265us/step - loss: 5.4928e-05 - acc: 1.0000 - val_loss: 0.7719 - val_acc: 0.8958\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 157us/step - loss: 4.0200e-05 - acc: 1.0000 - val_loss: 0.7720 - val_acc: 0.8958\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 148us/step - loss: 1.8969e-05 - acc: 1.0000 - val_loss: 0.7722 - val_acc: 0.8919\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 143us/step - loss: 2.2625e-05 - acc: 1.0000 - val_loss: 0.7743 - val_acc: 0.8958\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 149us/step - loss: 2.3003e-05 - acc: 1.0000 - val_loss: 0.7725 - val_acc: 0.8958\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 144us/step - loss: 2.0914e-05 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.9035\n",
      "\n",
      "kappa improvement: 0.80073857516541 (before: 0.7935495738549267), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 165us/step - loss: 2.9811e-05 - acc: 1.0000 - val_loss: 0.7756 - val_acc: 0.8919\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 135us/step - loss: 8.5613e-06 - acc: 1.0000 - val_loss: 0.7762 - val_acc: 0.8996\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 265us/step - loss: 3.5551e-05 - acc: 1.0000 - val_loss: 0.7820 - val_acc: 0.8958\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 128us/step - loss: 1.4744e-05 - acc: 1.0000 - val_loss: 0.7843 - val_acc: 0.8919\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 254us/step - loss: 7.2795e-05 - acc: 1.0000 - val_loss: 0.7935 - val_acc: 0.8919\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 273us/step - loss: 7.4889e-06 - acc: 1.0000 - val_loss: 0.7958 - val_acc: 0.8919\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 143us/step - loss: 1.6982e-05 - acc: 1.0000 - val_loss: 0.7976 - val_acc: 0.8958\n",
      "Accuracy: 0.9034749034749034\n",
      "Kappa: 0.80073857516541\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 4s 4ms/step - loss: 0.0505 - acc: 0.9787 - val_loss: 1.1295 - val_acc: 0.8649\n",
      "\n",
      "kappa improvement: 0.7138121546961326 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 209us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.8724 - val_acc: 0.8726\n",
      "\n",
      "kappa improvement: 0.7415404154948744 (before: 0.7138121546961326), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 226us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8328 - val_acc: 0.9073\n",
      "\n",
      "kappa improvement: 0.8070044709388972 (before: 0.7415404154948744), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 184us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.7729 - val_acc: 0.8919\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 175us/step - loss: 5.6228e-04 - acc: 1.0000 - val_loss: 0.8932 - val_acc: 0.8919\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 276us/step - loss: 2.0954e-04 - acc: 1.0000 - val_loss: 0.7855 - val_acc: 0.8958\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 141us/step - loss: 3.1859e-05 - acc: 1.0000 - val_loss: 0.7664 - val_acc: 0.9073\n",
      "\n",
      "kappa improvement: 0.807982206845422 (before: 0.8070044709388972), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 149us/step - loss: 1.5216e-05 - acc: 1.0000 - val_loss: 0.7640 - val_acc: 0.9073\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 133us/step - loss: 8.1575e-04 - acc: 1.0000 - val_loss: 0.8545 - val_acc: 0.8996\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 181us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.8788 - val_acc: 0.8842\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 143us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.8640 - val_acc: 0.9073\n",
      "\n",
      "kappa improvement: 0.8089500860585198 (before: 0.807982206845422), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 145us/step - loss: 2.2584e-04 - acc: 1.0000 - val_loss: 0.8902 - val_acc: 0.8996\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 202us/step - loss: 1.5737e-05 - acc: 1.0000 - val_loss: 0.8867 - val_acc: 0.8996\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 162us/step - loss: 1.3046e-05 - acc: 1.0000 - val_loss: 0.8866 - val_acc: 0.8996\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 140us/step - loss: 2.9393e-05 - acc: 1.0000 - val_loss: 0.8853 - val_acc: 0.8996\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 224us/step - loss: 2.6581e-05 - acc: 1.0000 - val_loss: 0.8875 - val_acc: 0.8996\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 173us/step - loss: 1.1912e-05 - acc: 1.0000 - val_loss: 0.8867 - val_acc: 0.8996\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 186us/step - loss: 1.4560e-06 - acc: 1.0000 - val_loss: 0.8867 - val_acc: 0.8996\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 170us/step - loss: 6.7342e-06 - acc: 1.0000 - val_loss: 0.8874 - val_acc: 0.8996\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 148us/step - loss: 2.0446e-05 - acc: 1.0000 - val_loss: 0.8881 - val_acc: 0.8996\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 161us/step - loss: 8.2654e-06 - acc: 1.0000 - val_loss: 0.8871 - val_acc: 0.8996\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 139us/step - loss: 1.0663e-05 - acc: 1.0000 - val_loss: 0.8874 - val_acc: 0.8996\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 123us/step - loss: 9.7489e-05 - acc: 1.0000 - val_loss: 0.9007 - val_acc: 0.8958\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 130us/step - loss: 2.3276e-06 - acc: 1.0000 - val_loss: 0.9009 - val_acc: 0.8958\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 134us/step - loss: 1.5318e-05 - acc: 1.0000 - val_loss: 0.8917 - val_acc: 0.8958\n",
      "Accuracy: 0.9073359073359073\n",
      "Kappa: 0.8089500860585198\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 4s 4ms/step - loss: 0.0328 - acc: 0.9874 - val_loss: 0.8242 - val_acc: 0.8764\n",
      "\n",
      "kappa improvement: 0.7521382857826424 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 214us/step - loss: 0.0023 - acc: 0.9990 - val_loss: 0.7319 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7869481765834934 (before: 0.7521382857826424), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 200us/step - loss: 5.2859e-04 - acc: 1.0000 - val_loss: 0.7529 - val_acc: 0.8880\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 158us/step - loss: 3.0828e-04 - acc: 1.0000 - val_loss: 0.7628 - val_acc: 0.8880\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 138us/step - loss: 4.1436e-04 - acc: 1.0000 - val_loss: 0.7988 - val_acc: 0.8919\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 129us/step - loss: 1.4509e-04 - acc: 1.0000 - val_loss: 0.7515 - val_acc: 0.8880\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 242us/step - loss: 5.3088e-04 - acc: 1.0000 - val_loss: 0.8857 - val_acc: 0.8919\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 195us/step - loss: 0.0041 - acc: 0.9981 - val_loss: 0.9960 - val_acc: 0.8919\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 191us/step - loss: 3.6861e-04 - acc: 1.0000 - val_loss: 0.7314 - val_acc: 0.8958\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 138us/step - loss: 2.1739e-05 - acc: 1.0000 - val_loss: 0.7337 - val_acc: 0.9035\n",
      "\n",
      "kappa improvement: 0.8022357289025992 (before: 0.7869481765834934), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 141us/step - loss: 8.3370e-06 - acc: 1.0000 - val_loss: 0.7319 - val_acc: 0.8996\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 153us/step - loss: 1.1577e-05 - acc: 1.0000 - val_loss: 0.7319 - val_acc: 0.8996\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 130us/step - loss: 2.3077e-06 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 0.8996\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 144us/step - loss: 1.3595e-05 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.9073\n",
      "\n",
      "kappa improvement: 0.8084673691994824 (before: 0.8022357289025992), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 146us/step - loss: 5.3557e-05 - acc: 1.0000 - val_loss: 0.7368 - val_acc: 0.9035\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 121us/step - loss: 1.1909e-05 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.9073\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 237us/step - loss: 1.3478e-05 - acc: 1.0000 - val_loss: 0.7493 - val_acc: 0.9035\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 150us/step - loss: 2.9444e-04 - acc: 1.0000 - val_loss: 0.9536 - val_acc: 0.8996\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 135us/step - loss: 4.1764e-05 - acc: 1.0000 - val_loss: 0.8814 - val_acc: 0.9073\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 153us/step - loss: 4.7827e-06 - acc: 1.0000 - val_loss: 0.8707 - val_acc: 0.9035\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 147us/step - loss: 2.2022e-06 - acc: 1.0000 - val_loss: 0.8717 - val_acc: 0.9035\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 143us/step - loss: 3.5508e-06 - acc: 1.0000 - val_loss: 0.8661 - val_acc: 0.9035\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 143us/step - loss: 1.1685e-04 - acc: 1.0000 - val_loss: 0.7607 - val_acc: 0.8919\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 150us/step - loss: 2.6665e-05 - acc: 1.0000 - val_loss: 0.7664 - val_acc: 0.8958\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 123us/step - loss: 4.1793e-05 - acc: 1.0000 - val_loss: 0.7696 - val_acc: 0.8996\n",
      "Accuracy: 0.9073359073359073\n",
      "Kappa: 0.8084673691994824\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 4s 4ms/step - loss: 0.1068 - acc: 0.9699 - val_loss: 0.7842 - val_acc: 0.8842\n",
      "\n",
      "kappa improvement: 0.7641595337825533 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 248us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8182 - val_acc: 0.8842\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 145us/step - loss: 0.0043 - acc: 0.9981 - val_loss: 0.8051 - val_acc: 0.9073\n",
      "\n",
      "kappa improvement: 0.8103837471783296 (before: 0.7641595337825533), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 172us/step - loss: 1.7635e-04 - acc: 1.0000 - val_loss: 0.8223 - val_acc: 0.9073\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 133us/step - loss: 0.0055 - acc: 0.9990 - val_loss: 0.8764 - val_acc: 0.8919\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 131us/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.8559 - val_acc: 0.8842\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 132us/step - loss: 9.3562e-05 - acc: 1.0000 - val_loss: 0.8372 - val_acc: 0.8996\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 171us/step - loss: 4.6500e-05 - acc: 1.0000 - val_loss: 0.8330 - val_acc: 0.9035\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 125us/step - loss: 6.1292e-05 - acc: 1.0000 - val_loss: 0.8316 - val_acc: 0.9035\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 127us/step - loss: 3.6838e-05 - acc: 1.0000 - val_loss: 0.8343 - val_acc: 0.9073\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 127us/step - loss: 8.0418e-05 - acc: 1.0000 - val_loss: 0.8336 - val_acc: 0.9073\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 168us/step - loss: 1.8089e-05 - acc: 1.0000 - val_loss: 0.8351 - val_acc: 0.9073\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 142us/step - loss: 7.6186e-04 - acc: 1.0000 - val_loss: 0.8211 - val_acc: 0.9073\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 129us/step - loss: 1.6566e-05 - acc: 1.0000 - val_loss: 0.8321 - val_acc: 0.9073\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 120us/step - loss: 1.6761e-05 - acc: 1.0000 - val_loss: 0.8289 - val_acc: 0.9151\n",
      "\n",
      "kappa improvement: 0.8235366986683184 (before: 0.8103837471783296), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 158us/step - loss: 9.8567e-06 - acc: 1.0000 - val_loss: 0.8248 - val_acc: 0.9073\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 134us/step - loss: 2.4755e-05 - acc: 1.0000 - val_loss: 0.8286 - val_acc: 0.9112\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 206us/step - loss: 2.1643e-05 - acc: 1.0000 - val_loss: 0.8338 - val_acc: 0.9073\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 168us/step - loss: 2.4312e-05 - acc: 1.0000 - val_loss: 0.8307 - val_acc: 0.9112\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 158us/step - loss: 1.2945e-05 - acc: 1.0000 - val_loss: 0.8294 - val_acc: 0.9151\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 143us/step - loss: 1.3130e-05 - acc: 1.0000 - val_loss: 0.8248 - val_acc: 0.9073\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 169us/step - loss: 1.3137e-05 - acc: 1.0000 - val_loss: 0.8208 - val_acc: 0.9073\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 184us/step - loss: 1.0274e-05 - acc: 1.0000 - val_loss: 0.8227 - val_acc: 0.9073\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 174us/step - loss: 2.6136e-06 - acc: 1.0000 - val_loss: 0.8244 - val_acc: 0.9073\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 134us/step - loss: 4.7357e-06 - acc: 1.0000 - val_loss: 0.8248 - val_acc: 0.9073\n",
      "Accuracy: 0.915057915057915\n",
      "Kappa: 0.8235366986683184\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 4s 3ms/step - loss: 0.0846 - acc: 0.9690 - val_loss: 0.8452 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7880073968533059 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 172us/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.8126 - val_acc: 0.8996\n",
      "\n",
      "kappa improvement: 0.7956049292782128 (before: 0.7880073968533059), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 156us/step - loss: 2.9692e-04 - acc: 1.0000 - val_loss: 0.7893 - val_acc: 0.8958\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 137us/step - loss: 1.9937e-04 - acc: 1.0000 - val_loss: 0.7911 - val_acc: 0.8958\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 131us/step - loss: 2.5154e-04 - acc: 1.0000 - val_loss: 0.7835 - val_acc: 0.8919\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 143us/step - loss: 1.7844e-04 - acc: 1.0000 - val_loss: 0.7811 - val_acc: 0.8919\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 181us/step - loss: 1.3030e-04 - acc: 1.0000 - val_loss: 0.7893 - val_acc: 0.8880\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 163us/step - loss: 6.6371e-05 - acc: 1.0000 - val_loss: 0.7803 - val_acc: 0.8919\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 258us/step - loss: 6.0954e-05 - acc: 1.0000 - val_loss: 0.7735 - val_acc: 0.8958\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 148us/step - loss: 4.9219e-05 - acc: 1.0000 - val_loss: 0.7775 - val_acc: 0.8919\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 183us/step - loss: 4.2441e-05 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.8958\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 158us/step - loss: 4.2423e-05 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.8958\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 185us/step - loss: 6.6577e-05 - acc: 1.0000 - val_loss: 0.7748 - val_acc: 0.8958\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 218us/step - loss: 3.2520e-05 - acc: 1.0000 - val_loss: 0.7705 - val_acc: 0.8958\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 137us/step - loss: 3.6762e-05 - acc: 1.0000 - val_loss: 0.7744 - val_acc: 0.8958\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 183us/step - loss: 9.5296e-05 - acc: 1.0000 - val_loss: 0.7694 - val_acc: 0.8880\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 197us/step - loss: 0.0176 - acc: 0.9961 - val_loss: 0.8749 - val_acc: 0.8842\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 169us/step - loss: 0.0018 - acc: 0.9990 - val_loss: 0.9378 - val_acc: 0.9035\n",
      "\n",
      "kappa improvement: 0.7971554775852887 (before: 0.7956049292782128), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 169us/step - loss: 2.0911e-04 - acc: 1.0000 - val_loss: 0.8351 - val_acc: 0.9073\n",
      "\n",
      "kappa improvement: 0.8084673691994824 (before: 0.7971554775852887), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9990 - val_loss: 0.8821 - val_acc: 0.8880\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 155us/step - loss: 0.0203 - acc: 0.9971 - val_loss: 1.1386 - val_acc: 0.8764\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 181us/step - loss: 0.0077 - acc: 0.9990 - val_loss: 1.3595 - val_acc: 0.8687\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 174us/step - loss: 0.0025 - acc: 0.9981 - val_loss: 1.1349 - val_acc: 0.8919\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 124us/step - loss: 6.5034e-05 - acc: 1.0000 - val_loss: 1.1460 - val_acc: 0.8919\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 136us/step - loss: 1.4109e-04 - acc: 1.0000 - val_loss: 1.0891 - val_acc: 0.9035\n",
      "Accuracy: 0.9073359073359073\n",
      "Kappa: 0.8084673691994824\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 4s 4ms/step - loss: 0.0846 - acc: 0.9631 - val_loss: 0.7645 - val_acc: 0.8880\n",
      "\n",
      "kappa improvement: 0.7676842658748569 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 228us/step - loss: 7.6244e-04 - acc: 1.0000 - val_loss: 0.7362 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7847976611786429 (before: 0.7676842658748569), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 198us/step - loss: 7.2543e-04 - acc: 1.0000 - val_loss: 0.7645 - val_acc: 0.8842\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 136us/step - loss: 2.5263e-04 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 0.8919\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 132us/step - loss: 2.2360e-04 - acc: 1.0000 - val_loss: 0.7726 - val_acc: 0.8880\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 144us/step - loss: 7.4105e-04 - acc: 1.0000 - val_loss: 0.7820 - val_acc: 0.8764\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 130us/step - loss: 5.3539e-05 - acc: 1.0000 - val_loss: 0.7857 - val_acc: 0.8764\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 162us/step - loss: 7.4463e-05 - acc: 1.0000 - val_loss: 0.7845 - val_acc: 0.8764\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 132us/step - loss: 6.3441e-05 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.8880\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 127us/step - loss: 5.4678e-05 - acc: 1.0000 - val_loss: 0.7664 - val_acc: 0.8996\n",
      "\n",
      "kappa improvement: 0.7940672782874618 (before: 0.7847976611786429), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 297us/step - loss: 4.7234e-05 - acc: 1.0000 - val_loss: 0.7651 - val_acc: 0.8996\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 142us/step - loss: 4.9498e-05 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.8996\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 247us/step - loss: 4.9969e-05 - acc: 1.0000 - val_loss: 0.7681 - val_acc: 0.8958\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 151us/step - loss: 3.2505e-05 - acc: 1.0000 - val_loss: 0.7703 - val_acc: 0.8958\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 227us/step - loss: 3.3194e-05 - acc: 1.0000 - val_loss: 0.7707 - val_acc: 0.8958\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 176us/step - loss: 2.3644e-05 - acc: 1.0000 - val_loss: 0.7739 - val_acc: 0.8880\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 207us/step - loss: 2.5572e-05 - acc: 1.0000 - val_loss: 0.7742 - val_acc: 0.8919\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 206us/step - loss: 6.1061e-05 - acc: 1.0000 - val_loss: 0.7720 - val_acc: 0.8996\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 202us/step - loss: 2.5785e-05 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.8996\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 171us/step - loss: 1.8499e-05 - acc: 1.0000 - val_loss: 0.7733 - val_acc: 0.8996\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 138us/step - loss: 2.9474e-05 - acc: 1.0000 - val_loss: 0.7758 - val_acc: 0.8958\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 134us/step - loss: 3.8491e-05 - acc: 1.0000 - val_loss: 0.7777 - val_acc: 0.8919\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 150us/step - loss: 6.6305e-05 - acc: 1.0000 - val_loss: 0.7814 - val_acc: 0.8919\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 139us/step - loss: 1.3562e-04 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.8958\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 165us/step - loss: 3.3812e-05 - acc: 1.0000 - val_loss: 0.7617 - val_acc: 0.8958\n",
      "Accuracy: 0.8996138996138996\n",
      "Kappa: 0.7940672782874618\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 4s 4ms/step - loss: 0.0868 - acc: 0.9719 - val_loss: 0.6758 - val_acc: 0.8996\n",
      "\n",
      "kappa improvement: 0.7940672782874618 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 198us/step - loss: 0.0011 - acc: 0.9990 - val_loss: 0.6909 - val_acc: 0.8958\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 189us/step - loss: 7.2293e-04 - acc: 1.0000 - val_loss: 0.6829 - val_acc: 0.9035\n",
      "\n",
      "kappa improvement: 0.8027297931328642 (before: 0.7940672782874618), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 157us/step - loss: 1.3365e-04 - acc: 1.0000 - val_loss: 0.6816 - val_acc: 0.9035\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 127us/step - loss: 3.5842e-04 - acc: 1.0000 - val_loss: 0.6822 - val_acc: 0.8919\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 142us/step - loss: 8.9531e-04 - acc: 1.0000 - val_loss: 0.6791 - val_acc: 0.9073\n",
      "\n",
      "kappa improvement: 0.8103837471783296 (before: 0.8027297931328642), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 145us/step - loss: 2.8552e-04 - acc: 1.0000 - val_loss: 0.6948 - val_acc: 0.8958\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 135us/step - loss: 1.9073e-04 - acc: 1.0000 - val_loss: 0.6869 - val_acc: 0.8996\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 139us/step - loss: 5.0757e-05 - acc: 1.0000 - val_loss: 0.6887 - val_acc: 0.8996\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 123us/step - loss: 3.5831e-05 - acc: 1.0000 - val_loss: 0.6905 - val_acc: 0.8996\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 124us/step - loss: 4.2833e-05 - acc: 1.0000 - val_loss: 0.6918 - val_acc: 0.8996\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 163us/step - loss: 3.3141e-05 - acc: 1.0000 - val_loss: 0.6930 - val_acc: 0.9035\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 158us/step - loss: 3.3513e-05 - acc: 1.0000 - val_loss: 0.6947 - val_acc: 0.8996\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 160us/step - loss: 1.5570e-04 - acc: 1.0000 - val_loss: 0.7152 - val_acc: 0.8880\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 145us/step - loss: 4.4819e-05 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.8919\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 191us/step - loss: 4.4742e-05 - acc: 1.0000 - val_loss: 0.6994 - val_acc: 0.8996\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 130us/step - loss: 1.9638e-05 - acc: 1.0000 - val_loss: 0.6972 - val_acc: 0.9035\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 160us/step - loss: 2.6358e-05 - acc: 1.0000 - val_loss: 0.6978 - val_acc: 0.9035\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 233us/step - loss: 2.7823e-05 - acc: 1.0000 - val_loss: 0.6988 - val_acc: 0.9035\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 157us/step - loss: 2.3017e-05 - acc: 1.0000 - val_loss: 0.6998 - val_acc: 0.8958\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 166us/step - loss: 1.2061e-05 - acc: 1.0000 - val_loss: 0.7006 - val_acc: 0.8996\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 167us/step - loss: 9.4111e-06 - acc: 1.0000 - val_loss: 0.7013 - val_acc: 0.8996\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 153us/step - loss: 1.6586e-05 - acc: 1.0000 - val_loss: 0.7024 - val_acc: 0.8996\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 146us/step - loss: 1.2242e-05 - acc: 1.0000 - val_loss: 0.7044 - val_acc: 0.8958\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 133us/step - loss: 2.2076e-05 - acc: 1.0000 - val_loss: 0.7065 - val_acc: 0.8996\n",
      "Accuracy: 0.9073359073359073\n",
      "Kappa: 0.8103837471783296\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 4s 4ms/step - loss: 0.0571 - acc: 0.9767 - val_loss: 0.8162 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7820476858345021 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 174us/step - loss: 0.0089 - acc: 0.9981 - val_loss: 0.7699 - val_acc: 0.9073\n",
      "\n",
      "kappa improvement: 0.8074945803654382 (before: 0.7820476858345021), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 169us/step - loss: 6.0257e-04 - acc: 1.0000 - val_loss: 0.7564 - val_acc: 0.8958\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 177us/step - loss: 1.1530e-04 - acc: 1.0000 - val_loss: 0.7595 - val_acc: 0.8958\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 163us/step - loss: 1.8852e-04 - acc: 1.0000 - val_loss: 0.7594 - val_acc: 0.8958\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 148us/step - loss: 8.5097e-05 - acc: 1.0000 - val_loss: 0.7609 - val_acc: 0.8958\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 142us/step - loss: 1.1569e-04 - acc: 1.0000 - val_loss: 0.7569 - val_acc: 0.8958\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 181us/step - loss: 7.4538e-05 - acc: 1.0000 - val_loss: 0.7515 - val_acc: 0.8996\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 165us/step - loss: 6.8366e-04 - acc: 1.0000 - val_loss: 0.7819 - val_acc: 0.8996\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 130us/step - loss: 1.9933e-04 - acc: 1.0000 - val_loss: 0.7505 - val_acc: 0.9112\n",
      "\n",
      "kappa improvement: 0.8166794891521773 (before: 0.8074945803654382), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 184us/step - loss: 1.1818e-04 - acc: 1.0000 - val_loss: 0.7598 - val_acc: 0.9073\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 136us/step - loss: 1.5804e-05 - acc: 1.0000 - val_loss: 0.7609 - val_acc: 0.9073\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 148us/step - loss: 1.7996e-05 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.9073\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 191us/step - loss: 2.8183e-05 - acc: 1.0000 - val_loss: 0.7625 - val_acc: 0.9073\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 154us/step - loss: 2.3453e-05 - acc: 1.0000 - val_loss: 0.7650 - val_acc: 0.9073\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 158us/step - loss: 7.1824e-05 - acc: 1.0000 - val_loss: 0.7714 - val_acc: 0.8996\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 255us/step - loss: 2.5274e-05 - acc: 1.0000 - val_loss: 0.7671 - val_acc: 0.8996\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 158us/step - loss: 2.2146e-05 - acc: 1.0000 - val_loss: 0.7658 - val_acc: 0.9073\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 163us/step - loss: 2.0452e-05 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.9035\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 150us/step - loss: 2.1085e-05 - acc: 1.0000 - val_loss: 0.7685 - val_acc: 0.9035\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 149us/step - loss: 1.0578e-05 - acc: 1.0000 - val_loss: 0.7686 - val_acc: 0.9073\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 158us/step - loss: 9.2016e-06 - acc: 1.0000 - val_loss: 0.7691 - val_acc: 0.9073\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 161us/step - loss: 7.4497e-06 - acc: 1.0000 - val_loss: 0.7704 - val_acc: 0.9073\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 153us/step - loss: 6.6042e-06 - acc: 1.0000 - val_loss: 0.7713 - val_acc: 0.9073\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 196us/step - loss: 1.0523e-05 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.9073\n",
      "Accuracy: 0.9111969111969112\n",
      "Kappa: 0.8166794891521773\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 4s 4ms/step - loss: 0.1011 - acc: 0.9690 - val_loss: 0.7891 - val_acc: 0.8803\n",
      "\n",
      "kappa improvement: 0.7553849434847516 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 191us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7586 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7787810383747178 (before: 0.7553849434847516), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 208us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.7635 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7793330087633885 (before: 0.7787810383747178), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 149us/step - loss: 1.4746e-04 - acc: 1.0000 - val_loss: 0.7616 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7869481765834934 (before: 0.7793330087633885), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 153us/step - loss: 2.2871e-04 - acc: 1.0000 - val_loss: 0.7739 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7874791065187662 (before: 0.7869481765834934), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 132us/step - loss: 3.6157e-04 - acc: 1.0000 - val_loss: 0.7769 - val_acc: 0.8958\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 166us/step - loss: 1.4512e-04 - acc: 1.0000 - val_loss: 0.7743 - val_acc: 0.8958\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 158us/step - loss: 1.1911e-04 - acc: 1.0000 - val_loss: 0.7624 - val_acc: 0.8919\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 126us/step - loss: 6.2520e-05 - acc: 1.0000 - val_loss: 0.7604 - val_acc: 0.8919\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 127us/step - loss: 8.3607e-05 - acc: 1.0000 - val_loss: 0.7619 - val_acc: 0.8919\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 179us/step - loss: 1.0538e-04 - acc: 1.0000 - val_loss: 0.7609 - val_acc: 0.8919\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 151us/step - loss: 8.0951e-05 - acc: 1.0000 - val_loss: 0.7567 - val_acc: 0.8958\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 150us/step - loss: 1.7043e-04 - acc: 1.0000 - val_loss: 0.7833 - val_acc: 0.8958\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 139us/step - loss: 3.4197e-05 - acc: 1.0000 - val_loss: 0.7821 - val_acc: 0.8919\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 182us/step - loss: 5.1079e-05 - acc: 1.0000 - val_loss: 0.7779 - val_acc: 0.8919\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 130us/step - loss: 4.6764e-05 - acc: 1.0000 - val_loss: 0.7813 - val_acc: 0.8919\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 162us/step - loss: 7.7736e-05 - acc: 1.0000 - val_loss: 0.7756 - val_acc: 0.8919\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 262us/step - loss: 3.1113e-05 - acc: 1.0000 - val_loss: 0.7733 - val_acc: 0.8958\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 191us/step - loss: 3.2990e-05 - acc: 1.0000 - val_loss: 0.7728 - val_acc: 0.8958\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 151us/step - loss: 3.9188e-05 - acc: 1.0000 - val_loss: 0.7708 - val_acc: 0.8958\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 145us/step - loss: 1.3305e-05 - acc: 1.0000 - val_loss: 0.7701 - val_acc: 0.8958\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 169us/step - loss: 1.9603e-05 - acc: 1.0000 - val_loss: 0.7709 - val_acc: 0.8958\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 156us/step - loss: 2.4644e-05 - acc: 1.0000 - val_loss: 0.7719 - val_acc: 0.8958\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 157us/step - loss: 1.7125e-05 - acc: 1.0000 - val_loss: 0.7752 - val_acc: 0.8958\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 133us/step - loss: 2.6946e-05 - acc: 1.0000 - val_loss: 0.7721 - val_acc: 0.8958\n",
      "Accuracy: 0.8957528957528957\n",
      "Kappa: 0.7874791065187662\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/25\n",
      "1031/1031 [==============================] - 4s 4ms/step - loss: 0.0447 - acc: 0.9855 - val_loss: 0.8117 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7759792413196589 (before: -inf), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 2/25\n",
      "1031/1031 [==============================] - 0s 180us/step - loss: 0.0023 - acc: 0.9981 - val_loss: 0.8929 - val_acc: 0.8803\n",
      "Epoch 3/25\n",
      "1031/1031 [==============================] - 0s 166us/step - loss: 3.8599e-04 - acc: 1.0000 - val_loss: 0.7891 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7869481765834934 (before: 0.7759792413196589), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 4/25\n",
      "1031/1031 [==============================] - 0s 165us/step - loss: 8.0435e-05 - acc: 1.0000 - val_loss: 0.7904 - val_acc: 0.8919\n",
      "Epoch 5/25\n",
      "1031/1031 [==============================] - 0s 135us/step - loss: 5.8576e-05 - acc: 1.0000 - val_loss: 0.7934 - val_acc: 0.8958\n",
      "Epoch 6/25\n",
      "1031/1031 [==============================] - 0s 133us/step - loss: 0.0018 - acc: 0.9990 - val_loss: 0.9846 - val_acc: 0.8842\n",
      "Epoch 7/25\n",
      "1031/1031 [==============================] - 0s 156us/step - loss: 0.0034 - acc: 0.9981 - val_loss: 1.0883 - val_acc: 0.8803\n",
      "Epoch 8/25\n",
      "1031/1031 [==============================] - 0s 169us/step - loss: 0.0043 - acc: 0.9981 - val_loss: 0.9826 - val_acc: 0.8958\n",
      "Epoch 9/25\n",
      "1031/1031 [==============================] - 0s 163us/step - loss: 7.4357e-05 - acc: 1.0000 - val_loss: 0.9832 - val_acc: 0.8958\n",
      "Epoch 10/25\n",
      "1031/1031 [==============================] - 0s 149us/step - loss: 5.0710e-04 - acc: 1.0000 - val_loss: 1.0486 - val_acc: 0.8880\n",
      "Epoch 11/25\n",
      "1031/1031 [==============================] - 0s 139us/step - loss: 8.3075e-05 - acc: 1.0000 - val_loss: 1.0009 - val_acc: 0.8958\n",
      "Epoch 12/25\n",
      "1031/1031 [==============================] - 0s 184us/step - loss: 3.9532e-05 - acc: 1.0000 - val_loss: 1.0262 - val_acc: 0.8880\n",
      "Epoch 13/25\n",
      "1031/1031 [==============================] - 0s 169us/step - loss: 2.9839e-04 - acc: 1.0000 - val_loss: 1.0009 - val_acc: 0.8996\n",
      "\n",
      "kappa improvement: 0.7930292598967298 (before: 0.7869481765834934), saving to Tobacco800_exp3_img-text_mlp_simple.hdf5\n",
      "Epoch 14/25\n",
      "1031/1031 [==============================] - 0s 170us/step - loss: 9.2827e-06 - acc: 1.0000 - val_loss: 1.0019 - val_acc: 0.8996\n",
      "Epoch 15/25\n",
      "1031/1031 [==============================] - 0s 168us/step - loss: 7.2332e-06 - acc: 1.0000 - val_loss: 1.0012 - val_acc: 0.8996\n",
      "Epoch 16/25\n",
      "1031/1031 [==============================] - 0s 255us/step - loss: 6.1325e-06 - acc: 1.0000 - val_loss: 0.9982 - val_acc: 0.8996\n",
      "Epoch 17/25\n",
      "1031/1031 [==============================] - 0s 175us/step - loss: 4.6170e-05 - acc: 1.0000 - val_loss: 0.9919 - val_acc: 0.8958\n",
      "Epoch 18/25\n",
      "1031/1031 [==============================] - 0s 164us/step - loss: 8.5062e-07 - acc: 1.0000 - val_loss: 0.9918 - val_acc: 0.8919\n",
      "Epoch 19/25\n",
      "1031/1031 [==============================] - 0s 204us/step - loss: 6.2637e-06 - acc: 1.0000 - val_loss: 0.9937 - val_acc: 0.8919\n",
      "Epoch 20/25\n",
      "1031/1031 [==============================] - 0s 189us/step - loss: 9.4086e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.8919\n",
      "Epoch 21/25\n",
      "1031/1031 [==============================] - 0s 187us/step - loss: 1.3143e-06 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.8919\n",
      "Epoch 22/25\n",
      "1031/1031 [==============================] - 0s 138us/step - loss: 9.3404e-07 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.8919\n",
      "Epoch 23/25\n",
      "1031/1031 [==============================] - 0s 137us/step - loss: 7.2380e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.8919\n",
      "Epoch 24/25\n",
      "1031/1031 [==============================] - 0s 148us/step - loss: 1.4602e-06 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.8919\n",
      "Epoch 25/25\n",
      "1031/1031 [==============================] - 0s 161us/step - loss: 8.3140e-06 - acc: 1.0000 - val_loss: 0.9976 - val_acc: 0.8958\n",
      "Accuracy: 0.8996138996138996\n",
      "Kappa: 0.7930292598967298\n",
      "0.9054054054054055\n",
      "0.8051798979324678\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 10\n",
    "all_acc = []\n",
    "all_kap = []\n",
    "for n_repeat in range(n_repeats):\n",
    "    text_input = Input(shape=(len(data_train_x[0][0]),))\n",
    "    img_input = Input(shape=(len(data_train_x[1][0]),))\n",
    "    combined = concatenate([text_input, img_input])\n",
    "    combined = Dense(400)(combined)\n",
    "    combined = LeakyReLU()(combined)\n",
    "    combined = Dropout(0.5)(combined)\n",
    "    model_output = Dense(1, activation = 'sigmoid')(combined)\n",
    "    combined_model = Model([text_input, img_input], model_output)\n",
    "\n",
    "    model_path = \"Tobacco800_exp3_img-text_mlp_simple.hdf5\"\n",
    "    checkpoint = ValidationCheckpoint(model_path, data_test_x, data_test_y)\n",
    "    combined_model.compile(loss = 'binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "    combined_model.fit(data_train_x, data_train_y, \n",
    "                       validation_data = (data_test_x, data_test_y), \n",
    "                       batch_size=32, epochs=25, \n",
    "                       callbacks=[checkpoint])\n",
    "\n",
    "    combined_model.load_weights(model_path)\n",
    "    y_predict = np.round(combined_model.predict(data_test_x))\n",
    "    all_acc.append(sklm.accuracy_score(data_test_y, y_predict))\n",
    "    all_kap.append(sklm.cohen_kappa_score(data_test_y, y_predict))\n",
    "    print(\"Accuracy: \" + str(all_acc[-1]))\n",
    "    print(\"Kappa: \" + str(all_kap[-1]))\n",
    "print(np.average(np.array(all_acc)))\n",
    "print(np.average(np.array(all_kap)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8841698841698842\n",
      "Kappa: 0.7568988173455979\n"
     ]
    }
   ],
   "source": [
    "combined_model.load_weights(model_path)\n",
    "y_predict = np.round(combined_model.predict(data_test_x))\n",
    "print(\"Accuracy: \" + str(sklm.accuracy_score(data_test_y, y_predict)))\n",
    "print(\"Kappa: \" + str(sklm.cohen_kappa_score(data_test_y, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Early fusion with LDA ()\n",
    "\n",
    "Accuracy: 0.9061776061776061\n",
    "Kappa: 0.8069826853972477\n",
    "\n",
    "Early fusion without LDA\n",
    "\n",
    "Accuracy: 0.9054054054054055\n",
    "Kappa: 0.0.8051798979324678\n",
    "\n",
    "--\n",
    "\n",
    "extract 10 fp and 10 fn files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP: predecessor page\n",
    "* extract features from text and image\n",
    "* combine 2 in sequence RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_x_train = np.concatenate([text_features_train, image_features_train, lda_train_x], axis = 1)\n",
    "features_x_test = np.concatenate([text_features_test, image_features_test, lda_test_x], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_x_train = np.empty((len(features_x_train),2,len(features_x_train[0])))\n",
    "sep_tp_x_train = np.empty((len(features_x_train),len(features_x_train[0])))\n",
    "sep_pp_x_train = np.empty((len(features_x_train),len(features_x_train[0])))\n",
    "for i, d in enumerate(features_x_train):\n",
    "    if d[3] == \"\":\n",
    "        prev_page = np.zeros((1,len(features_x_train[0])))\n",
    "    else:\n",
    "        prev_page = features_x_train[i-1]\n",
    "    sequence_x_train[i][0] = sep_pp_x_train[i] = prev_page\n",
    "    sequence_x_train[i][1] = sep_tp_x_train[i] = features_x_train[i]\n",
    "\n",
    "sequence_x_test = np.empty((len(features_x_test),2,len(features_x_test[0])))\n",
    "sep_tp_x_test = np.empty((len(features_x_test),len(features_x_test[0])))\n",
    "sep_pp_x_test = np.empty((len(features_x_test),len(features_x_test[0])))\n",
    "for i, d in enumerate(features_x_test):\n",
    "    if d[3] == \"\":\n",
    "        prev_page = np.zeros((1,len(features_x_test[0])))\n",
    "    else:\n",
    "        prev_page = features_x_test[i-1]\n",
    "    sequence_x_test[i][0] = sep_pp_x_test[i] = prev_page\n",
    "    sequence_x_test[i][1] = sep_tp_x_test[i] = features_x_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1031, 564)\n",
      "(1031, 564)\n",
      "(259, 564)\n",
      "(259, 564)\n"
     ]
    }
   ],
   "source": [
    "print(sep_tp_x_train.shape)\n",
    "print(sep_pp_x_train.shape)\n",
    "print(sep_tp_x_test.shape)\n",
    "print(sep_pp_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1031, 2, 564)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/2\n",
      "1031/1031 [==============================] - 6s 6ms/step - loss: 0.6114 - acc: 0.6857 - val_loss: 0.5471 - val_acc: 0.7568\n",
      "\n",
      "kappa improvement: 0.47673411794888243 (before: -inf), saving to Tobacco_exp3_img-text_rnn-model.hdf5\n",
      "Epoch 2/2\n",
      "1031/1031 [==============================] - 1s 735us/step - loss: 0.4355 - acc: 0.8603 - val_loss: 0.4560 - val_acc: 0.8069\n",
      "\n",
      "kappa improvement: 0.590630334450275 (before: 0.47673411794888243), saving to Tobacco_exp3_img-text_rnn-model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.keras.callbacks.History at 0x7f41ff5bab38>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"Tobacco_exp3_img-text_rnn-model.hdf5\"\n",
    "checkpoint = ValidationCheckpoint(model_path, sequence_x_test, data_test_y)\n",
    "\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, nesterov=True)\n",
    "\n",
    "rnn_input = Input(shape=sequence_x_train[0].shape,)\n",
    "#attention_probs = Dense(sequence_x_train[1][0].shape[0], activation='softmax')(rnn_input)\n",
    "#attention_mul = multiply([rnn_input, attention_probs])\n",
    "rnn_block = Bidirectional(GRU(300, return_sequences = True))(rnn_input)\n",
    "rnn_block = Bidirectional(GRU(300))(rnn_block)\n",
    "combined = Dense(128)(rnn_block)\n",
    "combined = LeakyReLU()(combined)\n",
    "model_output = Dense(1, activation = 'sigmoid')(combined)\n",
    "combined_model = Model([rnn_input], model_output)\n",
    "combined_model.compile(loss = 'binary_crossentropy', optimizer=Nadam(lr=1e-5), metrics=['accuracy'])\n",
    "combined_model.fit(sequence_x_train, data_train_y, validation_data = (sequence_x_test, data_test_y), \n",
    "                   batch_size=32, epochs=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 5s 5ms/step - loss: 1.1246 - acc: 0.5209 - val_loss: 0.5209 - val_acc: 0.7490\n",
      "\n",
      "kappa improvement: 0.465742121798737 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 32us/step - loss: 0.2904 - acc: 0.8691 - val_loss: 0.4209 - val_acc: 0.8301\n",
      "\n",
      "kappa improvement: 0.6443639995006866 (before: 0.465742121798737), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 31us/step - loss: 0.1371 - acc: 0.9515 - val_loss: 0.4119 - val_acc: 0.8494\n",
      "\n",
      "kappa improvement: 0.6859825286784593 (before: 0.6443639995006866), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 29us/step - loss: 0.0786 - acc: 0.9690 - val_loss: 0.4135 - val_acc: 0.8533\n",
      "\n",
      "kappa improvement: 0.6951997522452772 (before: 0.6859825286784593), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 28us/step - loss: 0.0456 - acc: 0.9835 - val_loss: 0.4257 - val_acc: 0.8610\n",
      "\n",
      "kappa improvement: 0.7127010537992235 (before: 0.6951997522452772), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 52us/step - loss: 0.0441 - acc: 0.9816 - val_loss: 0.4391 - val_acc: 0.8610\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 25us/step - loss: 0.0352 - acc: 0.9845 - val_loss: 0.4472 - val_acc: 0.8610\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 24us/step - loss: 0.0359 - acc: 0.9855 - val_loss: 0.4522 - val_acc: 0.8764\n",
      "\n",
      "kappa improvement: 0.7459071678214483 (before: 0.7127010537992235), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 27us/step - loss: 0.0293 - acc: 0.9864 - val_loss: 0.4562 - val_acc: 0.8764\n",
      "\n",
      "kappa improvement: 0.7465443425076452 (before: 0.7459071678214483), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 23us/step - loss: 0.0340 - acc: 0.9903 - val_loss: 0.4598 - val_acc: 0.8726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.keras.callbacks.History at 0x7f41ffc8f208>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_input = Input(shape=sequence_x_train[0].shape)\n",
    "combined = Flatten()(feature_input)\n",
    "combined = Dropout(0.25)(combined)\n",
    "combined = Dense(300, activation = 'relu')(combined)\n",
    "model_output = Dense(1, activation = 'sigmoid')(combined)\n",
    "combined_model = Model([feature_input], model_output)\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_path = \"Tobacco_exp3_img-text_mlp_model.hdf5\"\n",
    "checkpoint = ValidationCheckpoint(model_path, sequence_x_test, data_test_y)\n",
    "combined_model.compile(loss = 'binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "combined_model.fit(sequence_x_train, data_train_y, validation_data = (sequence_x_test, data_test_y), \n",
    "                   batch_size=256, epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_x_2inputs_train = [sep_tp_x_train, sep_pp_x_train]\n",
    "sequence_x_2inputs_test = [sep_tp_x_test, sep_pp_x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1031, 564)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_x_2inputs_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 6s 5ms/step - loss: 1.8950 - acc: 0.5315 - val_loss: 1.1666 - val_acc: 0.8764\n",
      "\n",
      "kappa improvement: 0.7400250941028859 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 25us/step - loss: 0.1005 - acc: 0.9777 - val_loss: 0.9473 - val_acc: 0.8842\n",
      "\n",
      "kappa improvement: 0.7611876075731497 (before: 0.7400250941028859), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 18us/step - loss: 0.0155 - acc: 0.9942 - val_loss: 0.9637 - val_acc: 0.8842\n",
      "\n",
      "kappa improvement: 0.7617879698326078 (before: 0.7611876075731497), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.9839 - val_acc: 0.8842\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0099 - acc: 0.9952 - val_loss: 1.0009 - val_acc: 0.8880\n",
      "\n",
      "kappa improvement: 0.769438560947908 (before: 0.7617879698326078), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0089 - acc: 0.9971 - val_loss: 1.0205 - val_acc: 0.8880\n",
      "\n",
      "kappa improvement: 0.770593445527015 (before: 0.769438560947908), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 1.0372 - val_acc: 0.8880\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0085 - acc: 0.9971 - val_loss: 1.0520 - val_acc: 0.8880\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 3.8714e-04 - acc: 1.0000 - val_loss: 1.0677 - val_acc: 0.8880\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 7.8856e-04 - acc: 1.0000 - val_loss: 1.0794 - val_acc: 0.8880\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 5s 5ms/step - loss: 2.3143 - acc: 0.4336 - val_loss: 1.7713 - val_acc: 0.8108\n",
      "\n",
      "kappa improvement: 0.5886890293307405 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 35us/step - loss: 0.3498 - acc: 0.9379 - val_loss: 0.9806 - val_acc: 0.8803\n",
      "\n",
      "kappa improvement: 0.7503963689495445 (before: 0.5886890293307405), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 25us/step - loss: 0.0213 - acc: 0.9952 - val_loss: 0.9767 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.775410343759678 (before: 0.7503963689495445), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 21us/step - loss: 0.0254 - acc: 0.9932 - val_loss: 0.9814 - val_acc: 0.8880\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 23us/step - loss: 0.0111 - acc: 0.9981 - val_loss: 0.9919 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7759792413196589 (before: 0.775410343759678), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 20us/step - loss: 0.0102 - acc: 0.9971 - val_loss: 1.0077 - val_acc: 0.8919\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0107 - acc: 0.9971 - val_loss: 1.0211 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7842532317280104 (before: 0.7759792413196589), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0119 - acc: 0.9952 - val_loss: 1.0373 - val_acc: 0.8958\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0538 - val_acc: 0.8996\n",
      "\n",
      "kappa improvement: 0.7925063166327726 (before: 0.7842532317280104), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0024 - acc: 0.9981 - val_loss: 1.0670 - val_acc: 0.8958\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 7s 6ms/step - loss: 1.4988 - acc: 0.5907 - val_loss: 1.6782 - val_acc: 0.8340\n",
      "\n",
      "kappa improvement: 0.6437869822485207 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 29us/step - loss: 0.4003 - acc: 0.9418 - val_loss: 0.9636 - val_acc: 0.8880\n",
      "\n",
      "kappa improvement: 0.7676842658748569 (before: 0.6437869822485207), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 21us/step - loss: 0.0173 - acc: 0.9952 - val_loss: 0.9742 - val_acc: 0.9035\n",
      "\n",
      "kappa improvement: 0.80073857516541 (before: 0.7676842658748569), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.9917 - val_acc: 0.9035\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0158 - acc: 0.9952 - val_loss: 1.0031 - val_acc: 0.9035\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0109 - acc: 0.9961 - val_loss: 1.0204 - val_acc: 0.9035\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 13us/step - loss: 0.0027 - acc: 0.9981 - val_loss: 1.0339 - val_acc: 0.8958\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0051 - acc: 0.9981 - val_loss: 1.0485 - val_acc: 0.9035\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0150 - acc: 0.9961 - val_loss: 1.0615 - val_acc: 0.8996\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 18us/step - loss: 0.0130 - acc: 0.9971 - val_loss: 1.0609 - val_acc: 0.8958\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 6s 6ms/step - loss: 1.6080 - acc: 0.5645 - val_loss: 2.2494 - val_acc: 0.7722\n",
      "\n",
      "kappa improvement: 0.496722985212265 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 31us/step - loss: 0.6956 - acc: 0.9020 - val_loss: 0.9265 - val_acc: 0.8803\n",
      "\n",
      "kappa improvement: 0.7497584541062803 (before: 0.496722985212265), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 20us/step - loss: 0.0267 - acc: 0.9932 - val_loss: 0.9187 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7837060406421081 (before: 0.7497584541062803), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 19us/step - loss: 0.0212 - acc: 0.9942 - val_loss: 0.9302 - val_acc: 0.8958\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0145 - acc: 0.9961 - val_loss: 0.9363 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7847976611786429 (before: 0.7837060406421081), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0184 - acc: 0.9961 - val_loss: 0.9513 - val_acc: 0.8958\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 13us/step - loss: 0.0093 - acc: 0.9961 - val_loss: 0.9706 - val_acc: 0.8996\n",
      "\n",
      "kappa improvement: 0.7930292598967298 (before: 0.7847976611786429), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.9881 - val_acc: 0.8919\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 1.0023 - val_acc: 0.8958\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.9981 - val_loss: 1.0157 - val_acc: 0.8958\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 6s 6ms/step - loss: 1.9464 - acc: 0.5131 - val_loss: 1.2169 - val_acc: 0.8610\n",
      "\n",
      "kappa improvement: 0.7067740109440845 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 18us/step - loss: 0.1545 - acc: 0.9699 - val_loss: 0.9271 - val_acc: 0.8880\n",
      "\n",
      "kappa improvement: 0.7700174530757219 (before: 0.7067740109440845), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0267 - acc: 0.9932 - val_loss: 0.9434 - val_acc: 0.8842\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0248 - acc: 0.9932 - val_loss: 0.9584 - val_acc: 0.8880\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0214 - acc: 0.9961 - val_loss: 0.9705 - val_acc: 0.8803\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0047 - acc: 0.9971 - val_loss: 0.9866 - val_acc: 0.8842\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0046 - acc: 0.9990 - val_loss: 1.0036 - val_acc: 0.8842\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 21us/step - loss: 0.0026 - acc: 0.9990 - val_loss: 1.0197 - val_acc: 0.8842\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0090 - acc: 0.9971 - val_loss: 1.0350 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7782262996941895 (before: 0.7700174530757219), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0062 - acc: 0.9981 - val_loss: 1.0501 - val_acc: 0.8919\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 6s 6ms/step - loss: 1.5749 - acc: 0.5984 - val_loss: 1.9500 - val_acc: 0.7761\n",
      "\n",
      "kappa improvement: 0.5666897427022037 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.6308 - acc: 0.9020 - val_loss: 0.9468 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7771084337349398 (before: 0.5666897427022037), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 21us/step - loss: 0.0312 - acc: 0.9922 - val_loss: 0.9616 - val_acc: 0.8919\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 19us/step - loss: 0.0200 - acc: 0.9932 - val_loss: 0.9771 - val_acc: 0.8919\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0138 - acc: 0.9942 - val_loss: 0.9934 - val_acc: 0.8919\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0132 - acc: 0.9942 - val_loss: 1.0004 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7853393498480523 (before: 0.7771084337349398), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0078 - acc: 0.9971 - val_loss: 1.0120 - val_acc: 0.8919\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 13us/step - loss: 0.0023 - acc: 0.9990 - val_loss: 1.0253 - val_acc: 0.8958\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0052 - acc: 0.9971 - val_loss: 1.0314 - val_acc: 0.8996\n",
      "\n",
      "kappa improvement: 0.7930292598967298 (before: 0.7853393498480523), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0033 - acc: 0.9981 - val_loss: 1.0411 - val_acc: 0.8996\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 5s 5ms/step - loss: 1.4581 - acc: 0.6188 - val_loss: 0.8710 - val_acc: 0.8880\n",
      "\n",
      "kappa improvement: 0.7682719896337888 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 27us/step - loss: 0.0269 - acc: 0.9942 - val_loss: 0.8836 - val_acc: 0.8880\n",
      "\n",
      "kappa improvement: 0.7700174530757219 (before: 0.7682719896337888), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0151 - acc: 0.9942 - val_loss: 0.8927 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7771084337349398 (before: 0.7700174530757219), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0163 - acc: 0.9961 - val_loss: 0.9157 - val_acc: 0.8958\n",
      "\n",
      "kappa improvement: 0.7853393498480523 (before: 0.7771084337349398), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0109 - acc: 0.9981 - val_loss: 0.9376 - val_acc: 0.8919\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0183 - acc: 0.9952 - val_loss: 0.9697 - val_acc: 0.8919\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 24us/step - loss: 0.0096 - acc: 0.9942 - val_loss: 0.9824 - val_acc: 0.8880\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 32us/step - loss: 0.0071 - acc: 0.9961 - val_loss: 0.9873 - val_acc: 0.8919\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 31us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 1.0009 - val_acc: 0.8880\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 2.5385e-04 - acc: 1.0000 - val_loss: 1.0149 - val_acc: 0.8880\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 4s 4ms/step - loss: 2.0564 - acc: 0.4956 - val_loss: 1.3706 - val_acc: 0.8533\n",
      "\n",
      "kappa improvement: 0.6896834405347458 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 26us/step - loss: 0.2373 - acc: 0.9564 - val_loss: 1.0181 - val_acc: 0.8803\n",
      "\n",
      "kappa improvement: 0.754772303839223 (before: 0.6896834405347458), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 18us/step - loss: 0.0251 - acc: 0.9942 - val_loss: 1.0241 - val_acc: 0.8803\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 21us/step - loss: 0.0244 - acc: 0.9942 - val_loss: 1.0302 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7771084337349398 (before: 0.754772303839223), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 18us/step - loss: 0.0190 - acc: 0.9952 - val_loss: 1.0421 - val_acc: 0.8919\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.9971 - val_loss: 1.0553 - val_acc: 0.8880\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0143 - acc: 0.9971 - val_loss: 1.0642 - val_acc: 0.8842\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0050 - acc: 0.9971 - val_loss: 1.0810 - val_acc: 0.8919\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0050 - acc: 0.9981 - val_loss: 1.0890 - val_acc: 0.8919\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.9990 - val_loss: 1.0990 - val_acc: 0.8919\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 5s 5ms/step - loss: 1.7940 - acc: 0.5761 - val_loss: 4.0784 - val_acc: 0.6988\n",
      "\n",
      "kappa improvement: 0.3171308815575987 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 25us/step - loss: 2.3390 - acc: 0.7934 - val_loss: 1.8185 - val_acc: 0.8301\n",
      "\n",
      "kappa improvement: 0.6350243402510889 (before: 0.3171308815575987), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 19us/step - loss: 0.5648 - acc: 0.9282 - val_loss: 1.3190 - val_acc: 0.8726\n",
      "\n",
      "kappa improvement: 0.7315556393102798 (before: 0.6350243402510889), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 18us/step - loss: 0.1205 - acc: 0.9825 - val_loss: 1.2533 - val_acc: 0.8687\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0522 - acc: 0.9874 - val_loss: 1.1945 - val_acc: 0.8764\n",
      "\n",
      "kappa improvement: 0.7420158127373467 (before: 0.7315556393102798), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 15us/step - loss: 0.0477 - acc: 0.9913 - val_loss: 1.1709 - val_acc: 0.8803\n",
      "\n",
      "kappa improvement: 0.7503963689495445 (before: 0.7420158127373467), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0310 - acc: 0.9922 - val_loss: 1.1502 - val_acc: 0.8842\n",
      "\n",
      "kappa improvement: 0.7593682254567977 (before: 0.7503963689495445), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0214 - acc: 0.9952 - val_loss: 1.1416 - val_acc: 0.8803\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0025 - acc: 0.9990 - val_loss: 1.1482 - val_acc: 0.8842\n",
      "\n",
      "kappa improvement: 0.760584211499353 (before: 0.7593682254567977), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0064 - acc: 0.9981 - val_loss: 1.1580 - val_acc: 0.8842\n",
      "Train on 1031 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 6s 6ms/step - loss: 1.7747 - acc: 0.5500 - val_loss: 1.7280 - val_acc: 0.8340\n",
      "\n",
      "kappa improvement: 0.6465678651899337 (before: -inf), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 0s 31us/step - loss: 0.5577 - acc: 0.9302 - val_loss: 0.9860 - val_acc: 0.8803\n",
      "\n",
      "kappa improvement: 0.7535377720477637 (before: 0.6465678651899337), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 0s 18us/step - loss: 0.0272 - acc: 0.9942 - val_loss: 0.9697 - val_acc: 0.8842\n",
      "\n",
      "kappa improvement: 0.7617879698326078 (before: 0.7535377720477637), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 0s 18us/step - loss: 0.0196 - acc: 0.9952 - val_loss: 0.9759 - val_acc: 0.8842\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 0s 13us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.9904 - val_acc: 0.8842\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0181 - acc: 0.9971 - val_loss: 1.0097 - val_acc: 0.8880\n",
      "\n",
      "kappa improvement: 0.7688567471918757 (before: 0.7617879698326078), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 0s 14us/step - loss: 0.0126 - acc: 0.9961 - val_loss: 1.0242 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7771084337349398 (before: 0.7688567471918757), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 0s 16us/step - loss: 0.0023 - acc: 0.9990 - val_loss: 1.0426 - val_acc: 0.8919\n",
      "\n",
      "kappa improvement: 0.7776687718437673 (before: 0.7771084337349398), saving to Tobacco_exp3_img-text_mlp_model.hdf5\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 0s 17us/step - loss: 0.0054 - acc: 0.9990 - val_loss: 1.0614 - val_acc: 0.8919\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 0s 27us/step - loss: 0.0033 - acc: 0.9971 - val_loss: 1.0744 - val_acc: 0.8919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7828823923738958"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_repeats = 10\n",
    "all_res = []\n",
    "for n_repeat in range(n_repeats):\n",
    "    input_tp = Input(shape=sequence_x_2inputs_train[0][0].shape)\n",
    "    input_pp = Input(shape=sequence_x_2inputs_train[1][0].shape)\n",
    "    # similarity = dot([input_tp, input_pp], axes=1, normalize=True)\n",
    "    difference = subtract([input_pp, input_tp])\n",
    "    final_feat = concatenate([input_tp, input_pp, difference]) \n",
    "    final_feat = Dense(500)(final_feat)\n",
    "    final_feat = LeakyReLU()(final_feat)\n",
    "    final_feat = Dropout(0.75)(final_feat)\n",
    "    model_output = Dense(1, activation = 'sigmoid')(final_feat)\n",
    "    combined_model = Model([input_tp, input_pp], model_output)\n",
    "    # sgd = SGD(lr=0.001, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "    model_path = \"Tobacco_exp3_img-text_mlp_model.hdf5\"\n",
    "    checkpoint = ValidationCheckpoint(model_path, sequence_x_2inputs_test, data_test_y)\n",
    "    combined_model.compile(loss = 'binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    combined_model.fit(sequence_x_2inputs_train, data_train_y, validation_data = (sequence_x_2inputs_test, data_test_y), \n",
    "                       batch_size=4096, epochs=10, callbacks=[checkpoint])\n",
    "    all_res.append(checkpoint.max_metric)\n",
    "np.average(all_res)\n",
    "# avg kappa = 0.7828823923738958"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300_0.1\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 9s 517us/step - loss: 0.4939 - acc: 0.8426 - val_loss: 0.8531 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6804976692600839 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0571 - acc: 0.9904 - val_loss: 0.8879 - val_acc: 0.9286\n",
      "\n",
      "kappa improvement: 0.6936578597444644 (before: 0.6804976692600839), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0478 - acc: 0.9927 - val_loss: 0.9101 - val_acc: 0.9282\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0411 - acc: 0.9938 - val_loss: 0.9280 - val_acc: 0.9270\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0341 - acc: 0.9947 - val_loss: 0.9331 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0281 - acc: 0.9958 - val_loss: 0.9384 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0232 - acc: 0.9963 - val_loss: 0.9414 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0204 - acc: 0.9970 - val_loss: 0.9464 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0168 - acc: 0.9974 - val_loss: 0.9492 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0136 - acc: 0.9977 - val_loss: 0.9490 - val_acc: 0.9223\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 9s 512us/step - loss: 0.2039 - acc: 0.9279 - val_loss: 0.8548 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.687492849424776 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0590 - acc: 0.9906 - val_loss: 0.8701 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6935939338475618 (before: 0.687492849424776), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0427 - acc: 0.9932 - val_loss: 0.8842 - val_acc: 0.9274\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0322 - acc: 0.9950 - val_loss: 0.8922 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0245 - acc: 0.9960 - val_loss: 0.8974 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0188 - acc: 0.9967 - val_loss: 0.8990 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0131 - acc: 0.9975 - val_loss: 0.8953 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0088 - acc: 0.9984 - val_loss: 0.8944 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0068 - acc: 0.9987 - val_loss: 0.9019 - val_acc: 0.9205\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0047 - acc: 0.9990 - val_loss: 0.9047 - val_acc: 0.9203\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 9s 514us/step - loss: 0.6928 - acc: 0.8142 - val_loss: 0.8540 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6609306575635323 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0655 - acc: 0.9885 - val_loss: 0.8808 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6776288038565833 (before: 0.6609306575635323), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0472 - acc: 0.9917 - val_loss: 0.8960 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6859939523272005 (before: 0.6776288038565833), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0389 - acc: 0.9938 - val_loss: 0.9118 - val_acc: 0.9262\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0325 - acc: 0.9948 - val_loss: 0.9202 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0265 - acc: 0.9960 - val_loss: 0.9165 - val_acc: 0.9246\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0230 - acc: 0.9965 - val_loss: 0.9184 - val_acc: 0.9248\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0191 - acc: 0.9964 - val_loss: 0.9200 - val_acc: 0.9242\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0161 - acc: 0.9971 - val_loss: 0.9190 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0121 - acc: 0.9977 - val_loss: 0.9199 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 657us/step - loss: 0.1833 - acc: 0.9406 - val_loss: 0.8287 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6831210282540112 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0491 - acc: 0.9907 - val_loss: 0.8563 - val_acc: 0.9248\n",
      "\n",
      "kappa improvement: 0.6861249060048336 (before: 0.6831210282540112), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0360 - acc: 0.9937 - val_loss: 0.8656 - val_acc: 0.9244\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0255 - acc: 0.9955 - val_loss: 0.8730 - val_acc: 0.9219\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0172 - acc: 0.9965 - val_loss: 0.8791 - val_acc: 0.9215\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0114 - acc: 0.9969 - val_loss: 0.8831 - val_acc: 0.9199\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0085 - acc: 0.9979 - val_loss: 0.8881 - val_acc: 0.9201\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.8852 - val_acc: 0.9193\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.8865 - val_acc: 0.9193\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.8815 - val_acc: 0.9187\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 628us/step - loss: 0.9419 - acc: 0.8726 - val_loss: 0.9168 - val_acc: 0.9215\n",
      "\n",
      "kappa improvement: 0.6685208678962948 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.1026 - acc: 0.9864 - val_loss: 0.9137 - val_acc: 0.9237\n",
      "\n",
      "kappa improvement: 0.6815791270539375 (before: 0.6685208678962948), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0663 - acc: 0.9900 - val_loss: 0.9264 - val_acc: 0.9237\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0507 - acc: 0.9921 - val_loss: 0.9358 - val_acc: 0.9237\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0402 - acc: 0.9938 - val_loss: 0.9399 - val_acc: 0.9233\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0330 - acc: 0.9953 - val_loss: 0.9417 - val_acc: 0.9223\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0257 - acc: 0.9957 - val_loss: 0.9386 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0195 - acc: 0.9964 - val_loss: 0.9357 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0146 - acc: 0.9969 - val_loss: 0.9330 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0112 - acc: 0.9976 - val_loss: 0.9320 - val_acc: 0.9213\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 653us/step - loss: 0.4965 - acc: 0.9142 - val_loss: 0.8675 - val_acc: 0.9217\n",
      "\n",
      "kappa improvement: 0.6778956875141116 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0695 - acc: 0.9890 - val_loss: 0.8796 - val_acc: 0.9233\n",
      "\n",
      "kappa improvement: 0.6803143667531883 (before: 0.6778956875141116), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0498 - acc: 0.9916 - val_loss: 0.8906 - val_acc: 0.9240\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0368 - acc: 0.9935 - val_loss: 0.8978 - val_acc: 0.9233\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0270 - acc: 0.9950 - val_loss: 0.8972 - val_acc: 0.9217\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0188 - acc: 0.9963 - val_loss: 0.8946 - val_acc: 0.9215\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0132 - acc: 0.9972 - val_loss: 0.8864 - val_acc: 0.9201\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.8859 - val_acc: 0.9197\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.8946 - val_acc: 0.9203\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.8874 - val_acc: 0.9203\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 623us/step - loss: 0.3052 - acc: 0.9302 - val_loss: 0.8951 - val_acc: 0.9221\n",
      "\n",
      "kappa improvement: 0.6624490494090358 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0550 - acc: 0.9902 - val_loss: 0.9195 - val_acc: 0.9225\n",
      "\n",
      "kappa improvement: 0.6641495579762446 (before: 0.6624490494090358), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0356 - acc: 0.9933 - val_loss: 0.9273 - val_acc: 0.9219\n",
      "\n",
      "kappa improvement: 0.6662425728722616 (before: 0.6641495579762446), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0251 - acc: 0.9953 - val_loss: 0.9349 - val_acc: 0.9213\n",
      "\n",
      "kappa improvement: 0.6674961246302633 (before: 0.6662425728722616), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0172 - acc: 0.9960 - val_loss: 0.9414 - val_acc: 0.9213\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0116 - acc: 0.9975 - val_loss: 0.9377 - val_acc: 0.9209\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0088 - acc: 0.9979 - val_loss: 0.9410 - val_acc: 0.9193\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.9404 - val_acc: 0.9191\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.9387 - val_acc: 0.9197\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.9341 - val_acc: 0.9199\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 614us/step - loss: 0.3540 - acc: 0.8900 - val_loss: 0.8188 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.693095960026465 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0532 - acc: 0.9902 - val_loss: 0.8534 - val_acc: 0.9268\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0427 - acc: 0.9923 - val_loss: 0.8737 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0323 - acc: 0.9942 - val_loss: 0.8827 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0255 - acc: 0.9955 - val_loss: 0.8865 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0198 - acc: 0.9963 - val_loss: 0.8913 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0148 - acc: 0.9971 - val_loss: 0.8977 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0106 - acc: 0.9974 - val_loss: 0.8913 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.8928 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.8928 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 647us/step - loss: 0.3279 - acc: 0.8789 - val_loss: 0.8394 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6765871240577703 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0528 - acc: 0.9906 - val_loss: 0.8683 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6912351290266499 (before: 0.6765871240577703), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0412 - acc: 0.9931 - val_loss: 0.8887 - val_acc: 0.9274\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0334 - acc: 0.9944 - val_loss: 0.9040 - val_acc: 0.9264\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0265 - acc: 0.9957 - val_loss: 0.9080 - val_acc: 0.9264\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0212 - acc: 0.9963 - val_loss: 0.9070 - val_acc: 0.9258\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0177 - acc: 0.9969 - val_loss: 0.9071 - val_acc: 0.9237\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0134 - acc: 0.9975 - val_loss: 0.9095 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0112 - acc: 0.9979 - val_loss: 0.9103 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.9104 - val_acc: 0.9205\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 694us/step - loss: 0.6593 - acc: 0.7941 - val_loss: 0.8319 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6668517036456826 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 25us/step - loss: 0.0601 - acc: 0.9886 - val_loss: 0.8701 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6785315037478202 (before: 0.6668517036456826), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0486 - acc: 0.9918 - val_loss: 0.8967 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6789190357619418 (before: 0.6785315037478202), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0414 - acc: 0.9932 - val_loss: 0.9073 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6794244509019861 (before: 0.6789190357619418), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0336 - acc: 0.9946 - val_loss: 0.9123 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0268 - acc: 0.9955 - val_loss: 0.9153 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0225 - acc: 0.9960 - val_loss: 0.9160 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0186 - acc: 0.9968 - val_loss: 0.9221 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0158 - acc: 0.9969 - val_loss: 0.9185 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0128 - acc: 0.9975 - val_loss: 0.9163 - val_acc: 0.9221\n",
      "300_0.2\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 623us/step - loss: 0.8117 - acc: 0.7989 - val_loss: 0.8270 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6797554903042891 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0558 - acc: 0.9903 - val_loss: 0.8826 - val_acc: 0.9248\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0477 - acc: 0.9920 - val_loss: 0.8907 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6842111787383323 (before: 0.6797554903042891), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0376 - acc: 0.9932 - val_loss: 0.9003 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0314 - acc: 0.9945 - val_loss: 0.9193 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0250 - acc: 0.9953 - val_loss: 0.9217 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0194 - acc: 0.9965 - val_loss: 0.9202 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0174 - acc: 0.9967 - val_loss: 0.9312 - val_acc: 0.9231\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0137 - acc: 0.9972 - val_loss: 0.9252 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.9303 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 633us/step - loss: 1.2621 - acc: 0.7681 - val_loss: 0.8342 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.6637006939176129 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0662 - acc: 0.9879 - val_loss: 0.8664 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6880499796188305 (before: 0.6637006939176129), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0541 - acc: 0.9911 - val_loss: 0.8898 - val_acc: 0.9262\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0454 - acc: 0.9930 - val_loss: 0.9041 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0399 - acc: 0.9938 - val_loss: 0.9105 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0352 - acc: 0.9945 - val_loss: 0.9130 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0284 - acc: 0.9952 - val_loss: 0.9124 - val_acc: 0.9250\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0243 - acc: 0.9956 - val_loss: 0.9128 - val_acc: 0.9242\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0213 - acc: 0.9963 - val_loss: 0.9121 - val_acc: 0.9240\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0185 - acc: 0.9968 - val_loss: 0.9111 - val_acc: 0.9238\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 615us/step - loss: 0.8569 - acc: 0.7894 - val_loss: 0.8248 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.685010373879663 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0592 - acc: 0.9886 - val_loss: 0.8627 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6902914625987991 (before: 0.685010373879663), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0463 - acc: 0.9915 - val_loss: 0.8871 - val_acc: 0.9264\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0394 - acc: 0.9936 - val_loss: 0.9009 - val_acc: 0.9244\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0326 - acc: 0.9945 - val_loss: 0.9059 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0259 - acc: 0.9956 - val_loss: 0.9095 - val_acc: 0.9256\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0217 - acc: 0.9965 - val_loss: 0.9134 - val_acc: 0.9246\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0184 - acc: 0.9969 - val_loss: 0.9124 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0143 - acc: 0.9975 - val_loss: 0.9196 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.9137 - val_acc: 0.9223\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 629us/step - loss: 0.3565 - acc: 0.9205 - val_loss: 0.8703 - val_acc: 0.9227\n",
      "\n",
      "kappa improvement: 0.6647970344148146 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0556 - acc: 0.9899 - val_loss: 0.8954 - val_acc: 0.9237\n",
      "\n",
      "kappa improvement: 0.6763005638737021 (before: 0.6647970344148146), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0402 - acc: 0.9927 - val_loss: 0.9103 - val_acc: 0.9240\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0313 - acc: 0.9946 - val_loss: 0.9179 - val_acc: 0.9240\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0226 - acc: 0.9958 - val_loss: 0.9212 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0174 - acc: 0.9968 - val_loss: 0.9206 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0125 - acc: 0.9974 - val_loss: 0.9227 - val_acc: 0.9211\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0090 - acc: 0.9978 - val_loss: 0.9268 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.9263 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.9335 - val_acc: 0.9205\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 631us/step - loss: 0.3961 - acc: 0.8638 - val_loss: 0.8394 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6925791932892655 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0567 - acc: 0.9897 - val_loss: 0.8738 - val_acc: 0.9272\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0446 - acc: 0.9925 - val_loss: 0.8957 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0339 - acc: 0.9946 - val_loss: 0.9105 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0277 - acc: 0.9957 - val_loss: 0.9212 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0218 - acc: 0.9960 - val_loss: 0.9216 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0170 - acc: 0.9970 - val_loss: 0.9277 - val_acc: 0.9237\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0139 - acc: 0.9974 - val_loss: 0.9300 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0114 - acc: 0.9977 - val_loss: 0.9334 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.9343 - val_acc: 0.9213\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 635us/step - loss: 0.1893 - acc: 0.9521 - val_loss: 0.8490 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6873994033648292 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0611 - acc: 0.9894 - val_loss: 0.8613 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6902091300382418 (before: 0.6873994033648292), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0404 - acc: 0.9935 - val_loss: 0.8652 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6928661523088768 (before: 0.6902091300382418), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0273 - acc: 0.9952 - val_loss: 0.8654 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0177 - acc: 0.9969 - val_loss: 0.8655 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0129 - acc: 0.9971 - val_loss: 0.8636 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.9982 - val_loss: 0.8658 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0072 - acc: 0.9984 - val_loss: 0.8567 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.8814 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.8793 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 640us/step - loss: 0.3492 - acc: 0.8998 - val_loss: 0.8613 - val_acc: 0.9248\n",
      "\n",
      "kappa improvement: 0.6759209974548791 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0699 - acc: 0.9884 - val_loss: 0.8851 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6894402845606931 (before: 0.6759209974548791), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0519 - acc: 0.9915 - val_loss: 0.9026 - val_acc: 0.9252\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0416 - acc: 0.9932 - val_loss: 0.9097 - val_acc: 0.9246\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0323 - acc: 0.9948 - val_loss: 0.9108 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0226 - acc: 0.9960 - val_loss: 0.9104 - val_acc: 0.9225\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0166 - acc: 0.9966 - val_loss: 0.9114 - val_acc: 0.9213\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0126 - acc: 0.9974 - val_loss: 0.9116 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0105 - acc: 0.9978 - val_loss: 0.9123 - val_acc: 0.9203\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0086 - acc: 0.9983 - val_loss: 0.9118 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 607us/step - loss: 0.3573 - acc: 0.8808 - val_loss: 0.8627 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6755284151136225 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0602 - acc: 0.9900 - val_loss: 0.8949 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.685140805109492 (before: 0.6755284151136225), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0461 - acc: 0.9925 - val_loss: 0.9136 - val_acc: 0.9254\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0358 - acc: 0.9942 - val_loss: 0.9239 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0283 - acc: 0.9951 - val_loss: 0.9303 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0227 - acc: 0.9963 - val_loss: 0.9337 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0185 - acc: 0.9965 - val_loss: 0.9396 - val_acc: 0.9221\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0151 - acc: 0.9972 - val_loss: 0.9408 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0117 - acc: 0.9980 - val_loss: 0.9446 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0108 - acc: 0.9982 - val_loss: 0.9469 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 647us/step - loss: 0.3137 - acc: 0.9292 - val_loss: 0.8747 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6842111787383323 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0607 - acc: 0.9905 - val_loss: 0.8941 - val_acc: 0.9246\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0454 - acc: 0.9929 - val_loss: 0.9053 - val_acc: 0.9246\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0341 - acc: 0.9944 - val_loss: 0.9085 - val_acc: 0.9237\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0236 - acc: 0.9958 - val_loss: 0.9129 - val_acc: 0.9225\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0174 - acc: 0.9964 - val_loss: 0.9131 - val_acc: 0.9219\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0131 - acc: 0.9976 - val_loss: 0.9155 - val_acc: 0.9211\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.9165 - val_acc: 0.9207\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.9228 - val_acc: 0.9205\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.9249 - val_acc: 0.9191\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 611us/step - loss: 0.2936 - acc: 0.9266 - val_loss: 0.8703 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6828509181450357 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0653 - acc: 0.9898 - val_loss: 0.8912 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6881325523719064 (before: 0.6828509181450357), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0452 - acc: 0.9927 - val_loss: 0.9013 - val_acc: 0.9248\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0333 - acc: 0.9945 - val_loss: 0.9051 - val_acc: 0.9240\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0252 - acc: 0.9957 - val_loss: 0.9068 - val_acc: 0.9242\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0185 - acc: 0.9967 - val_loss: 0.9089 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0145 - acc: 0.9974 - val_loss: 0.9070 - val_acc: 0.9215\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0106 - acc: 0.9980 - val_loss: 0.9068 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.9055 - val_acc: 0.9203\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0061 - acc: 0.9986 - val_loss: 0.9042 - val_acc: 0.9197\n",
      "300_0.3\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 613us/step - loss: 0.3106 - acc: 0.9266 - val_loss: 0.8718 - val_acc: 0.9225\n",
      "\n",
      "kappa improvement: 0.6800221000624049 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0716 - acc: 0.9890 - val_loss: 0.8817 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.687762890331207 (before: 0.6800221000624049), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0488 - acc: 0.9922 - val_loss: 0.8885 - val_acc: 0.9274\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0397 - acc: 0.9938 - val_loss: 0.8872 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0265 - acc: 0.9957 - val_loss: 0.8857 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0209 - acc: 0.9964 - val_loss: 0.8856 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0152 - acc: 0.9970 - val_loss: 0.8864 - val_acc: 0.9231\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0116 - acc: 0.9975 - val_loss: 0.8808 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0089 - acc: 0.9982 - val_loss: 0.9001 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.8821 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 629us/step - loss: 1.2348 - acc: 0.7989 - val_loss: 0.8327 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.685010373879663 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0546 - acc: 0.9903 - val_loss: 0.8718 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6896357040564913 (before: 0.685010373879663), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0453 - acc: 0.9925 - val_loss: 0.8973 - val_acc: 0.9272\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0345 - acc: 0.9941 - val_loss: 0.9144 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0304 - acc: 0.9951 - val_loss: 0.9304 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0250 - acc: 0.9963 - val_loss: 0.9258 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0231 - acc: 0.9967 - val_loss: 0.9304 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0178 - acc: 0.9972 - val_loss: 0.9346 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0153 - acc: 0.9972 - val_loss: 0.9328 - val_acc: 0.9248\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0152 - acc: 0.9974 - val_loss: 0.9330 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 698us/step - loss: 0.2800 - acc: 0.9175 - val_loss: 0.8603 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6891427458743733 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0680 - acc: 0.9894 - val_loss: 0.8805 - val_acc: 0.9266\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0470 - acc: 0.9920 - val_loss: 0.8917 - val_acc: 0.9266\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0357 - acc: 0.9942 - val_loss: 0.8975 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0264 - acc: 0.9955 - val_loss: 0.8979 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0205 - acc: 0.9962 - val_loss: 0.8996 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0173 - acc: 0.9968 - val_loss: 0.8966 - val_acc: 0.9227\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 0.9980 - val_loss: 0.8936 - val_acc: 0.9231\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0094 - acc: 0.9982 - val_loss: 0.8939 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.8902 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 679us/step - loss: 0.4365 - acc: 0.8816 - val_loss: 0.8604 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6626175118369588 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0629 - acc: 0.9896 - val_loss: 0.8880 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6856964703632729 (before: 0.6626175118369588), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0477 - acc: 0.9922 - val_loss: 0.9070 - val_acc: 0.9262\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0376 - acc: 0.9942 - val_loss: 0.9148 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0296 - acc: 0.9951 - val_loss: 0.9223 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0236 - acc: 0.9962 - val_loss: 0.9264 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0194 - acc: 0.9968 - val_loss: 0.9282 - val_acc: 0.9227\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0145 - acc: 0.9975 - val_loss: 0.9287 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0109 - acc: 0.9980 - val_loss: 0.9315 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0093 - acc: 0.9984 - val_loss: 0.9320 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 614us/step - loss: 0.5311 - acc: 0.9052 - val_loss: 0.8432 - val_acc: 0.9238\n",
      "\n",
      "kappa improvement: 0.6761740953691417 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0591 - acc: 0.9893 - val_loss: 0.8694 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6806502950321964 (before: 0.6761740953691417), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0456 - acc: 0.9916 - val_loss: 0.8764 - val_acc: 0.9248\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0341 - acc: 0.9939 - val_loss: 0.8812 - val_acc: 0.9231\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0252 - acc: 0.9954 - val_loss: 0.8832 - val_acc: 0.9227\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0196 - acc: 0.9964 - val_loss: 0.8806 - val_acc: 0.9209\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0153 - acc: 0.9965 - val_loss: 0.8821 - val_acc: 0.9205\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.8851 - val_acc: 0.9201\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.8818 - val_acc: 0.9197\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0066 - acc: 0.9986 - val_loss: 0.8778 - val_acc: 0.9197\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 633us/step - loss: 0.3891 - acc: 0.9288 - val_loss: 0.8705 - val_acc: 0.9235\n",
      "\n",
      "kappa improvement: 0.6677979419705924 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0639 - acc: 0.9896 - val_loss: 0.8879 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.683602431690417 (before: 0.6677979419705924), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0442 - acc: 0.9930 - val_loss: 0.8947 - val_acc: 0.9238\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0308 - acc: 0.9945 - val_loss: 0.8945 - val_acc: 0.9237\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0214 - acc: 0.9955 - val_loss: 0.8882 - val_acc: 0.9215\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0156 - acc: 0.9968 - val_loss: 0.8877 - val_acc: 0.9221\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0099 - acc: 0.9974 - val_loss: 0.8842 - val_acc: 0.9207\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.8871 - val_acc: 0.9207\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.8875 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.8953 - val_acc: 0.9193\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 666us/step - loss: 0.5121 - acc: 0.8543 - val_loss: 0.8372 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6759253088580792 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0635 - acc: 0.9890 - val_loss: 0.8692 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6929432084046172 (before: 0.6759253088580792), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0450 - acc: 0.9925 - val_loss: 0.8879 - val_acc: 0.9272\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0394 - acc: 0.9934 - val_loss: 0.8971 - val_acc: 0.9264\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0337 - acc: 0.9941 - val_loss: 0.9033 - val_acc: 0.9262\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0271 - acc: 0.9956 - val_loss: 0.9066 - val_acc: 0.9254\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0225 - acc: 0.9961 - val_loss: 0.9099 - val_acc: 0.9254\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0179 - acc: 0.9965 - val_loss: 0.9103 - val_acc: 0.9240\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0155 - acc: 0.9971 - val_loss: 0.9116 - val_acc: 0.9233\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0134 - acc: 0.9975 - val_loss: 0.9125 - val_acc: 0.9233\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 622us/step - loss: 0.8945 - acc: 0.8045 - val_loss: 0.8761 - val_acc: 0.9223\n",
      "\n",
      "kappa improvement: 0.6534460103573545 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0663 - acc: 0.9881 - val_loss: 0.9008 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.6713492205697904 (before: 0.6534460103573545), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0489 - acc: 0.9914 - val_loss: 0.9170 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.6769514539922514 (before: 0.6713492205697904), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0388 - acc: 0.9930 - val_loss: 0.9231 - val_acc: 0.9233\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0330 - acc: 0.9946 - val_loss: 0.9322 - val_acc: 0.9233\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0268 - acc: 0.9951 - val_loss: 0.9318 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0232 - acc: 0.9956 - val_loss: 0.9295 - val_acc: 0.9227\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0174 - acc: 0.9966 - val_loss: 0.9307 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0153 - acc: 0.9967 - val_loss: 0.9289 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0113 - acc: 0.9976 - val_loss: 0.9270 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 602us/step - loss: 0.4449 - acc: 0.8831 - val_loss: 0.8621 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6843466544662382 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0662 - acc: 0.9885 - val_loss: 0.8917 - val_acc: 0.9280\n",
      "\n",
      "kappa improvement: 0.6909480069252478 (before: 0.6843466544662382), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0511 - acc: 0.9915 - val_loss: 0.9096 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0416 - acc: 0.9937 - val_loss: 0.9169 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0326 - acc: 0.9948 - val_loss: 0.9187 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0259 - acc: 0.9959 - val_loss: 0.9228 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0204 - acc: 0.9967 - val_loss: 0.9250 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0170 - acc: 0.9968 - val_loss: 0.9279 - val_acc: 0.9223\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0154 - acc: 0.9975 - val_loss: 0.9342 - val_acc: 0.9195\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0125 - acc: 0.9977 - val_loss: 0.9306 - val_acc: 0.9205\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 584us/step - loss: 0.2937 - acc: 0.9093 - val_loss: 0.8677 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6900067190726855 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0595 - acc: 0.9903 - val_loss: 0.8970 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6912789439515257 (before: 0.6900067190726855), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0452 - acc: 0.9929 - val_loss: 0.9134 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0343 - acc: 0.9947 - val_loss: 0.9231 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0279 - acc: 0.9956 - val_loss: 0.9280 - val_acc: 0.9235\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0220 - acc: 0.9966 - val_loss: 0.9333 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0180 - acc: 0.9969 - val_loss: 0.9389 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0131 - acc: 0.9975 - val_loss: 0.9378 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0097 - acc: 0.9979 - val_loss: 0.9408 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.9425 - val_acc: 0.9217\n",
      "300_0.4\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 582us/step - loss: 0.9791 - acc: 0.7940 - val_loss: 0.8328 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6809249379834874 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0523 - acc: 0.9902 - val_loss: 0.8733 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6938080851203573 (before: 0.6809249379834874), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0505 - acc: 0.9912 - val_loss: 0.8937 - val_acc: 0.9280\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0386 - acc: 0.9937 - val_loss: 0.9048 - val_acc: 0.9270\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0364 - acc: 0.9940 - val_loss: 0.9127 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0285 - acc: 0.9952 - val_loss: 0.9195 - val_acc: 0.9246\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0245 - acc: 0.9959 - val_loss: 0.9246 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0216 - acc: 0.9965 - val_loss: 0.9269 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0172 - acc: 0.9968 - val_loss: 0.9255 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0140 - acc: 0.9972 - val_loss: 0.9256 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 572us/step - loss: 0.4665 - acc: 0.8648 - val_loss: 0.8507 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6770987082947657 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0594 - acc: 0.9895 - val_loss: 0.8781 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6897229948812482 (before: 0.6770987082947657), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0464 - acc: 0.9922 - val_loss: 0.9154 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0377 - acc: 0.9939 - val_loss: 0.9179 - val_acc: 0.9238\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0275 - acc: 0.9949 - val_loss: 0.9217 - val_acc: 0.9229\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0222 - acc: 0.9957 - val_loss: 0.9245 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0175 - acc: 0.9968 - val_loss: 0.9290 - val_acc: 0.9217\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0156 - acc: 0.9971 - val_loss: 0.9231 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0121 - acc: 0.9972 - val_loss: 0.9272 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.9221 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 587us/step - loss: 0.2821 - acc: 0.9305 - val_loss: 0.8629 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6881325523719064 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0648 - acc: 0.9898 - val_loss: 0.8841 - val_acc: 0.9266\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0478 - acc: 0.9915 - val_loss: 0.8935 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6887885455321665 (before: 0.6881325523719064), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0328 - acc: 0.9945 - val_loss: 0.8940 - val_acc: 0.9244\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0255 - acc: 0.9953 - val_loss: 0.8940 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0204 - acc: 0.9962 - val_loss: 0.8913 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0135 - acc: 0.9973 - val_loss: 0.8907 - val_acc: 0.9219\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0104 - acc: 0.9979 - val_loss: 0.8973 - val_acc: 0.9223\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0076 - acc: 0.9982 - val_loss: 0.9042 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.8919 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 569us/step - loss: 0.4792 - acc: 0.9092 - val_loss: 0.8719 - val_acc: 0.9237\n",
      "\n",
      "kappa improvement: 0.67242172941123 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0772 - acc: 0.9880 - val_loss: 0.8847 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6845858994098024 (before: 0.67242172941123), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0533 - acc: 0.9915 - val_loss: 0.8907 - val_acc: 0.9252\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0387 - acc: 0.9934 - val_loss: 0.8897 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0283 - acc: 0.9947 - val_loss: 0.8823 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0219 - acc: 0.9957 - val_loss: 0.8775 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0175 - acc: 0.9967 - val_loss: 0.8736 - val_acc: 0.9215\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0120 - acc: 0.9977 - val_loss: 0.8709 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0099 - acc: 0.9982 - val_loss: 0.8732 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.8669 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 605us/step - loss: 0.2658 - acc: 0.9215 - val_loss: 0.8494 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6865845941897812 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0635 - acc: 0.9894 - val_loss: 0.8703 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.689488709263536 (before: 0.6865845941897812), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0470 - acc: 0.9923 - val_loss: 0.8811 - val_acc: 0.9248\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0355 - acc: 0.9940 - val_loss: 0.8863 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0288 - acc: 0.9953 - val_loss: 0.8827 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0203 - acc: 0.9963 - val_loss: 0.8875 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0147 - acc: 0.9968 - val_loss: 0.8878 - val_acc: 0.9211\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0119 - acc: 0.9972 - val_loss: 0.8840 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0086 - acc: 0.9983 - val_loss: 0.8850 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.8877 - val_acc: 0.9195\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 605us/step - loss: 0.2811 - acc: 0.9140 - val_loss: 0.8581 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6845891301387106 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0539 - acc: 0.9898 - val_loss: 0.8860 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6895277409209297 (before: 0.6845891301387106), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0409 - acc: 0.9927 - val_loss: 0.9063 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0300 - acc: 0.9949 - val_loss: 0.9174 - val_acc: 0.9246\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0238 - acc: 0.9959 - val_loss: 0.9169 - val_acc: 0.9233\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0168 - acc: 0.9968 - val_loss: 0.9293 - val_acc: 0.9225\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0132 - acc: 0.9973 - val_loss: 0.9310 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.9283 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0079 - acc: 0.9984 - val_loss: 0.9282 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0076 - acc: 0.9984 - val_loss: 0.9228 - val_acc: 0.9213\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 595us/step - loss: 1.0908 - acc: 0.7903 - val_loss: 0.7927 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.6706199917074946 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0524 - acc: 0.9903 - val_loss: 0.8407 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6785315037478202 (before: 0.6706199917074946), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9913 - val_loss: 0.8630 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6842111787383323 (before: 0.6785315037478202), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0364 - acc: 0.9933 - val_loss: 0.8792 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0304 - acc: 0.9947 - val_loss: 0.8921 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0261 - acc: 0.9956 - val_loss: 0.8926 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0202 - acc: 0.9958 - val_loss: 0.8907 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0185 - acc: 0.9965 - val_loss: 0.8930 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0129 - acc: 0.9971 - val_loss: 0.9057 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0115 - acc: 0.9974 - val_loss: 0.9016 - val_acc: 0.9213\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 620us/step - loss: 0.2795 - acc: 0.9134 - val_loss: 0.8286 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6970538303454663 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0526 - acc: 0.9908 - val_loss: 0.8597 - val_acc: 0.9272\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0428 - acc: 0.9928 - val_loss: 0.8728 - val_acc: 0.9266\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0308 - acc: 0.9945 - val_loss: 0.8798 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0198 - acc: 0.9961 - val_loss: 0.8852 - val_acc: 0.9225\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0165 - acc: 0.9971 - val_loss: 0.8922 - val_acc: 0.9223\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0143 - acc: 0.9975 - val_loss: 0.8969 - val_acc: 0.9199\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 0.9976 - val_loss: 0.8986 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.8937 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0062 - acc: 0.9985 - val_loss: 0.8937 - val_acc: 0.9199\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 625us/step - loss: 0.8088 - acc: 0.8018 - val_loss: 0.8151 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6757934996911465 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0568 - acc: 0.9894 - val_loss: 0.8532 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6868290581652052 (before: 0.6757934996911465), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0495 - acc: 0.9913 - val_loss: 0.8757 - val_acc: 0.9262\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0405 - acc: 0.9928 - val_loss: 0.8888 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0324 - acc: 0.9941 - val_loss: 0.8971 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0280 - acc: 0.9949 - val_loss: 0.8999 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0217 - acc: 0.9963 - val_loss: 0.9036 - val_acc: 0.9242\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0183 - acc: 0.9964 - val_loss: 0.9045 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0153 - acc: 0.9974 - val_loss: 0.9030 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0129 - acc: 0.9973 - val_loss: 0.9052 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 602us/step - loss: 0.4870 - acc: 0.8667 - val_loss: 0.8480 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6854181362500933 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0624 - acc: 0.9892 - val_loss: 0.8827 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6875804809850259 (before: 0.6854181362500933), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0513 - acc: 0.9918 - val_loss: 0.9002 - val_acc: 0.9238\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0438 - acc: 0.9932 - val_loss: 0.9070 - val_acc: 0.9264\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0348 - acc: 0.9940 - val_loss: 0.9100 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0280 - acc: 0.9953 - val_loss: 0.9132 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0221 - acc: 0.9963 - val_loss: 0.9124 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0172 - acc: 0.9968 - val_loss: 0.9139 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0140 - acc: 0.9970 - val_loss: 0.9111 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0102 - acc: 0.9976 - val_loss: 0.9127 - val_acc: 0.9211\n",
      "300_0.5\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 594us/step - loss: 0.6137 - acc: 0.8570 - val_loss: 0.8423 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6642876651531187 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0591 - acc: 0.9892 - val_loss: 0.8791 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6723963885927505 (before: 0.6642876651531187), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0449 - acc: 0.9921 - val_loss: 0.9042 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.6750112867752129 (before: 0.6723963885927505), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0408 - acc: 0.9935 - val_loss: 0.9120 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0316 - acc: 0.9940 - val_loss: 0.9207 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0269 - acc: 0.9955 - val_loss: 0.9281 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0225 - acc: 0.9965 - val_loss: 0.9312 - val_acc: 0.9217\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0194 - acc: 0.9967 - val_loss: 0.9320 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0157 - acc: 0.9970 - val_loss: 0.9317 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0132 - acc: 0.9977 - val_loss: 0.9264 - val_acc: 0.9205\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 611us/step - loss: 0.5118 - acc: 0.8711 - val_loss: 0.8396 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6900928003682423 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0687 - acc: 0.9879 - val_loss: 0.8725 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.692500963517536 (before: 0.6900928003682423), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0540 - acc: 0.9914 - val_loss: 0.8903 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0426 - acc: 0.9929 - val_loss: 0.9005 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0347 - acc: 0.9945 - val_loss: 0.9052 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0273 - acc: 0.9951 - val_loss: 0.9032 - val_acc: 0.9221\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0236 - acc: 0.9960 - val_loss: 0.9068 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0170 - acc: 0.9969 - val_loss: 0.9030 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 0.9974 - val_loss: 0.9084 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0102 - acc: 0.9979 - val_loss: 0.9105 - val_acc: 0.9201\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 588us/step - loss: 0.3231 - acc: 0.9294 - val_loss: 0.8661 - val_acc: 0.9217\n",
      "\n",
      "kappa improvement: 0.6804650998298511 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0690 - acc: 0.9894 - val_loss: 0.8704 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.6834374288409616 (before: 0.6804650998298511), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0473 - acc: 0.9912 - val_loss: 0.8749 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6895080187035552 (before: 0.6834374288409616), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0366 - acc: 0.9934 - val_loss: 0.8755 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0265 - acc: 0.9952 - val_loss: 0.8735 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0187 - acc: 0.9963 - val_loss: 0.8716 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0121 - acc: 0.9972 - val_loss: 0.8720 - val_acc: 0.9217\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0119 - acc: 0.9972 - val_loss: 0.8693 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.8796 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.8761 - val_acc: 0.9213\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 605us/step - loss: 0.4581 - acc: 0.8890 - val_loss: 0.8354 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6882349049894984 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0596 - acc: 0.9888 - val_loss: 0.8685 - val_acc: 0.9246\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0459 - acc: 0.9918 - val_loss: 0.8841 - val_acc: 0.9244\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0358 - acc: 0.9937 - val_loss: 0.8909 - val_acc: 0.9246\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0266 - acc: 0.9948 - val_loss: 0.8939 - val_acc: 0.9242\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0223 - acc: 0.9959 - val_loss: 0.8938 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0155 - acc: 0.9967 - val_loss: 0.8928 - val_acc: 0.9221\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0144 - acc: 0.9969 - val_loss: 0.8908 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0130 - acc: 0.9973 - val_loss: 0.8904 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.8912 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 598us/step - loss: 0.2843 - acc: 0.9228 - val_loss: 0.8180 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6808835287846482 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0572 - acc: 0.9898 - val_loss: 0.8476 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6830143028786806 (before: 0.6808835287846482), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0375 - acc: 0.9928 - val_loss: 0.8597 - val_acc: 0.9246\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0313 - acc: 0.9945 - val_loss: 0.8667 - val_acc: 0.9229\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0215 - acc: 0.9957 - val_loss: 0.8769 - val_acc: 0.9237\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0165 - acc: 0.9966 - val_loss: 0.8762 - val_acc: 0.9209\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0116 - acc: 0.9970 - val_loss: 0.8761 - val_acc: 0.9205\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0080 - acc: 0.9979 - val_loss: 0.8805 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.8846 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.8751 - val_acc: 0.9193\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 597us/step - loss: 0.6881 - acc: 0.8440 - val_loss: 0.8591 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6684887405323889 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0638 - acc: 0.9888 - val_loss: 0.8901 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6861734098303653 (before: 0.6684887405323889), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0501 - acc: 0.9913 - val_loss: 0.9115 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0437 - acc: 0.9928 - val_loss: 0.9212 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0361 - acc: 0.9947 - val_loss: 0.9235 - val_acc: 0.9258\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0290 - acc: 0.9955 - val_loss: 0.9260 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0228 - acc: 0.9963 - val_loss: 0.9259 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0213 - acc: 0.9961 - val_loss: 0.9271 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0180 - acc: 0.9966 - val_loss: 0.9266 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0136 - acc: 0.9975 - val_loss: 0.9285 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 10s 592us/step - loss: 0.8829 - acc: 0.8151 - val_loss: 0.8290 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.6661137034241404 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0717 - acc: 0.9872 - val_loss: 0.8673 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6833457965667946 (before: 0.6661137034241404), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0543 - acc: 0.9903 - val_loss: 0.8922 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6866463583038258 (before: 0.6833457965667946), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0440 - acc: 0.9927 - val_loss: 0.9087 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0347 - acc: 0.9940 - val_loss: 0.9120 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0295 - acc: 0.9952 - val_loss: 0.9192 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0230 - acc: 0.9960 - val_loss: 0.9212 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0203 - acc: 0.9962 - val_loss: 0.9239 - val_acc: 0.9205\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0165 - acc: 0.9967 - val_loss: 0.9190 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0113 - acc: 0.9971 - val_loss: 0.9235 - val_acc: 0.9185\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 621us/step - loss: 0.4872 - acc: 0.8730 - val_loss: 0.8521 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.679305634557178 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0608 - acc: 0.9896 - val_loss: 0.8874 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6916053384490713 (before: 0.679305634557178), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0488 - acc: 0.9921 - val_loss: 0.9077 - val_acc: 0.9272\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0406 - acc: 0.9936 - val_loss: 0.9197 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0330 - acc: 0.9948 - val_loss: 0.9238 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0264 - acc: 0.9953 - val_loss: 0.9299 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0222 - acc: 0.9964 - val_loss: 0.9322 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0159 - acc: 0.9972 - val_loss: 0.9294 - val_acc: 0.9223\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0142 - acc: 0.9973 - val_loss: 0.9344 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0117 - acc: 0.9974 - val_loss: 0.9355 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 616us/step - loss: 1.3901 - acc: 0.7907 - val_loss: 0.8242 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6575509346775887 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0729 - acc: 0.9862 - val_loss: 0.8519 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6703219983993733 (before: 0.6575509346775887), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0521 - acc: 0.9914 - val_loss: 0.8785 - val_acc: 0.9242\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0447 - acc: 0.9926 - val_loss: 0.8900 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0365 - acc: 0.9934 - val_loss: 0.9020 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6705125506277418 (before: 0.6703219983993733), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0301 - acc: 0.9946 - val_loss: 0.9007 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0250 - acc: 0.9957 - val_loss: 0.8983 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0193 - acc: 0.9965 - val_loss: 0.8983 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0158 - acc: 0.9967 - val_loss: 0.8973 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0116 - acc: 0.9976 - val_loss: 0.9000 - val_acc: 0.9227\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 610us/step - loss: 0.5114 - acc: 0.8719 - val_loss: 0.8550 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6863545990732807 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0632 - acc: 0.9890 - val_loss: 0.8913 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6884096158225171 (before: 0.6863545990732807), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0566 - acc: 0.9915 - val_loss: 0.9090 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6933818028040728 (before: 0.6884096158225171), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0459 - acc: 0.9930 - val_loss: 0.9147 - val_acc: 0.9266\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0344 - acc: 0.9941 - val_loss: 0.9176 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0283 - acc: 0.9952 - val_loss: 0.9186 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0239 - acc: 0.9955 - val_loss: 0.9184 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0184 - acc: 0.9963 - val_loss: 0.9206 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0122 - acc: 0.9973 - val_loss: 0.9210 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0122 - acc: 0.9974 - val_loss: 0.9197 - val_acc: 0.9213\n",
      "300_0.6\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 629us/step - loss: 0.7772 - acc: 0.8427 - val_loss: 0.8364 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6871094365928347 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0618 - acc: 0.9888 - val_loss: 0.8737 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6892467184197725 (before: 0.6871094365928347), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0560 - acc: 0.9903 - val_loss: 0.8927 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0474 - acc: 0.9929 - val_loss: 0.9034 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0369 - acc: 0.9938 - val_loss: 0.9097 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0301 - acc: 0.9950 - val_loss: 0.9108 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0249 - acc: 0.9955 - val_loss: 0.9128 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0196 - acc: 0.9963 - val_loss: 0.9123 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0173 - acc: 0.9969 - val_loss: 0.9103 - val_acc: 0.9227\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0136 - acc: 0.9973 - val_loss: 0.9121 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 625us/step - loss: 0.8896 - acc: 0.8276 - val_loss: 0.8359 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6796040799386248 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0649 - acc: 0.9891 - val_loss: 0.8764 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6880458218806064 (before: 0.6796040799386248), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0541 - acc: 0.9908 - val_loss: 0.8994 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6896146794984341 (before: 0.6880458218806064), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0477 - acc: 0.9922 - val_loss: 0.9084 - val_acc: 0.9264\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0376 - acc: 0.9937 - val_loss: 0.9140 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0311 - acc: 0.9948 - val_loss: 0.9173 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0262 - acc: 0.9956 - val_loss: 0.9183 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0217 - acc: 0.9959 - val_loss: 0.9153 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0188 - acc: 0.9963 - val_loss: 0.9182 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0164 - acc: 0.9970 - val_loss: 0.9176 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 630us/step - loss: 1.6144 - acc: 0.7920 - val_loss: 0.8232 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6823603348444347 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0545 - acc: 0.9900 - val_loss: 0.8636 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6899201217192849 (before: 0.6823603348444347), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0501 - acc: 0.9917 - val_loss: 0.8874 - val_acc: 0.9266\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0410 - acc: 0.9933 - val_loss: 0.9005 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0346 - acc: 0.9941 - val_loss: 0.9047 - val_acc: 0.9258\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0270 - acc: 0.9951 - val_loss: 0.9087 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0201 - acc: 0.9963 - val_loss: 0.9161 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0203 - acc: 0.9964 - val_loss: 0.9187 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0157 - acc: 0.9970 - val_loss: 0.9159 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0147 - acc: 0.9973 - val_loss: 0.9161 - val_acc: 0.9227\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 656us/step - loss: 0.5179 - acc: 0.8865 - val_loss: 0.8574 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6708765147950815 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 23us/step - loss: 0.0663 - acc: 0.9890 - val_loss: 0.8865 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6812684574366312 (before: 0.6708765147950815), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0493 - acc: 0.9922 - val_loss: 0.9038 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0375 - acc: 0.9937 - val_loss: 0.9119 - val_acc: 0.9235\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0324 - acc: 0.9942 - val_loss: 0.9108 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0251 - acc: 0.9955 - val_loss: 0.9143 - val_acc: 0.9223\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0211 - acc: 0.9965 - val_loss: 0.9145 - val_acc: 0.9217\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0148 - acc: 0.9974 - val_loss: 0.9165 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0124 - acc: 0.9972 - val_loss: 0.9208 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.9196 - val_acc: 0.9193\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 630us/step - loss: 0.9873 - acc: 0.8235 - val_loss: 0.8574 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.668586851022528 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0708 - acc: 0.9884 - val_loss: 0.8878 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.68400211171294 (before: 0.668586851022528), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0560 - acc: 0.9910 - val_loss: 0.9094 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6849661779193958 (before: 0.68400211171294), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0493 - acc: 0.9926 - val_loss: 0.9184 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0405 - acc: 0.9937 - val_loss: 0.9235 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0322 - acc: 0.9946 - val_loss: 0.9270 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0286 - acc: 0.9955 - val_loss: 0.9293 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0240 - acc: 0.9961 - val_loss: 0.9339 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0178 - acc: 0.9965 - val_loss: 0.9371 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0178 - acc: 0.9966 - val_loss: 0.9293 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 621us/step - loss: 2.1333 - acc: 0.7846 - val_loss: 0.8164 - val_acc: 0.9238\n",
      "\n",
      "kappa improvement: 0.6633814088919918 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0568 - acc: 0.9896 - val_loss: 0.8553 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6774886727078892 (before: 0.6633814088919918), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0447 - acc: 0.9917 - val_loss: 0.8818 - val_acc: 0.9248\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0377 - acc: 0.9936 - val_loss: 0.9070 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0320 - acc: 0.9941 - val_loss: 0.9087 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0256 - acc: 0.9958 - val_loss: 0.9111 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0217 - acc: 0.9959 - val_loss: 0.9135 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0185 - acc: 0.9970 - val_loss: 0.9177 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0144 - acc: 0.9972 - val_loss: 0.9172 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.9223 - val_acc: 0.9203\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 658us/step - loss: 0.8558 - acc: 0.8346 - val_loss: 0.8336 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6786766089673084 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0567 - acc: 0.9898 - val_loss: 0.8740 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6823077530626073 (before: 0.6786766089673084), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0463 - acc: 0.9913 - val_loss: 0.8885 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.683179254800139 (before: 0.6823077530626073), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0359 - acc: 0.9938 - val_loss: 0.9095 - val_acc: 0.9238\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0284 - acc: 0.9949 - val_loss: 0.9176 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0233 - acc: 0.9955 - val_loss: 0.9249 - val_acc: 0.9225\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0194 - acc: 0.9962 - val_loss: 0.9253 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0138 - acc: 0.9971 - val_loss: 0.9242 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0130 - acc: 0.9974 - val_loss: 0.9260 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.9241 - val_acc: 0.9197\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 639us/step - loss: 0.2647 - acc: 0.9242 - val_loss: 0.8237 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6907634133222007 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0508 - acc: 0.9897 - val_loss: 0.8528 - val_acc: 0.9244\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0385 - acc: 0.9929 - val_loss: 0.8733 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0263 - acc: 0.9948 - val_loss: 0.8735 - val_acc: 0.9244\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0173 - acc: 0.9965 - val_loss: 0.8810 - val_acc: 0.9223\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0128 - acc: 0.9968 - val_loss: 0.8793 - val_acc: 0.9213\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0101 - acc: 0.9977 - val_loss: 0.8990 - val_acc: 0.9195\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.8821 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.8754 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0050 - acc: 0.9981 - val_loss: 0.8773 - val_acc: 0.9205\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 645us/step - loss: 0.7634 - acc: 0.8321 - val_loss: 0.8502 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.6611112304658128 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0636 - acc: 0.9885 - val_loss: 0.8751 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6812684574366312 (before: 0.6611112304658128), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0464 - acc: 0.9916 - val_loss: 0.8960 - val_acc: 0.9256\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0376 - acc: 0.9932 - val_loss: 0.9093 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0300 - acc: 0.9943 - val_loss: 0.9167 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0241 - acc: 0.9959 - val_loss: 0.9163 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0219 - acc: 0.9961 - val_loss: 0.9204 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0169 - acc: 0.9969 - val_loss: 0.9222 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0142 - acc: 0.9971 - val_loss: 0.9293 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0116 - acc: 0.9976 - val_loss: 0.9217 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 643us/step - loss: 1.2332 - acc: 0.8074 - val_loss: 0.8247 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6720571457762188 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0638 - acc: 0.9886 - val_loss: 0.8629 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.685717575553207 (before: 0.6720571457762188), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0488 - acc: 0.9908 - val_loss: 0.8903 - val_acc: 0.9266\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0400 - acc: 0.9931 - val_loss: 0.9032 - val_acc: 0.9244\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0337 - acc: 0.9942 - val_loss: 0.9100 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0298 - acc: 0.9950 - val_loss: 0.9138 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0241 - acc: 0.9956 - val_loss: 0.9158 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0204 - acc: 0.9966 - val_loss: 0.9203 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0175 - acc: 0.9966 - val_loss: 0.9184 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0127 - acc: 0.9978 - val_loss: 0.9200 - val_acc: 0.9221\n",
      "300_0.7\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 648us/step - loss: 0.5842 - acc: 0.8814 - val_loss: 0.8481 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6945353580028503 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0687 - acc: 0.9892 - val_loss: 0.8816 - val_acc: 0.9284\n",
      "\n",
      "kappa improvement: 0.6966309547599336 (before: 0.6945353580028503), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0581 - acc: 0.9904 - val_loss: 0.8969 - val_acc: 0.9284\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0422 - acc: 0.9927 - val_loss: 0.9046 - val_acc: 0.9262\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0318 - acc: 0.9946 - val_loss: 0.9078 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0283 - acc: 0.9951 - val_loss: 0.9085 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0229 - acc: 0.9963 - val_loss: 0.9095 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0181 - acc: 0.9968 - val_loss: 0.9089 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0154 - acc: 0.9969 - val_loss: 0.9121 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0126 - acc: 0.9974 - val_loss: 0.9100 - val_acc: 0.9205\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 652us/step - loss: 0.8497 - acc: 0.8549 - val_loss: 0.8594 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6771218462476913 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0760 - acc: 0.9884 - val_loss: 0.8913 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6838966302254021 (before: 0.6771218462476913), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0533 - acc: 0.9911 - val_loss: 0.9102 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0449 - acc: 0.9930 - val_loss: 0.9214 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0370 - acc: 0.9940 - val_loss: 0.9246 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0292 - acc: 0.9955 - val_loss: 0.9236 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0232 - acc: 0.9959 - val_loss: 0.9321 - val_acc: 0.9219\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0223 - acc: 0.9961 - val_loss: 0.9346 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0173 - acc: 0.9968 - val_loss: 0.9329 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0124 - acc: 0.9976 - val_loss: 0.9387 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 659us/step - loss: 1.2380 - acc: 0.8122 - val_loss: 0.8446 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6659413643158038 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0701 - acc: 0.9876 - val_loss: 0.8749 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6877661081971388 (before: 0.6659413643158038), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0537 - acc: 0.9906 - val_loss: 0.8931 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6889666935990664 (before: 0.6877661081971388), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0500 - acc: 0.9923 - val_loss: 0.9043 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0424 - acc: 0.9934 - val_loss: 0.9065 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0346 - acc: 0.9944 - val_loss: 0.9090 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0281 - acc: 0.9948 - val_loss: 0.9071 - val_acc: 0.9231\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0226 - acc: 0.9957 - val_loss: 0.9049 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0199 - acc: 0.9961 - val_loss: 0.9060 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0151 - acc: 0.9968 - val_loss: 0.9064 - val_acc: 0.9223\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 676us/step - loss: 0.4310 - acc: 0.9016 - val_loss: 0.8493 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.685140805109492 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0678 - acc: 0.9876 - val_loss: 0.8728 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6854421858067059 (before: 0.685140805109492), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0502 - acc: 0.9913 - val_loss: 0.8883 - val_acc: 0.9252\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0348 - acc: 0.9937 - val_loss: 0.8916 - val_acc: 0.9233\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0269 - acc: 0.9945 - val_loss: 0.8908 - val_acc: 0.9223\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0210 - acc: 0.9959 - val_loss: 0.8939 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0170 - acc: 0.9967 - val_loss: 0.8971 - val_acc: 0.9213\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0108 - acc: 0.9975 - val_loss: 0.8945 - val_acc: 0.9205\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0131 - acc: 0.9973 - val_loss: 0.8984 - val_acc: 0.9205\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0093 - acc: 0.9976 - val_loss: 0.8938 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 652us/step - loss: 0.5417 - acc: 0.8838 - val_loss: 0.8199 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.686549688259712 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0565 - acc: 0.9895 - val_loss: 0.8564 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6882287976832271 (before: 0.686549688259712), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0457 - acc: 0.9921 - val_loss: 0.8731 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6898097664439002 (before: 0.6882287976832271), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0401 - acc: 0.9932 - val_loss: 0.8825 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0328 - acc: 0.9942 - val_loss: 0.8872 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0258 - acc: 0.9955 - val_loss: 0.8934 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0206 - acc: 0.9964 - val_loss: 0.9000 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0144 - acc: 0.9965 - val_loss: 0.9027 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0126 - acc: 0.9969 - val_loss: 0.9007 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.9065 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 705us/step - loss: 1.0042 - acc: 0.8503 - val_loss: 0.8885 - val_acc: 0.9231\n",
      "\n",
      "kappa improvement: 0.6543640595661466 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0813 - acc: 0.9869 - val_loss: 0.9003 - val_acc: 0.9227\n",
      "\n",
      "kappa improvement: 0.6652023449161517 (before: 0.6543640595661466), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0554 - acc: 0.9904 - val_loss: 0.9142 - val_acc: 0.9235\n",
      "\n",
      "kappa improvement: 0.6729512648748293 (before: 0.6652023449161517), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0426 - acc: 0.9927 - val_loss: 0.9235 - val_acc: 0.9235\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0366 - acc: 0.9939 - val_loss: 0.9282 - val_acc: 0.9225\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0276 - acc: 0.9949 - val_loss: 0.9289 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0229 - acc: 0.9953 - val_loss: 0.9269 - val_acc: 0.9227\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0195 - acc: 0.9965 - val_loss: 0.9256 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0167 - acc: 0.9964 - val_loss: 0.9284 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0140 - acc: 0.9973 - val_loss: 0.9254 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 715us/step - loss: 0.8891 - acc: 0.8492 - val_loss: 0.8377 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6802641072537208 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0674 - acc: 0.9888 - val_loss: 0.8720 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6904920372783176 (before: 0.6802641072537208), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0592 - acc: 0.9906 - val_loss: 0.8901 - val_acc: 0.9268\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0440 - acc: 0.9930 - val_loss: 0.9003 - val_acc: 0.9266\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0407 - acc: 0.9937 - val_loss: 0.9068 - val_acc: 0.9262\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0330 - acc: 0.9944 - val_loss: 0.9077 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0262 - acc: 0.9956 - val_loss: 0.9082 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0202 - acc: 0.9961 - val_loss: 0.9095 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0178 - acc: 0.9965 - val_loss: 0.9078 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0150 - acc: 0.9968 - val_loss: 0.9069 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 690us/step - loss: 0.7364 - acc: 0.8634 - val_loss: 0.8622 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6772497497814547 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0727 - acc: 0.9880 - val_loss: 0.8876 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6893523057782465 (before: 0.6772497497814547), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0592 - acc: 0.9905 - val_loss: 0.9059 - val_acc: 0.9262\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0463 - acc: 0.9923 - val_loss: 0.9126 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0383 - acc: 0.9942 - val_loss: 0.9170 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0337 - acc: 0.9952 - val_loss: 0.9178 - val_acc: 0.9252\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0260 - acc: 0.9956 - val_loss: 0.9180 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0223 - acc: 0.9964 - val_loss: 0.9174 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0213 - acc: 0.9967 - val_loss: 0.9158 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0156 - acc: 0.9971 - val_loss: 0.9207 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 661us/step - loss: 0.8636 - acc: 0.8386 - val_loss: 0.8269 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6861734098303653 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0680 - acc: 0.9883 - val_loss: 0.8642 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.692134905257627 (before: 0.6861734098303653), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0537 - acc: 0.9910 - val_loss: 0.8848 - val_acc: 0.9274\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0447 - acc: 0.9925 - val_loss: 0.8917 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0379 - acc: 0.9938 - val_loss: 0.8930 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0298 - acc: 0.9944 - val_loss: 0.8942 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0236 - acc: 0.9957 - val_loss: 0.8959 - val_acc: 0.9237\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0217 - acc: 0.9960 - val_loss: 0.8982 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0173 - acc: 0.9967 - val_loss: 0.8963 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0161 - acc: 0.9968 - val_loss: 0.9009 - val_acc: 0.9223\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 694us/step - loss: 0.9884 - acc: 0.8340 - val_loss: 0.8471 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.678554289645452 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0726 - acc: 0.9880 - val_loss: 0.8799 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6890699214139728 (before: 0.678554289645452), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0592 - acc: 0.9906 - val_loss: 0.9000 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0501 - acc: 0.9925 - val_loss: 0.9152 - val_acc: 0.9262\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0407 - acc: 0.9934 - val_loss: 0.9171 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0342 - acc: 0.9946 - val_loss: 0.9179 - val_acc: 0.9246\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0254 - acc: 0.9954 - val_loss: 0.9184 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0224 - acc: 0.9961 - val_loss: 0.9177 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0213 - acc: 0.9961 - val_loss: 0.9152 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0139 - acc: 0.9971 - val_loss: 0.9164 - val_acc: 0.9217\n",
      "300_0.8\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 680us/step - loss: 1.0536 - acc: 0.8458 - val_loss: 0.8468 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6755293743034549 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0825 - acc: 0.9875 - val_loss: 0.8799 - val_acc: 0.9280\n",
      "\n",
      "kappa improvement: 0.6916868994571155 (before: 0.6755293743034549), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0672 - acc: 0.9899 - val_loss: 0.9038 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0501 - acc: 0.9923 - val_loss: 0.9121 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0441 - acc: 0.9926 - val_loss: 0.9155 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0375 - acc: 0.9941 - val_loss: 0.9138 - val_acc: 0.9252\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0301 - acc: 0.9954 - val_loss: 0.9134 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0241 - acc: 0.9959 - val_loss: 0.9125 - val_acc: 0.9223\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0187 - acc: 0.9964 - val_loss: 0.9102 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0208 - acc: 0.9966 - val_loss: 0.9070 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 693us/step - loss: 1.1584 - acc: 0.8327 - val_loss: 0.8484 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6703219983993733 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0757 - acc: 0.9869 - val_loss: 0.8914 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6731465615477467 (before: 0.6703219983993733), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0638 - acc: 0.9903 - val_loss: 0.9062 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6769719755931296 (before: 0.6731465615477467), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0513 - acc: 0.9919 - val_loss: 0.9185 - val_acc: 0.9246\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0371 - acc: 0.9937 - val_loss: 0.9215 - val_acc: 0.9242\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0318 - acc: 0.9942 - val_loss: 0.9266 - val_acc: 0.9246\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0274 - acc: 0.9950 - val_loss: 0.9230 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0193 - acc: 0.9956 - val_loss: 0.9237 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0202 - acc: 0.9961 - val_loss: 0.9235 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0136 - acc: 0.9972 - val_loss: 0.9203 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 11s 661us/step - loss: 1.2063 - acc: 0.8348 - val_loss: 0.8480 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6814726190426039 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0867 - acc: 0.9862 - val_loss: 0.8818 - val_acc: 0.9284\n",
      "\n",
      "kappa improvement: 0.6926322139719767 (before: 0.6814726190426039), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0623 - acc: 0.9902 - val_loss: 0.9050 - val_acc: 0.9268\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0467 - acc: 0.9924 - val_loss: 0.9179 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0395 - acc: 0.9938 - val_loss: 0.9219 - val_acc: 0.9258\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0341 - acc: 0.9944 - val_loss: 0.9249 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0299 - acc: 0.9949 - val_loss: 0.9294 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0253 - acc: 0.9958 - val_loss: 0.9239 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0190 - acc: 0.9963 - val_loss: 0.9242 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0144 - acc: 0.9968 - val_loss: 0.9302 - val_acc: 0.9197\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 682us/step - loss: 0.8440 - acc: 0.8647 - val_loss: 0.8271 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6881375818964279 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0719 - acc: 0.9880 - val_loss: 0.8602 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6886986738470786 (before: 0.6881375818964279), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0556 - acc: 0.9906 - val_loss: 0.8754 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0415 - acc: 0.9927 - val_loss: 0.8889 - val_acc: 0.9244\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0331 - acc: 0.9943 - val_loss: 0.8923 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0261 - acc: 0.9949 - val_loss: 0.8916 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0223 - acc: 0.9955 - val_loss: 0.8936 - val_acc: 0.9227\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0181 - acc: 0.9960 - val_loss: 0.8914 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0152 - acc: 0.9969 - val_loss: 0.8906 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0147 - acc: 0.9967 - val_loss: 0.8867 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 683us/step - loss: 0.6766 - acc: 0.8913 - val_loss: 0.8726 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6818124133785295 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0685 - acc: 0.9887 - val_loss: 0.8981 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6890699214139728 (before: 0.6818124133785295), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0557 - acc: 0.9915 - val_loss: 0.9136 - val_acc: 0.9254\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0433 - acc: 0.9939 - val_loss: 0.9222 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0375 - acc: 0.9938 - val_loss: 0.9222 - val_acc: 0.9237\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0267 - acc: 0.9952 - val_loss: 0.9227 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0241 - acc: 0.9955 - val_loss: 0.9208 - val_acc: 0.9227\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0222 - acc: 0.9960 - val_loss: 0.9206 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0161 - acc: 0.9968 - val_loss: 0.9196 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0136 - acc: 0.9972 - val_loss: 0.9145 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 690us/step - loss: 0.6353 - acc: 0.8861 - val_loss: 0.8407 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6862713214446375 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0660 - acc: 0.9883 - val_loss: 0.8750 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6906299733124404 (before: 0.6862713214446375), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0514 - acc: 0.9915 - val_loss: 0.8877 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0364 - acc: 0.9934 - val_loss: 0.8954 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0294 - acc: 0.9946 - val_loss: 0.9011 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0260 - acc: 0.9955 - val_loss: 0.9010 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0188 - acc: 0.9965 - val_loss: 0.9016 - val_acc: 0.9211\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0149 - acc: 0.9972 - val_loss: 0.9089 - val_acc: 0.9197\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0132 - acc: 0.9971 - val_loss: 0.9020 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.8981 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 702us/step - loss: 0.5329 - acc: 0.8995 - val_loss: 0.8415 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6781627733118296 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0680 - acc: 0.9883 - val_loss: 0.8720 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6850672782120517 (before: 0.6781627733118296), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0571 - acc: 0.9910 - val_loss: 0.8875 - val_acc: 0.9252\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0431 - acc: 0.9929 - val_loss: 0.8930 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0329 - acc: 0.9948 - val_loss: 0.8934 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0283 - acc: 0.9952 - val_loss: 0.8977 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0234 - acc: 0.9956 - val_loss: 0.8927 - val_acc: 0.9217\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0182 - acc: 0.9964 - val_loss: 0.8930 - val_acc: 0.9223\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0167 - acc: 0.9967 - val_loss: 0.8939 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0117 - acc: 0.9974 - val_loss: 0.8933 - val_acc: 0.9203\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 694us/step - loss: 0.4514 - acc: 0.9179 - val_loss: 0.8532 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6903479936291462 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0718 - acc: 0.9885 - val_loss: 0.8750 - val_acc: 0.9250\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0489 - acc: 0.9923 - val_loss: 0.8883 - val_acc: 0.9240\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0429 - acc: 0.9931 - val_loss: 0.8878 - val_acc: 0.9244\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0321 - acc: 0.9949 - val_loss: 0.8898 - val_acc: 0.9227\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0249 - acc: 0.9958 - val_loss: 0.8898 - val_acc: 0.9207\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0185 - acc: 0.9963 - val_loss: 0.8918 - val_acc: 0.9209\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0154 - acc: 0.9967 - val_loss: 0.8947 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0140 - acc: 0.9969 - val_loss: 0.8961 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0113 - acc: 0.9973 - val_loss: 0.8883 - val_acc: 0.9205\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 697us/step - loss: 1.2536 - acc: 0.8286 - val_loss: 0.8409 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6724868505966265 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0706 - acc: 0.9875 - val_loss: 0.8733 - val_acc: 0.9280\n",
      "\n",
      "kappa improvement: 0.6924222672747387 (before: 0.6724868505966265), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0549 - acc: 0.9908 - val_loss: 0.8955 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0502 - acc: 0.9915 - val_loss: 0.9026 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0405 - acc: 0.9935 - val_loss: 0.9096 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0332 - acc: 0.9941 - val_loss: 0.9116 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0282 - acc: 0.9951 - val_loss: 0.9175 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0244 - acc: 0.9958 - val_loss: 0.9144 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0200 - acc: 0.9963 - val_loss: 0.9110 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0175 - acc: 0.9966 - val_loss: 0.9123 - val_acc: 0.9195\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 686us/step - loss: 0.5564 - acc: 0.9012 - val_loss: 0.8774 - val_acc: 0.9280\n",
      "\n",
      "kappa improvement: 0.693882529171254 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0778 - acc: 0.9884 - val_loss: 0.9046 - val_acc: 0.9274\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0592 - acc: 0.9919 - val_loss: 0.9231 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0482 - acc: 0.9922 - val_loss: 0.9344 - val_acc: 0.9233\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0365 - acc: 0.9940 - val_loss: 0.9359 - val_acc: 0.9237\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0296 - acc: 0.9951 - val_loss: 0.9427 - val_acc: 0.9221\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0229 - acc: 0.9964 - val_loss: 0.9409 - val_acc: 0.9207\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0162 - acc: 0.9968 - val_loss: 0.9434 - val_acc: 0.9205\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.9455 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.9454 - val_acc: 0.9197\n",
      "300_0.9\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 707us/step - loss: 0.9889 - acc: 0.8702 - val_loss: 0.8474 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6797231440536994 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0831 - acc: 0.9863 - val_loss: 0.8755 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6829069388327837 (before: 0.6797231440536994), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0611 - acc: 0.9899 - val_loss: 0.8936 - val_acc: 0.9238\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0505 - acc: 0.9923 - val_loss: 0.8960 - val_acc: 0.9237\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0413 - acc: 0.9929 - val_loss: 0.9022 - val_acc: 0.9227\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0278 - acc: 0.9948 - val_loss: 0.9051 - val_acc: 0.9217\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0257 - acc: 0.9953 - val_loss: 0.9024 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0216 - acc: 0.9952 - val_loss: 0.9016 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0224 - acc: 0.9959 - val_loss: 0.9048 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0164 - acc: 0.9964 - val_loss: 0.8959 - val_acc: 0.9203\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 684us/step - loss: 0.8288 - acc: 0.8820 - val_loss: 0.8272 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6886082640259665 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0851 - acc: 0.9855 - val_loss: 0.8580 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6939565327391883 (before: 0.6886082640259665), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 13us/step - loss: 0.0612 - acc: 0.9900 - val_loss: 0.8664 - val_acc: 0.9266\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0474 - acc: 0.9918 - val_loss: 0.8716 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0364 - acc: 0.9940 - val_loss: 0.8743 - val_acc: 0.9237\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0362 - acc: 0.9938 - val_loss: 0.8728 - val_acc: 0.9225\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0241 - acc: 0.9955 - val_loss: 0.8730 - val_acc: 0.9211\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0217 - acc: 0.9958 - val_loss: 0.8714 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0190 - acc: 0.9959 - val_loss: 0.8734 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0167 - acc: 0.9959 - val_loss: 0.8732 - val_acc: 0.9203\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 720us/step - loss: 0.9830 - acc: 0.8801 - val_loss: 0.8571 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6859939523272005 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0925 - acc: 0.9869 - val_loss: 0.8959 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6943200781718091 (before: 0.6859939523272005), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0730 - acc: 0.9891 - val_loss: 0.9060 - val_acc: 0.9266\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0584 - acc: 0.9911 - val_loss: 0.9158 - val_acc: 0.9235\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0471 - acc: 0.9922 - val_loss: 0.9194 - val_acc: 0.9237\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0379 - acc: 0.9942 - val_loss: 0.9180 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0318 - acc: 0.9947 - val_loss: 0.9142 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0220 - acc: 0.9955 - val_loss: 0.9157 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0249 - acc: 0.9955 - val_loss: 0.9106 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0184 - acc: 0.9961 - val_loss: 0.9134 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 708us/step - loss: 0.9580 - acc: 0.8733 - val_loss: 0.8254 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6854181362500933 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0821 - acc: 0.9873 - val_loss: 0.8616 - val_acc: 0.9244\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0646 - acc: 0.9897 - val_loss: 0.8763 - val_acc: 0.9248\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9918 - val_loss: 0.8850 - val_acc: 0.9233\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0367 - acc: 0.9934 - val_loss: 0.8859 - val_acc: 0.9229\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0317 - acc: 0.9938 - val_loss: 0.8870 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0261 - acc: 0.9949 - val_loss: 0.8836 - val_acc: 0.9209\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0194 - acc: 0.9956 - val_loss: 0.8826 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0200 - acc: 0.9959 - val_loss: 0.8850 - val_acc: 0.9193\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0140 - acc: 0.9965 - val_loss: 0.8862 - val_acc: 0.9199\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 757us/step - loss: 1.1750 - acc: 0.8607 - val_loss: 0.8480 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6776445379888056 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.1061 - acc: 0.9856 - val_loss: 0.8736 - val_acc: 0.9280\n",
      "\n",
      "kappa improvement: 0.6927886372878014 (before: 0.6776445379888056), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0750 - acc: 0.9887 - val_loss: 0.8888 - val_acc: 0.9276\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0556 - acc: 0.9907 - val_loss: 0.8990 - val_acc: 0.9246\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0446 - acc: 0.9931 - val_loss: 0.8994 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0384 - acc: 0.9939 - val_loss: 0.8974 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0295 - acc: 0.9952 - val_loss: 0.8976 - val_acc: 0.9231\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0245 - acc: 0.9956 - val_loss: 0.8999 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0223 - acc: 0.9955 - val_loss: 0.9035 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0191 - acc: 0.9962 - val_loss: 0.9049 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 738us/step - loss: 0.6722 - acc: 0.9013 - val_loss: 0.8408 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.683179254800139 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0961 - acc: 0.9851 - val_loss: 0.8634 - val_acc: 0.9244\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0674 - acc: 0.9896 - val_loss: 0.8730 - val_acc: 0.9246\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0471 - acc: 0.9918 - val_loss: 0.8806 - val_acc: 0.9238\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0388 - acc: 0.9934 - val_loss: 0.8705 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0318 - acc: 0.9941 - val_loss: 0.8664 - val_acc: 0.9246\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0238 - acc: 0.9953 - val_loss: 0.8683 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0213 - acc: 0.9961 - val_loss: 0.8710 - val_acc: 0.9207\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0208 - acc: 0.9956 - val_loss: 0.8655 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0168 - acc: 0.9966 - val_loss: 0.8719 - val_acc: 0.9203\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 744us/step - loss: 1.5945 - acc: 0.8259 - val_loss: 0.8013 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6771101856248922 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0737 - acc: 0.9868 - val_loss: 0.8397 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6837268359073518 (before: 0.6771101856248922), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0653 - acc: 0.9892 - val_loss: 0.8605 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0436 - acc: 0.9921 - val_loss: 0.8748 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0348 - acc: 0.9936 - val_loss: 0.8794 - val_acc: 0.9227\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0324 - acc: 0.9934 - val_loss: 0.8809 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0291 - acc: 0.9945 - val_loss: 0.8783 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0255 - acc: 0.9951 - val_loss: 0.8791 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0233 - acc: 0.9955 - val_loss: 0.8785 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0203 - acc: 0.9961 - val_loss: 0.8820 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 813us/step - loss: 1.0499 - acc: 0.8621 - val_loss: 0.8440 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6769719755931296 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0877 - acc: 0.9857 - val_loss: 0.8757 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6840414026228241 (before: 0.6769719755931296), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0637 - acc: 0.9901 - val_loss: 0.8924 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0444 - acc: 0.9926 - val_loss: 0.9002 - val_acc: 0.9246\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0387 - acc: 0.9935 - val_loss: 0.9013 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0364 - acc: 0.9937 - val_loss: 0.9048 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0292 - acc: 0.9949 - val_loss: 0.9038 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0237 - acc: 0.9955 - val_loss: 0.9029 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0227 - acc: 0.9963 - val_loss: 0.9072 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0189 - acc: 0.9955 - val_loss: 0.9075 - val_acc: 0.9205\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 726us/step - loss: 1.3575 - acc: 0.8412 - val_loss: 0.8226 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.679363767119532 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0833 - acc: 0.9865 - val_loss: 0.8548 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6856183594007788 (before: 0.679363767119532), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0727 - acc: 0.9894 - val_loss: 0.8745 - val_acc: 0.9252\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0585 - acc: 0.9905 - val_loss: 0.8827 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0452 - acc: 0.9925 - val_loss: 0.8895 - val_acc: 0.9242\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0322 - acc: 0.9942 - val_loss: 0.8883 - val_acc: 0.9225\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0284 - acc: 0.9948 - val_loss: 0.8882 - val_acc: 0.9221\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0197 - acc: 0.9955 - val_loss: 0.8876 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0223 - acc: 0.9959 - val_loss: 0.8837 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0175 - acc: 0.9963 - val_loss: 0.8866 - val_acc: 0.9193\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 748us/step - loss: 0.7935 - acc: 0.8865 - val_loss: 0.8402 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6882287976832271 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0925 - acc: 0.9858 - val_loss: 0.8752 - val_acc: 0.9250\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0676 - acc: 0.9902 - val_loss: 0.8807 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0516 - acc: 0.9916 - val_loss: 0.8845 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0420 - acc: 0.9930 - val_loss: 0.8821 - val_acc: 0.9233\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0290 - acc: 0.9941 - val_loss: 0.8781 - val_acc: 0.9221\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0285 - acc: 0.9943 - val_loss: 0.8788 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0241 - acc: 0.9955 - val_loss: 0.8755 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0183 - acc: 0.9964 - val_loss: 0.8726 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0176 - acc: 0.9964 - val_loss: 0.8751 - val_acc: 0.9205\n",
      "400_0.1\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 750us/step - loss: 1.3397 - acc: 0.7599 - val_loss: 0.8862 - val_acc: 0.9233\n",
      "\n",
      "kappa improvement: 0.6554619232714899 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0730 - acc: 0.9873 - val_loss: 0.9083 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.681426744351286 (before: 0.6554619232714899), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0557 - acc: 0.9914 - val_loss: 0.9265 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6852418668803013 (before: 0.681426744351286), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0500 - acc: 0.9928 - val_loss: 0.9389 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6873937484835899 (before: 0.6852418668803013), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0445 - acc: 0.9938 - val_loss: 0.9463 - val_acc: 0.9262\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0394 - acc: 0.9942 - val_loss: 0.9515 - val_acc: 0.9252\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0330 - acc: 0.9953 - val_loss: 0.9525 - val_acc: 0.9246\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0286 - acc: 0.9956 - val_loss: 0.9531 - val_acc: 0.9242\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0244 - acc: 0.9963 - val_loss: 0.9526 - val_acc: 0.9246\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0217 - acc: 0.9963 - val_loss: 0.9548 - val_acc: 0.9242\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 12s 717us/step - loss: 0.2936 - acc: 0.8940 - val_loss: 0.8826 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6849661779193958 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0594 - acc: 0.9906 - val_loss: 0.9139 - val_acc: 0.9262\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0478 - acc: 0.9929 - val_loss: 0.9319 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0360 - acc: 0.9950 - val_loss: 0.9514 - val_acc: 0.9240\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0292 - acc: 0.9959 - val_loss: 0.9477 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0219 - acc: 0.9969 - val_loss: 0.9534 - val_acc: 0.9225\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0169 - acc: 0.9972 - val_loss: 0.9537 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0130 - acc: 0.9976 - val_loss: 0.9580 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0100 - acc: 0.9982 - val_loss: 0.9614 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0075 - acc: 0.9984 - val_loss: 0.9645 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 750us/step - loss: 0.4959 - acc: 0.8526 - val_loss: 0.8868 - val_acc: 0.9237\n",
      "\n",
      "kappa improvement: 0.65593000394943 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0713 - acc: 0.9880 - val_loss: 0.9053 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6825809568230277 (before: 0.65593000394943), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0498 - acc: 0.9928 - val_loss: 0.9267 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6834975803444475 (before: 0.6825809568230277), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0433 - acc: 0.9937 - val_loss: 0.9332 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0326 - acc: 0.9950 - val_loss: 0.9425 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0255 - acc: 0.9959 - val_loss: 0.9468 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0208 - acc: 0.9964 - val_loss: 0.9455 - val_acc: 0.9207\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0155 - acc: 0.9974 - val_loss: 0.9457 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0127 - acc: 0.9981 - val_loss: 0.9457 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0092 - acc: 0.9983 - val_loss: 0.9490 - val_acc: 0.9199\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 751us/step - loss: 0.5355 - acc: 0.8492 - val_loss: 0.9172 - val_acc: 0.9233\n",
      "\n",
      "kappa improvement: 0.6554619232714899 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0772 - acc: 0.9881 - val_loss: 0.9355 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6768444720371831 (before: 0.6554619232714899), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0581 - acc: 0.9913 - val_loss: 0.9487 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6786529348791276 (before: 0.6768444720371831), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0473 - acc: 0.9934 - val_loss: 0.9562 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.683179254800139 (before: 0.6786529348791276), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0408 - acc: 0.9941 - val_loss: 0.9593 - val_acc: 0.9254\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0330 - acc: 0.9949 - val_loss: 0.9632 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0279 - acc: 0.9957 - val_loss: 0.9640 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0231 - acc: 0.9964 - val_loss: 0.9651 - val_acc: 0.9238\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0202 - acc: 0.9971 - val_loss: 0.9613 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0165 - acc: 0.9978 - val_loss: 0.9623 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 730us/step - loss: 0.5808 - acc: 0.8897 - val_loss: 0.8857 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.679305634557178 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0711 - acc: 0.9883 - val_loss: 0.9135 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6909129558545191 (before: 0.679305634557178), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0571 - acc: 0.9913 - val_loss: 0.9293 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0453 - acc: 0.9933 - val_loss: 0.9374 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6911595717955574 (before: 0.6909129558545191), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0375 - acc: 0.9946 - val_loss: 0.9376 - val_acc: 0.9262\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0303 - acc: 0.9956 - val_loss: 0.9360 - val_acc: 0.9252\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0238 - acc: 0.9964 - val_loss: 0.9347 - val_acc: 0.9258\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0187 - acc: 0.9971 - val_loss: 0.9374 - val_acc: 0.9248\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0155 - acc: 0.9972 - val_loss: 0.9326 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0121 - acc: 0.9978 - val_loss: 0.9311 - val_acc: 0.9223\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 730us/step - loss: 0.4092 - acc: 0.8664 - val_loss: 0.8937 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6884176263161788 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0689 - acc: 0.9891 - val_loss: 0.9241 - val_acc: 0.9260\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0576 - acc: 0.9916 - val_loss: 0.9409 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0481 - acc: 0.9934 - val_loss: 0.9498 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0409 - acc: 0.9942 - val_loss: 0.9573 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0337 - acc: 0.9952 - val_loss: 0.9592 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0283 - acc: 0.9961 - val_loss: 0.9621 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0228 - acc: 0.9968 - val_loss: 0.9651 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0183 - acc: 0.9971 - val_loss: 0.9643 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0149 - acc: 0.9976 - val_loss: 0.9636 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 761us/step - loss: 0.3616 - acc: 0.9102 - val_loss: 0.9131 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6797449905959176 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0725 - acc: 0.9896 - val_loss: 0.9310 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.679808821340566 (before: 0.6797449905959176), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0550 - acc: 0.9913 - val_loss: 0.9554 - val_acc: 0.9240\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0445 - acc: 0.9936 - val_loss: 0.9568 - val_acc: 0.9237\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0352 - acc: 0.9949 - val_loss: 0.9598 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0274 - acc: 0.9957 - val_loss: 0.9558 - val_acc: 0.9219\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0207 - acc: 0.9965 - val_loss: 0.9603 - val_acc: 0.9219\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0155 - acc: 0.9972 - val_loss: 0.9594 - val_acc: 0.9203\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0119 - acc: 0.9979 - val_loss: 0.9609 - val_acc: 0.9205\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0091 - acc: 0.9984 - val_loss: 0.9603 - val_acc: 0.9193\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 730us/step - loss: 0.3608 - acc: 0.8976 - val_loss: 0.9035 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.677224677111609 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0719 - acc: 0.9888 - val_loss: 0.9292 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6793664509186951 (before: 0.677224677111609), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0569 - acc: 0.9920 - val_loss: 0.9378 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0424 - acc: 0.9939 - val_loss: 0.9446 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0338 - acc: 0.9948 - val_loss: 0.9478 - val_acc: 0.9229\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0269 - acc: 0.9956 - val_loss: 0.9494 - val_acc: 0.9221\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0215 - acc: 0.9965 - val_loss: 0.9490 - val_acc: 0.9213\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0163 - acc: 0.9971 - val_loss: 0.9497 - val_acc: 0.9203\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0128 - acc: 0.9976 - val_loss: 0.9525 - val_acc: 0.9205\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0099 - acc: 0.9982 - val_loss: 0.9553 - val_acc: 0.9193\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 731us/step - loss: 0.3611 - acc: 0.9027 - val_loss: 0.9030 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.6744959823031493 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0686 - acc: 0.9896 - val_loss: 0.9245 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.680041756055861 (before: 0.6744959823031493), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0460 - acc: 0.9926 - val_loss: 0.9334 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6842480061155329 (before: 0.680041756055861), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0359 - acc: 0.9946 - val_loss: 0.9419 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0275 - acc: 0.9956 - val_loss: 0.9479 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0217 - acc: 0.9966 - val_loss: 0.9516 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0162 - acc: 0.9972 - val_loss: 0.9543 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0124 - acc: 0.9979 - val_loss: 0.9552 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0096 - acc: 0.9981 - val_loss: 0.9570 - val_acc: 0.9227\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.9596 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 805us/step - loss: 0.2690 - acc: 0.9049 - val_loss: 0.9129 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.6709515922450802 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0604 - acc: 0.9902 - val_loss: 0.9438 - val_acc: 0.9211\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0461 - acc: 0.9928 - val_loss: 0.9479 - val_acc: 0.9219\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0346 - acc: 0.9946 - val_loss: 0.9571 - val_acc: 0.9213\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0264 - acc: 0.9959 - val_loss: 0.9672 - val_acc: 0.9227\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0196 - acc: 0.9964 - val_loss: 0.9775 - val_acc: 0.9213\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0143 - acc: 0.9971 - val_loss: 0.9688 - val_acc: 0.9205\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0106 - acc: 0.9978 - val_loss: 0.9701 - val_acc: 0.9203\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.9703 - val_acc: 0.9197\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0062 - acc: 0.9988 - val_loss: 0.9718 - val_acc: 0.9203\n",
      "400_0.2\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 765us/step - loss: 0.3626 - acc: 0.9265 - val_loss: 0.8980 - val_acc: 0.9237\n",
      "\n",
      "kappa improvement: 0.6863288004019894 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0770 - acc: 0.9889 - val_loss: 0.9061 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6950391984645913 (before: 0.6863288004019894), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0530 - acc: 0.9917 - val_loss: 0.9139 - val_acc: 0.9286\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0409 - acc: 0.9937 - val_loss: 0.9168 - val_acc: 0.9274\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0300 - acc: 0.9956 - val_loss: 0.9160 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0221 - acc: 0.9968 - val_loss: 0.9126 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0168 - acc: 0.9971 - val_loss: 0.9109 - val_acc: 0.9231\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0131 - acc: 0.9978 - val_loss: 0.9041 - val_acc: 0.9238\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0101 - acc: 0.9982 - val_loss: 0.9050 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0078 - acc: 0.9986 - val_loss: 0.9037 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 832us/step - loss: 0.6859 - acc: 0.8293 - val_loss: 0.8858 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.665282027559807 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0701 - acc: 0.9881 - val_loss: 0.9110 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6877672273129253 (before: 0.665282027559807), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0571 - acc: 0.9907 - val_loss: 0.9285 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6897011048779098 (before: 0.6877672273129253), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0490 - acc: 0.9926 - val_loss: 0.9356 - val_acc: 0.9266\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0426 - acc: 0.9937 - val_loss: 0.9422 - val_acc: 0.9258\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0350 - acc: 0.9949 - val_loss: 0.9445 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0304 - acc: 0.9957 - val_loss: 0.9484 - val_acc: 0.9246\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0254 - acc: 0.9964 - val_loss: 0.9470 - val_acc: 0.9240\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0219 - acc: 0.9965 - val_loss: 0.9430 - val_acc: 0.9235\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0174 - acc: 0.9972 - val_loss: 0.9413 - val_acc: 0.9227\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 15s 837us/step - loss: 1.0159 - acc: 0.7971 - val_loss: 0.9337 - val_acc: 0.9233\n",
      "\n",
      "kappa improvement: 0.6541610065404295 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0742 - acc: 0.9884 - val_loss: 0.9409 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.6734422927253583 (before: 0.6541610065404295), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0525 - acc: 0.9919 - val_loss: 0.9565 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6775980686995856 (before: 0.6734422927253583), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0449 - acc: 0.9932 - val_loss: 0.9673 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.6781044746115945 (before: 0.6775980686995856), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0367 - acc: 0.9946 - val_loss: 0.9662 - val_acc: 0.9229\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0303 - acc: 0.9953 - val_loss: 0.9716 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0236 - acc: 0.9964 - val_loss: 0.9765 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0192 - acc: 0.9968 - val_loss: 0.9746 - val_acc: 0.9238\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0163 - acc: 0.9974 - val_loss: 0.9711 - val_acc: 0.9227\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0123 - acc: 0.9979 - val_loss: 0.9696 - val_acc: 0.9227\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 826us/step - loss: 0.3189 - acc: 0.9068 - val_loss: 0.9008 - val_acc: 0.9229\n",
      "\n",
      "kappa improvement: 0.6714157364217056 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0635 - acc: 0.9903 - val_loss: 0.9209 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6822050234720647 (before: 0.6714157364217056), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0472 - acc: 0.9924 - val_loss: 0.9396 - val_acc: 0.9237\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0365 - acc: 0.9944 - val_loss: 0.9457 - val_acc: 0.9237\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0279 - acc: 0.9956 - val_loss: 0.9410 - val_acc: 0.9229\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0207 - acc: 0.9964 - val_loss: 0.9424 - val_acc: 0.9217\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0154 - acc: 0.9970 - val_loss: 0.9604 - val_acc: 0.9215\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.9592 - val_acc: 0.9223\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0094 - acc: 0.9981 - val_loss: 0.9571 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.9594 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 818us/step - loss: 0.3465 - acc: 0.8956 - val_loss: 0.8898 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6672624767217408 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 23us/step - loss: 0.0645 - acc: 0.9896 - val_loss: 0.9216 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6776133160060285 (before: 0.6672624767217408), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0490 - acc: 0.9928 - val_loss: 0.9322 - val_acc: 0.9238\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0377 - acc: 0.9945 - val_loss: 0.9443 - val_acc: 0.9231\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0278 - acc: 0.9957 - val_loss: 0.9505 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0232 - acc: 0.9963 - val_loss: 0.9517 - val_acc: 0.9223\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0179 - acc: 0.9973 - val_loss: 0.9629 - val_acc: 0.9211\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0141 - acc: 0.9977 - val_loss: 0.9699 - val_acc: 0.9199\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0111 - acc: 0.9981 - val_loss: 0.9654 - val_acc: 0.9195\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0088 - acc: 0.9985 - val_loss: 0.9831 - val_acc: 0.9189\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 764us/step - loss: 0.1961 - acc: 0.9598 - val_loss: 0.9101 - val_acc: 0.9225\n",
      "\n",
      "kappa improvement: 0.6840285273557245 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0587 - acc: 0.9911 - val_loss: 0.9117 - val_acc: 0.9266\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0372 - acc: 0.9940 - val_loss: 0.9169 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6855638750642861 (before: 0.6840285273557245), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0245 - acc: 0.9963 - val_loss: 0.9312 - val_acc: 0.9229\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0169 - acc: 0.9972 - val_loss: 0.9301 - val_acc: 0.9221\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0095 - acc: 0.9982 - val_loss: 0.9386 - val_acc: 0.9215\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.9458 - val_acc: 0.9209\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.9442 - val_acc: 0.9195\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.9397 - val_acc: 0.9189\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.9503 - val_acc: 0.9189\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 772us/step - loss: 0.2059 - acc: 0.9270 - val_loss: 0.8790 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6934567996334933 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0541 - acc: 0.9908 - val_loss: 0.9051 - val_acc: 0.9270\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0409 - acc: 0.9935 - val_loss: 0.9188 - val_acc: 0.9246\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0308 - acc: 0.9952 - val_loss: 0.9380 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0229 - acc: 0.9961 - val_loss: 0.9404 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0181 - acc: 0.9969 - val_loss: 0.9389 - val_acc: 0.9213\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0133 - acc: 0.9977 - val_loss: 0.9397 - val_acc: 0.9215\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0103 - acc: 0.9982 - val_loss: 0.9404 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.9421 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0062 - acc: 0.9988 - val_loss: 0.9468 - val_acc: 0.9199\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 779us/step - loss: 0.3917 - acc: 0.8698 - val_loss: 0.8868 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6727460194043473 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0643 - acc: 0.9898 - val_loss: 0.9144 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6822559889130865 (before: 0.6727460194043473), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0499 - acc: 0.9919 - val_loss: 0.9322 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6854421858067059 (before: 0.6822559889130865), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0383 - acc: 0.9943 - val_loss: 0.9360 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0325 - acc: 0.9951 - val_loss: 0.9419 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0264 - acc: 0.9964 - val_loss: 0.9474 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0208 - acc: 0.9970 - val_loss: 0.9567 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0169 - acc: 0.9973 - val_loss: 0.9504 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0139 - acc: 0.9976 - val_loss: 0.9619 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0118 - acc: 0.9980 - val_loss: 0.9565 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 775us/step - loss: 0.3340 - acc: 0.8889 - val_loss: 0.8736 - val_acc: 0.9289\n",
      "\n",
      "kappa improvement: 0.695341058317297 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0624 - acc: 0.9902 - val_loss: 0.9073 - val_acc: 0.9274\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0503 - acc: 0.9926 - val_loss: 0.9280 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0422 - acc: 0.9938 - val_loss: 0.9378 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0334 - acc: 0.9951 - val_loss: 0.9392 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0266 - acc: 0.9962 - val_loss: 0.9441 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0219 - acc: 0.9967 - val_loss: 0.9509 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0157 - acc: 0.9974 - val_loss: 0.9576 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0121 - acc: 0.9980 - val_loss: 0.9592 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0103 - acc: 0.9981 - val_loss: 0.9602 - val_acc: 0.9213\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 781us/step - loss: 0.5001 - acc: 0.8687 - val_loss: 0.8770 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.693077340882532 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0671 - acc: 0.9897 - val_loss: 0.9057 - val_acc: 0.9278\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0536 - acc: 0.9917 - val_loss: 0.9246 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.693668658576823 (before: 0.693077340882532), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0446 - acc: 0.9939 - val_loss: 0.9352 - val_acc: 0.9274\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0361 - acc: 0.9947 - val_loss: 0.9378 - val_acc: 0.9256\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0295 - acc: 0.9959 - val_loss: 0.9389 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0245 - acc: 0.9965 - val_loss: 0.9387 - val_acc: 0.9256\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0197 - acc: 0.9969 - val_loss: 0.9358 - val_acc: 0.9252\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0165 - acc: 0.9975 - val_loss: 0.9375 - val_acc: 0.9240\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0135 - acc: 0.9979 - val_loss: 0.9384 - val_acc: 0.9237\n",
      "400_0.3\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 791us/step - loss: 1.1596 - acc: 0.7783 - val_loss: 0.8876 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.668586851022528 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0692 - acc: 0.9882 - val_loss: 0.9104 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6852418668803013 (before: 0.668586851022528), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0570 - acc: 0.9909 - val_loss: 0.9281 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6898097664439002 (before: 0.6852418668803013), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0520 - acc: 0.9925 - val_loss: 0.9401 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0427 - acc: 0.9937 - val_loss: 0.9460 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0370 - acc: 0.9947 - val_loss: 0.9481 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0302 - acc: 0.9956 - val_loss: 0.9511 - val_acc: 0.9242\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0248 - acc: 0.9963 - val_loss: 0.9505 - val_acc: 0.9231\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0217 - acc: 0.9964 - val_loss: 0.9526 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0178 - acc: 0.9969 - val_loss: 0.9509 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 815us/step - loss: 0.5313 - acc: 0.8879 - val_loss: 0.8959 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.6730476742102565 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0745 - acc: 0.9883 - val_loss: 0.9211 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.6863148804835828 (before: 0.6730476742102565), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0554 - acc: 0.9919 - val_loss: 0.9266 - val_acc: 0.9254\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0459 - acc: 0.9935 - val_loss: 0.9332 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0379 - acc: 0.9948 - val_loss: 0.9365 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0308 - acc: 0.9955 - val_loss: 0.9374 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0258 - acc: 0.9960 - val_loss: 0.9356 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0194 - acc: 0.9967 - val_loss: 0.9369 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0137 - acc: 0.9974 - val_loss: 0.9296 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0100 - acc: 0.9982 - val_loss: 0.9293 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 800us/step - loss: 0.2551 - acc: 0.9310 - val_loss: 0.8947 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.685050494563199 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0761 - acc: 0.9890 - val_loss: 0.8997 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6942482194565209 (before: 0.685050494563199), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0526 - acc: 0.9920 - val_loss: 0.9053 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0397 - acc: 0.9940 - val_loss: 0.9072 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0283 - acc: 0.9955 - val_loss: 0.9130 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0214 - acc: 0.9961 - val_loss: 0.9013 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0135 - acc: 0.9971 - val_loss: 0.9027 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0088 - acc: 0.9983 - val_loss: 0.9014 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.9073 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.9070 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 782us/step - loss: 0.6915 - acc: 0.9020 - val_loss: 0.9400 - val_acc: 0.9223\n",
      "\n",
      "kappa improvement: 0.6726077855485421 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.1030 - acc: 0.9869 - val_loss: 0.9341 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.6813605200324818 (before: 0.6726077855485421), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0667 - acc: 0.9907 - val_loss: 0.9467 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6829576216860681 (before: 0.6813605200324818), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0474 - acc: 0.9935 - val_loss: 0.9559 - val_acc: 0.9229\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0374 - acc: 0.9945 - val_loss: 0.9574 - val_acc: 0.9227\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0313 - acc: 0.9956 - val_loss: 0.9513 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0228 - acc: 0.9965 - val_loss: 0.9479 - val_acc: 0.9213\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0185 - acc: 0.9965 - val_loss: 0.9498 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0141 - acc: 0.9976 - val_loss: 0.9523 - val_acc: 0.9197\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 0.9978 - val_loss: 0.9503 - val_acc: 0.9199\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 796us/step - loss: 0.4770 - acc: 0.9088 - val_loss: 0.9081 - val_acc: 0.9213\n",
      "\n",
      "kappa improvement: 0.6698335104212538 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0856 - acc: 0.9880 - val_loss: 0.9203 - val_acc: 0.9248\n",
      "\n",
      "kappa improvement: 0.6857584553509962 (before: 0.6698335104212538), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0589 - acc: 0.9918 - val_loss: 0.9231 - val_acc: 0.9246\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0435 - acc: 0.9935 - val_loss: 0.9286 - val_acc: 0.9229\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0337 - acc: 0.9948 - val_loss: 0.9288 - val_acc: 0.9233\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0244 - acc: 0.9959 - val_loss: 0.9244 - val_acc: 0.9225\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0189 - acc: 0.9968 - val_loss: 0.9189 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.9282 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0097 - acc: 0.9982 - val_loss: 0.9228 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0086 - acc: 0.9986 - val_loss: 0.9342 - val_acc: 0.9182\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 13s 776us/step - loss: 0.3659 - acc: 0.9322 - val_loss: 0.9569 - val_acc: 0.9197\n",
      "\n",
      "kappa improvement: 0.6801119072198578 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0956 - acc: 0.9878 - val_loss: 0.9321 - val_acc: 0.9237\n",
      "\n",
      "kappa improvement: 0.6837890336759562 (before: 0.6801119072198578), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0623 - acc: 0.9913 - val_loss: 0.9322 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6879504150453426 (before: 0.6837890336759562), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0444 - acc: 0.9933 - val_loss: 0.9325 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0312 - acc: 0.9951 - val_loss: 0.9284 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0216 - acc: 0.9964 - val_loss: 0.9234 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0158 - acc: 0.9972 - val_loss: 0.9189 - val_acc: 0.9242\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0100 - acc: 0.9980 - val_loss: 0.9168 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.9188 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.9238 - val_acc: 0.9197\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 832us/step - loss: 0.7153 - acc: 0.8131 - val_loss: 0.8720 - val_acc: 0.9235\n",
      "\n",
      "kappa improvement: 0.658271277967909 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0685 - acc: 0.9884 - val_loss: 0.9007 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6752673422189508 (before: 0.658271277967909), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0541 - acc: 0.9918 - val_loss: 0.9188 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6825269716916034 (before: 0.6752673422189508), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0424 - acc: 0.9935 - val_loss: 0.9312 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0367 - acc: 0.9945 - val_loss: 0.9393 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0296 - acc: 0.9956 - val_loss: 0.9451 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0250 - acc: 0.9961 - val_loss: 0.9422 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0192 - acc: 0.9963 - val_loss: 0.9462 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0175 - acc: 0.9972 - val_loss: 0.9449 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0145 - acc: 0.9975 - val_loss: 0.9437 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 808us/step - loss: 0.7941 - acc: 0.8170 - val_loss: 0.8849 - val_acc: 0.9233\n",
      "\n",
      "kappa improvement: 0.6597285029229278 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0615 - acc: 0.9893 - val_loss: 0.9024 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6827989303661757 (before: 0.6597285029229278), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0483 - acc: 0.9923 - val_loss: 0.9194 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6849661779193958 (before: 0.6827989303661757), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0388 - acc: 0.9940 - val_loss: 0.9325 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0347 - acc: 0.9945 - val_loss: 0.9402 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0274 - acc: 0.9957 - val_loss: 0.9396 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0227 - acc: 0.9961 - val_loss: 0.9430 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0188 - acc: 0.9965 - val_loss: 0.9418 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0134 - acc: 0.9975 - val_loss: 0.9417 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0116 - acc: 0.9978 - val_loss: 0.9409 - val_acc: 0.9223\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 822us/step - loss: 0.6125 - acc: 0.8396 - val_loss: 0.9050 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.664782530476574 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0719 - acc: 0.9894 - val_loss: 0.9289 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6878606495624602 (before: 0.664782530476574), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0598 - acc: 0.9920 - val_loss: 0.9472 - val_acc: 0.9272\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0498 - acc: 0.9930 - val_loss: 0.9582 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0411 - acc: 0.9941 - val_loss: 0.9645 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0316 - acc: 0.9959 - val_loss: 0.9659 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0267 - acc: 0.9963 - val_loss: 0.9733 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0235 - acc: 0.9965 - val_loss: 0.9713 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0197 - acc: 0.9968 - val_loss: 0.9719 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0176 - acc: 0.9975 - val_loss: 0.9729 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 804us/step - loss: 0.4754 - acc: 0.9414 - val_loss: 0.9298 - val_acc: 0.9231\n",
      "\n",
      "kappa improvement: 0.6720567469048635 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0569 - acc: 0.9915 - val_loss: 0.9425 - val_acc: 0.9225\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0369 - acc: 0.9938 - val_loss: 0.9460 - val_acc: 0.9217\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0227 - acc: 0.9961 - val_loss: 0.9548 - val_acc: 0.9221\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0136 - acc: 0.9972 - val_loss: 0.9534 - val_acc: 0.9211\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.9573 - val_acc: 0.9205\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.9593 - val_acc: 0.9199\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.9645 - val_acc: 0.9203\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.9620 - val_acc: 0.9203\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.9586 - val_acc: 0.9197\n",
      "400_0.4\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 795us/step - loss: 1.0369 - acc: 0.7998 - val_loss: 0.8932 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6704714534891123 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0764 - acc: 0.9881 - val_loss: 0.9195 - val_acc: 0.9280\n",
      "\n",
      "kappa improvement: 0.6913178953624182 (before: 0.6704714534891123), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0592 - acc: 0.9913 - val_loss: 0.9397 - val_acc: 0.9274\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0543 - acc: 0.9927 - val_loss: 0.9501 - val_acc: 0.9280\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0458 - acc: 0.9932 - val_loss: 0.9599 - val_acc: 0.9260\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0376 - acc: 0.9943 - val_loss: 0.9608 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0304 - acc: 0.9955 - val_loss: 0.9644 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0267 - acc: 0.9958 - val_loss: 0.9644 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0219 - acc: 0.9965 - val_loss: 0.9678 - val_acc: 0.9231\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0194 - acc: 0.9972 - val_loss: 0.9700 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 14s 799us/step - loss: 0.9198 - acc: 0.8054 - val_loss: 0.9007 - val_acc: 0.9227\n",
      "\n",
      "kappa improvement: 0.6521641946215692 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0839 - acc: 0.9871 - val_loss: 0.9187 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6832383960530537 (before: 0.6521641946215692), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0620 - acc: 0.9911 - val_loss: 0.9386 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6916053384490713 (before: 0.6832383960530537), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0534 - acc: 0.9926 - val_loss: 0.9452 - val_acc: 0.9266\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0405 - acc: 0.9944 - val_loss: 0.9554 - val_acc: 0.9260\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0350 - acc: 0.9948 - val_loss: 0.9703 - val_acc: 0.9252\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0308 - acc: 0.9957 - val_loss: 0.9702 - val_acc: 0.9250\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0257 - acc: 0.9962 - val_loss: 0.9711 - val_acc: 0.9246\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0230 - acc: 0.9967 - val_loss: 0.9699 - val_acc: 0.9242\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0201 - acc: 0.9964 - val_loss: 0.9733 - val_acc: 0.9229\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 15s 844us/step - loss: 0.3852 - acc: 0.8892 - val_loss: 0.8731 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6891585826862049 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0726 - acc: 0.9883 - val_loss: 0.9027 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.693668658576823 (before: 0.6891585826862049), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0544 - acc: 0.9917 - val_loss: 0.9184 - val_acc: 0.9278\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0443 - acc: 0.9937 - val_loss: 0.9265 - val_acc: 0.9262\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0345 - acc: 0.9944 - val_loss: 0.9340 - val_acc: 0.9240\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0270 - acc: 0.9956 - val_loss: 0.9351 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0216 - acc: 0.9965 - val_loss: 0.9386 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0157 - acc: 0.9971 - val_loss: 0.9381 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0128 - acc: 0.9978 - val_loss: 0.9314 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0108 - acc: 0.9979 - val_loss: 0.9364 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 897us/step - loss: 0.9102 - acc: 0.8055 - val_loss: 0.8813 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6768539933954326 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0686 - acc: 0.9888 - val_loss: 0.9122 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6830718702180864 (before: 0.6768539933954326), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0594 - acc: 0.9915 - val_loss: 0.9301 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.685717575553207 (before: 0.6830718702180864), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0463 - acc: 0.9931 - val_loss: 0.9418 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.686837975274849 (before: 0.685717575553207), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0397 - acc: 0.9941 - val_loss: 0.9481 - val_acc: 0.9268\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0334 - acc: 0.9952 - val_loss: 0.9524 - val_acc: 0.9260\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0302 - acc: 0.9952 - val_loss: 0.9565 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0227 - acc: 0.9967 - val_loss: 0.9607 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0197 - acc: 0.9968 - val_loss: 0.9566 - val_acc: 0.9237\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0175 - acc: 0.9974 - val_loss: 0.9577 - val_acc: 0.9227\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 15s 862us/step - loss: 0.3403 - acc: 0.9148 - val_loss: 0.8891 - val_acc: 0.9248\n",
      "\n",
      "kappa improvement: 0.6897429476554457 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0725 - acc: 0.9894 - val_loss: 0.9088 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6897647536078209 (before: 0.6897429476554457), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0536 - acc: 0.9925 - val_loss: 0.9183 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6924497379395396 (before: 0.6897647536078209), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0397 - acc: 0.9938 - val_loss: 0.9258 - val_acc: 0.9244\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0315 - acc: 0.9952 - val_loss: 0.9269 - val_acc: 0.9235\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0220 - acc: 0.9965 - val_loss: 0.9280 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0171 - acc: 0.9969 - val_loss: 0.9387 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0143 - acc: 0.9970 - val_loss: 0.9353 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.9359 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0081 - acc: 0.9983 - val_loss: 0.9339 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 904us/step - loss: 0.5873 - acc: 0.8433 - val_loss: 0.8764 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6768444720371831 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0675 - acc: 0.9895 - val_loss: 0.9028 - val_acc: 0.9284\n",
      "\n",
      "kappa improvement: 0.6944628136513556 (before: 0.6768444720371831), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0557 - acc: 0.9915 - val_loss: 0.9227 - val_acc: 0.9272\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0466 - acc: 0.9932 - val_loss: 0.9339 - val_acc: 0.9268\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0367 - acc: 0.9945 - val_loss: 0.9395 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0295 - acc: 0.9952 - val_loss: 0.9493 - val_acc: 0.9252\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0258 - acc: 0.9960 - val_loss: 0.9481 - val_acc: 0.9248\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0217 - acc: 0.9966 - val_loss: 0.9476 - val_acc: 0.9244\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0178 - acc: 0.9969 - val_loss: 0.9483 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0159 - acc: 0.9975 - val_loss: 0.9521 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 15s 853us/step - loss: 0.2017 - acc: 0.9467 - val_loss: 0.8927 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6914414908082789 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0655 - acc: 0.9903 - val_loss: 0.9099 - val_acc: 0.9270\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0450 - acc: 0.9929 - val_loss: 0.9186 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0326 - acc: 0.9949 - val_loss: 0.9201 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0223 - acc: 0.9960 - val_loss: 0.9248 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0139 - acc: 0.9973 - val_loss: 0.9157 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0090 - acc: 0.9978 - val_loss: 0.9278 - val_acc: 0.9213\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.9235 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.9253 - val_acc: 0.9203\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.9993 - val_loss: 0.9342 - val_acc: 0.9193\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 15s 880us/step - loss: 0.7607 - acc: 0.8229 - val_loss: 0.8914 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.6637006939176129 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0795 - acc: 0.9881 - val_loss: 0.9215 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6769719755931296 (before: 0.6637006939176129), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0628 - acc: 0.9908 - val_loss: 0.9340 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6877672273129253 (before: 0.6769719755931296), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0522 - acc: 0.9928 - val_loss: 0.9448 - val_acc: 0.9266\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0431 - acc: 0.9941 - val_loss: 0.9511 - val_acc: 0.9258\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0351 - acc: 0.9946 - val_loss: 0.9547 - val_acc: 0.9246\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0268 - acc: 0.9957 - val_loss: 0.9559 - val_acc: 0.9244\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0237 - acc: 0.9964 - val_loss: 0.9547 - val_acc: 0.9238\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0197 - acc: 0.9969 - val_loss: 0.9528 - val_acc: 0.9238\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0171 - acc: 0.9971 - val_loss: 0.9530 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 901us/step - loss: 0.4446 - acc: 0.8867 - val_loss: 0.9008 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6773906880615194 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0742 - acc: 0.9888 - val_loss: 0.9279 - val_acc: 0.9286\n",
      "\n",
      "kappa improvement: 0.6951183225244331 (before: 0.6773906880615194), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0548 - acc: 0.9923 - val_loss: 0.9440 - val_acc: 0.9268\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0428 - acc: 0.9939 - val_loss: 0.9543 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0347 - acc: 0.9948 - val_loss: 0.9580 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0276 - acc: 0.9959 - val_loss: 0.9597 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0229 - acc: 0.9963 - val_loss: 0.9612 - val_acc: 0.9237\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0197 - acc: 0.9967 - val_loss: 0.9622 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0158 - acc: 0.9974 - val_loss: 0.9654 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0132 - acc: 0.9977 - val_loss: 0.9681 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 914us/step - loss: 0.7445 - acc: 0.8256 - val_loss: 0.8627 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6707284925892227 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0601 - acc: 0.9902 - val_loss: 0.8993 - val_acc: 0.9248\n",
      "\n",
      "kappa improvement: 0.6719713556878879 (before: 0.6707284925892227), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0501 - acc: 0.9923 - val_loss: 0.9159 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6856183594007788 (before: 0.6719713556878879), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0420 - acc: 0.9937 - val_loss: 0.9306 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0346 - acc: 0.9948 - val_loss: 0.9423 - val_acc: 0.9242\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0281 - acc: 0.9959 - val_loss: 0.9534 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0214 - acc: 0.9969 - val_loss: 0.9550 - val_acc: 0.9237\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0198 - acc: 0.9969 - val_loss: 0.9565 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0163 - acc: 0.9974 - val_loss: 0.9527 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0146 - acc: 0.9977 - val_loss: 0.9543 - val_acc: 0.9217\n",
      "400_0.5\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 910us/step - loss: 0.4572 - acc: 0.8863 - val_loss: 0.8956 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6744777452176428 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0676 - acc: 0.9893 - val_loss: 0.9228 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6834525520537789 (before: 0.6744777452176428), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0548 - acc: 0.9924 - val_loss: 0.9348 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6858953857850612 (before: 0.6834525520537789), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0423 - acc: 0.9939 - val_loss: 0.9480 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0319 - acc: 0.9956 - val_loss: 0.9543 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0271 - acc: 0.9959 - val_loss: 0.9668 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0193 - acc: 0.9969 - val_loss: 0.9583 - val_acc: 0.9237\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0159 - acc: 0.9973 - val_loss: 0.9637 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0143 - acc: 0.9975 - val_loss: 0.9568 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0102 - acc: 0.9980 - val_loss: 0.9630 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 912us/step - loss: 0.7525 - acc: 0.8301 - val_loss: 0.8706 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6763266068759342 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0715 - acc: 0.9887 - val_loss: 0.9043 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6869250654531339 (before: 0.6763266068759342), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0562 - acc: 0.9913 - val_loss: 0.9260 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.693077340882532 (before: 0.6869250654531339), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0483 - acc: 0.9935 - val_loss: 0.9386 - val_acc: 0.9264\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0382 - acc: 0.9946 - val_loss: 0.9447 - val_acc: 0.9264\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0300 - acc: 0.9955 - val_loss: 0.9464 - val_acc: 0.9246\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0261 - acc: 0.9961 - val_loss: 0.9493 - val_acc: 0.9246\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0217 - acc: 0.9963 - val_loss: 0.9479 - val_acc: 0.9240\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0172 - acc: 0.9969 - val_loss: 0.9506 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0156 - acc: 0.9971 - val_loss: 0.9524 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 934us/step - loss: 0.2661 - acc: 0.9376 - val_loss: 0.8753 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.6856614500056528 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0685 - acc: 0.9890 - val_loss: 0.8914 - val_acc: 0.9286\n",
      "\n",
      "kappa improvement: 0.6958433443488672 (before: 0.6856614500056528), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0485 - acc: 0.9921 - val_loss: 0.8961 - val_acc: 0.9278\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0350 - acc: 0.9940 - val_loss: 0.8961 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0249 - acc: 0.9952 - val_loss: 0.8897 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0185 - acc: 0.9965 - val_loss: 0.8886 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0128 - acc: 0.9974 - val_loss: 0.8902 - val_acc: 0.9219\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0100 - acc: 0.9976 - val_loss: 0.8895 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.8958 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.9190 - val_acc: 0.9185\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 927us/step - loss: 0.3639 - acc: 0.9200 - val_loss: 0.9084 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6784093375857865 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0686 - acc: 0.9894 - val_loss: 0.9287 - val_acc: 0.9248\n",
      "\n",
      "kappa improvement: 0.6824214856194285 (before: 0.6784093375857865), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0481 - acc: 0.9929 - val_loss: 0.9407 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.684553359427548 (before: 0.6824214856194285), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0426 - acc: 0.9941 - val_loss: 0.9439 - val_acc: 0.9238\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0301 - acc: 0.9953 - val_loss: 0.9457 - val_acc: 0.9219\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0240 - acc: 0.9961 - val_loss: 0.9446 - val_acc: 0.9215\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0192 - acc: 0.9967 - val_loss: 0.9504 - val_acc: 0.9219\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0147 - acc: 0.9973 - val_loss: 0.9521 - val_acc: 0.9207\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0105 - acc: 0.9978 - val_loss: 0.9571 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.9549 - val_acc: 0.9201\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 940us/step - loss: 0.3703 - acc: 0.9092 - val_loss: 0.9135 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.6726283388279621 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0645 - acc: 0.9904 - val_loss: 0.9251 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6828509181450357 (before: 0.6726283388279621), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0498 - acc: 0.9929 - val_loss: 0.9546 - val_acc: 0.9229\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0384 - acc: 0.9940 - val_loss: 0.9568 - val_acc: 0.9235\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0273 - acc: 0.9958 - val_loss: 0.9555 - val_acc: 0.9233\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0221 - acc: 0.9963 - val_loss: 0.9614 - val_acc: 0.9213\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0184 - acc: 0.9972 - val_loss: 0.9643 - val_acc: 0.9211\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0153 - acc: 0.9973 - val_loss: 0.9691 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0121 - acc: 0.9978 - val_loss: 0.9694 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0084 - acc: 0.9985 - val_loss: 0.9664 - val_acc: 0.9201\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 15s 861us/step - loss: 1.0900 - acc: 0.7968 - val_loss: 0.8996 - val_acc: 0.9227\n",
      "\n",
      "kappa improvement: 0.6512880643424184 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0882 - acc: 0.9867 - val_loss: 0.9156 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6771101856248922 (before: 0.6512880643424184), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0678 - acc: 0.9903 - val_loss: 0.9343 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6843147756016775 (before: 0.6771101856248922), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0517 - acc: 0.9925 - val_loss: 0.9449 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6870204995821033 (before: 0.6843147756016775), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0459 - acc: 0.9936 - val_loss: 0.9513 - val_acc: 0.9256\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0395 - acc: 0.9944 - val_loss: 0.9518 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0324 - acc: 0.9957 - val_loss: 0.9538 - val_acc: 0.9244\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0291 - acc: 0.9958 - val_loss: 0.9563 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0223 - acc: 0.9966 - val_loss: 0.9587 - val_acc: 0.9231\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0210 - acc: 0.9966 - val_loss: 0.9574 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 15s 861us/step - loss: 0.6183 - acc: 0.8542 - val_loss: 0.8929 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6852154891712725 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0696 - acc: 0.9890 - val_loss: 0.9234 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6900067190726855 (before: 0.6852154891712725), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0563 - acc: 0.9917 - val_loss: 0.9419 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6907460943443557 (before: 0.6900067190726855), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0505 - acc: 0.9927 - val_loss: 0.9496 - val_acc: 0.9272\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0393 - acc: 0.9942 - val_loss: 0.9512 - val_acc: 0.9258\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0346 - acc: 0.9948 - val_loss: 0.9521 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0275 - acc: 0.9961 - val_loss: 0.9558 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0233 - acc: 0.9964 - val_loss: 0.9585 - val_acc: 0.9231\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0204 - acc: 0.9967 - val_loss: 0.9544 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0157 - acc: 0.9971 - val_loss: 0.9556 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 904us/step - loss: 0.3639 - acc: 0.9011 - val_loss: 0.8880 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6888650417302778 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0733 - acc: 0.9891 - val_loss: 0.9149 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6922444562882568 (before: 0.6888650417302778), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0524 - acc: 0.9918 - val_loss: 0.9284 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0418 - acc: 0.9936 - val_loss: 0.9345 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0335 - acc: 0.9949 - val_loss: 0.9366 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0266 - acc: 0.9958 - val_loss: 0.9367 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0193 - acc: 0.9967 - val_loss: 0.9393 - val_acc: 0.9221\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0146 - acc: 0.9971 - val_loss: 0.9401 - val_acc: 0.9207\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0121 - acc: 0.9976 - val_loss: 0.9409 - val_acc: 0.9205\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0096 - acc: 0.9981 - val_loss: 0.9410 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 944us/step - loss: 1.4046 - acc: 0.7953 - val_loss: 0.8756 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6711339855958689 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0659 - acc: 0.9899 - val_loss: 0.9108 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6808835287846482 (before: 0.6711339855958689), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0586 - acc: 0.9915 - val_loss: 0.9381 - val_acc: 0.9254\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0435 - acc: 0.9934 - val_loss: 0.9428 - val_acc: 0.9262\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0356 - acc: 0.9945 - val_loss: 0.9543 - val_acc: 0.9256\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0311 - acc: 0.9959 - val_loss: 0.9656 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0278 - acc: 0.9961 - val_loss: 0.9693 - val_acc: 0.9242\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0226 - acc: 0.9966 - val_loss: 0.9770 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0207 - acc: 0.9968 - val_loss: 0.9742 - val_acc: 0.9231\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0183 - acc: 0.9972 - val_loss: 0.9708 - val_acc: 0.9225\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 15s 879us/step - loss: 0.4570 - acc: 0.8878 - val_loss: 0.9238 - val_acc: 0.9237\n",
      "\n",
      "kappa improvement: 0.6668325257508836 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0638 - acc: 0.9898 - val_loss: 0.9576 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.6709515922450802 (before: 0.6668325257508836), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0491 - acc: 0.9929 - val_loss: 0.9501 - val_acc: 0.9237\n",
      "\n",
      "kappa improvement: 0.6732049152283867 (before: 0.6709515922450802), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0406 - acc: 0.9946 - val_loss: 0.9745 - val_acc: 0.9240\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0308 - acc: 0.9956 - val_loss: 0.9845 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0250 - acc: 0.9958 - val_loss: 0.9779 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0211 - acc: 0.9967 - val_loss: 0.9733 - val_acc: 0.9219\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0167 - acc: 0.9970 - val_loss: 0.9742 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0148 - acc: 0.9972 - val_loss: 0.9721 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0116 - acc: 0.9979 - val_loss: 0.9809 - val_acc: 0.9203\n",
      "400_0.6\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 15s 875us/step - loss: 1.1861 - acc: 0.8052 - val_loss: 0.8670 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6711339855958689 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0736 - acc: 0.9889 - val_loss: 0.9036 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.68400211171294 (before: 0.6711339855958689), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0530 - acc: 0.9917 - val_loss: 0.9278 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6879535127505644 (before: 0.68400211171294), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0462 - acc: 0.9933 - val_loss: 0.9380 - val_acc: 0.9266\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0390 - acc: 0.9945 - val_loss: 0.9440 - val_acc: 0.9260\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0321 - acc: 0.9953 - val_loss: 0.9563 - val_acc: 0.9252\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0282 - acc: 0.9957 - val_loss: 0.9568 - val_acc: 0.9246\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0237 - acc: 0.9967 - val_loss: 0.9592 - val_acc: 0.9240\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0210 - acc: 0.9967 - val_loss: 0.9587 - val_acc: 0.9231\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0193 - acc: 0.9969 - val_loss: 0.9582 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 901us/step - loss: 1.0922 - acc: 0.8108 - val_loss: 0.8534 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6676722380758255 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0679 - acc: 0.9891 - val_loss: 0.8894 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6818124133785295 (before: 0.6676722380758255), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0557 - acc: 0.9911 - val_loss: 0.9119 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6923431003761631 (before: 0.6818124133785295), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0494 - acc: 0.9931 - val_loss: 0.9211 - val_acc: 0.9272\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0400 - acc: 0.9934 - val_loss: 0.9257 - val_acc: 0.9256\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0335 - acc: 0.9951 - val_loss: 0.9316 - val_acc: 0.9258\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0270 - acc: 0.9954 - val_loss: 0.9342 - val_acc: 0.9246\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0232 - acc: 0.9961 - val_loss: 0.9364 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0205 - acc: 0.9965 - val_loss: 0.9359 - val_acc: 0.9240\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0176 - acc: 0.9969 - val_loss: 0.9373 - val_acc: 0.9231\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 896us/step - loss: 0.5441 - acc: 0.8757 - val_loss: 0.8762 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6812684574366312 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0739 - acc: 0.9881 - val_loss: 0.9029 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6912789439515257 (before: 0.6812684574366312), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0576 - acc: 0.9914 - val_loss: 0.9181 - val_acc: 0.9268\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0443 - acc: 0.9936 - val_loss: 0.9263 - val_acc: 0.9264\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0382 - acc: 0.9943 - val_loss: 0.9271 - val_acc: 0.9256\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0331 - acc: 0.9953 - val_loss: 0.9269 - val_acc: 0.9254\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0254 - acc: 0.9957 - val_loss: 0.9298 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0209 - acc: 0.9967 - val_loss: 0.9288 - val_acc: 0.9242\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0170 - acc: 0.9972 - val_loss: 0.9250 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0152 - acc: 0.9974 - val_loss: 0.9212 - val_acc: 0.9225\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 16s 901us/step - loss: 0.4994 - acc: 0.8836 - val_loss: 0.8860 - val_acc: 0.9289\n",
      "\n",
      "kappa improvement: 0.6923940326386978 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0750 - acc: 0.9887 - val_loss: 0.9153 - val_acc: 0.9274\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0588 - acc: 0.9918 - val_loss: 0.9344 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6956198124525623 (before: 0.6923940326386978), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0459 - acc: 0.9932 - val_loss: 0.9415 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0397 - acc: 0.9946 - val_loss: 0.9507 - val_acc: 0.9260\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0322 - acc: 0.9952 - val_loss: 0.9526 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0264 - acc: 0.9964 - val_loss: 0.9537 - val_acc: 0.9237\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0201 - acc: 0.9969 - val_loss: 0.9522 - val_acc: 0.9231\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0179 - acc: 0.9968 - val_loss: 0.9515 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0155 - acc: 0.9971 - val_loss: 0.9517 - val_acc: 0.9213\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 17s 975us/step - loss: 0.6413 - acc: 0.8605 - val_loss: 0.8815 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6824176917210968 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0720 - acc: 0.9887 - val_loss: 0.9122 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6920083261029846 (before: 0.6824176917210968), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0609 - acc: 0.9908 - val_loss: 0.9283 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.692371726278872 (before: 0.6920083261029846), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0473 - acc: 0.9930 - val_loss: 0.9374 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0422 - acc: 0.9939 - val_loss: 0.9378 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0369 - acc: 0.9948 - val_loss: 0.9400 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0288 - acc: 0.9952 - val_loss: 0.9415 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0234 - acc: 0.9964 - val_loss: 0.9422 - val_acc: 0.9223\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0218 - acc: 0.9968 - val_loss: 0.9439 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0171 - acc: 0.9969 - val_loss: 0.9413 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 17s 974us/step - loss: 0.2292 - acc: 0.9442 - val_loss: 0.8898 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.6885786517752852 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0590 - acc: 0.9916 - val_loss: 0.9037 - val_acc: 0.9246\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0400 - acc: 0.9936 - val_loss: 0.9107 - val_acc: 0.9238\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0308 - acc: 0.9953 - val_loss: 0.9099 - val_acc: 0.9225\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0207 - acc: 0.9961 - val_loss: 0.9268 - val_acc: 0.9217\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0154 - acc: 0.9967 - val_loss: 0.9192 - val_acc: 0.9205\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.9183 - val_acc: 0.9193\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0090 - acc: 0.9979 - val_loss: 0.9146 - val_acc: 0.9205\n",
      "\n",
      "kappa improvement: 0.6844861700982705 (before: 0.6780195437561127), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0351 - acc: 0.9951 - val_loss: 0.9669 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0252 - acc: 0.9962 - val_loss: 0.9699 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0225 - acc: 0.9967 - val_loss: 0.9687 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0173 - acc: 0.9968 - val_loss: 0.9716 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0147 - acc: 0.9971 - val_loss: 0.9695 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0132 - acc: 0.9975 - val_loss: 0.9709 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 17s 979us/step - loss: 0.8123 - acc: 0.8376 - val_loss: 0.8919 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6639476464071317 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0651 - acc: 0.9890 - val_loss: 0.9104 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.682963837982181 (before: 0.6639476464071317), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0523 - acc: 0.9918 - val_loss: 0.9305 - val_acc: 0.9252\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0455 - acc: 0.9933 - val_loss: 0.9434 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6834975803444475 (before: 0.682963837982181), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0392 - acc: 0.9940 - val_loss: 0.9519 - val_acc: 0.9254\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0343 - acc: 0.9949 - val_loss: 0.9580 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0274 - acc: 0.9957 - val_loss: 0.9586 - val_acc: 0.9231\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0222 - acc: 0.9969 - val_loss: 0.9572 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0185 - acc: 0.9968 - val_loss: 0.9571 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0156 - acc: 0.9969 - val_loss: 0.9580 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "\n",
      "kappa improvement: 0.6878585352269563 (before: 0.6876731290527236), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0425 - acc: 0.9941 - val_loss: 0.9517 - val_acc: 0.9254\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0374 - acc: 0.9944 - val_loss: 0.9573 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0309 - acc: 0.9956 - val_loss: 0.9601 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0227 - acc: 0.9965 - val_loss: 0.9656 - val_acc: 0.9231\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0208 - acc: 0.9967 - val_loss: 0.9653 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0184 - acc: 0.9973 - val_loss: 0.9617 - val_acc: 0.9213\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 17s 986us/step - loss: 0.3792 - acc: 0.9263 - val_loss: 0.9391 - val_acc: 0.9223\n",
      "\n",
      "kappa improvement: 0.6626871410778323 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0638 - acc: 0.9901 - val_loss: 0.9424 - val_acc: 0.9219\n",
      "\n",
      "kappa improvement: 0.6678280668992744 (before: 0.6626871410778323), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0442 - acc: 0.9932 - val_loss: 0.9616 - val_acc: 0.9223\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0324 - acc: 0.9950 - val_loss: 0.9587 - val_acc: 0.9229\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0228 - acc: 0.9958 - val_loss: 0.9576 - val_acc: 0.9197\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0178 - acc: 0.9969 - val_loss: 0.9647 - val_acc: 0.9203\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0136 - acc: 0.9970 - val_loss: 0.9698 - val_acc: 0.9195\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 0.9978 - val_loss: 0.9759 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.9626 - val_acc: 0.9193\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0062 - acc: 0.9986 - val_loss: 0.9678 - val_acc: 0.9195\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 17s 999us/step - loss: 0.3710 - acc: 0.9181 - val_loss: 0.8741 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6925272920686154 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0646 - acc: 0.9895 - val_loss: 0.8963 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6936791679392994 (before: 0.6925272920686154), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0537 - acc: 0.9921 - val_loss: 0.9065 - val_acc: 0.9276\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0374 - acc: 0.9934 - val_loss: 0.9156 - val_acc: 0.9264\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0294 - acc: 0.9949 - val_loss: 0.9235 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0201 - acc: 0.9959 - val_loss: 0.9162 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0160 - acc: 0.9971 - val_loss: 0.9223 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0131 - acc: 0.9974 - val_loss: 0.9239 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.9219 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.9258 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 17s 1ms/step - loss: 0.4062 - acc: 0.9221 - val_loss: 0.8847 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6819975907315929 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0778 - acc: 0.9885 - val_loss: 0.9003 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6893523057782465 (before: 0.6819975907315929), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0534 - acc: 0.9921 - val_loss: 0.9096 - val_acc: 0.9256\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0383 - acc: 0.9937 - val_loss: 0.9110 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0289 - acc: 0.9950 - val_loss: 0.9073 - val_acc: 0.9229\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0237 - acc: 0.9959 - val_loss: 0.9069 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0175 - acc: 0.9969 - val_loss: 0.9138 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0156 - acc: 0.9975 - val_loss: 0.9116 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0103 - acc: 0.9977 - val_loss: 0.9119 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0086 - acc: 0.9980 - val_loss: 0.9100 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 17s 994us/step - loss: 0.9101 - acc: 0.8338 - val_loss: 0.8817 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6853171184444362 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0743 - acc: 0.9887 - val_loss: 0.9109 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6910314825037696 (before: 0.6853171184444362), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0591 - acc: 0.9912 - val_loss: 0.9285 - val_acc: 0.9268\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0538 - acc: 0.9921 - val_loss: 0.9373 - val_acc: 0.9266\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0426 - acc: 0.9937 - val_loss: 0.9431 - val_acc: 0.9262\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0356 - acc: 0.9947 - val_loss: 0.9453 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0285 - acc: 0.9956 - val_loss: 0.9498 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0242 - acc: 0.9964 - val_loss: 0.9507 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0186 - acc: 0.9969 - val_loss: 0.9499 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0164 - acc: 0.9973 - val_loss: 0.9518 - val_acc: 0.9201\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.6815 - acc: 0.8652 - val_loss: 0.8730 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6912351290266499 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0731 - acc: 0.9888 - val_loss: 0.9071 - val_acc: 0.9274\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0567 - acc: 0.9918 - val_loss: 0.9224 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0461 - acc: 0.9927 - val_loss: 0.9350 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0396 - acc: 0.9940 - val_loss: 0.9351 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0302 - acc: 0.9950 - val_loss: 0.9412 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0253 - acc: 0.9961 - val_loss: 0.9422 - val_acc: 0.9221\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0221 - acc: 0.9965 - val_loss: 0.9404 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0172 - acc: 0.9972 - val_loss: 0.9427 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.9455 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.4662 - acc: 0.8992 - val_loss: 0.8955 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6802279074219741 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0697 - acc: 0.9893 - val_loss: 0.9189 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6845891301387106 (before: 0.6802279074219741), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0516 - acc: 0.9919 - val_loss: 0.9339 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.685140805109492 (before: 0.6845891301387106), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0433 - acc: 0.9933 - val_loss: 0.9436 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0308 - acc: 0.9954 - val_loss: 0.9474 - val_acc: 0.9237\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0278 - acc: 0.9956 - val_loss: 0.9595 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0217 - acc: 0.9967 - val_loss: 0.9616 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0175 - acc: 0.9972 - val_loss: 0.9608 - val_acc: 0.9207\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0130 - acc: 0.9977 - val_loss: 0.9620 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0095 - acc: 0.9978 - val_loss: 0.9585 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.5752 - acc: 0.8862 - val_loss: 0.8880 - val_acc: 0.9248\n",
      "\n",
      "kappa improvement: 0.6751386963995123 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0702 - acc: 0.9891 - val_loss: 0.9150 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6839371741569327 (before: 0.6751386963995123), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0550 - acc: 0.9918 - val_loss: 0.9351 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6867424522641152 (before: 0.6839371741569327), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0430 - acc: 0.9938 - val_loss: 0.9430 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0344 - acc: 0.9949 - val_loss: 0.9511 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0284 - acc: 0.9952 - val_loss: 0.9506 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0231 - acc: 0.9965 - val_loss: 0.9536 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0193 - acc: 0.9967 - val_loss: 0.9603 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0173 - acc: 0.9972 - val_loss: 0.9645 - val_acc: 0.9227\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0139 - acc: 0.9975 - val_loss: 0.9605 - val_acc: 0.9229\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.6546 - acc: 0.8689 - val_loss: 0.8817 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6899201217192849 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0722 - acc: 0.9891 - val_loss: 0.9139 - val_acc: 0.9268\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0639 - acc: 0.9911 - val_loss: 0.9330 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0479 - acc: 0.9929 - val_loss: 0.9469 - val_acc: 0.9240\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0433 - acc: 0.9941 - val_loss: 0.9421 - val_acc: 0.9237\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0314 - acc: 0.9954 - val_loss: 0.9432 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0262 - acc: 0.9956 - val_loss: 0.9410 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0196 - acc: 0.9963 - val_loss: 0.9389 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0160 - acc: 0.9971 - val_loss: 0.9427 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0129 - acc: 0.9975 - val_loss: 0.9489 - val_acc: 0.9207\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 17s 1ms/step - loss: 0.8333 - acc: 0.8495 - val_loss: 0.8923 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6819739248619897 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0829 - acc: 0.9877 - val_loss: 0.9204 - val_acc: 0.9280\n",
      "\n",
      "kappa improvement: 0.6905772309627136 (before: 0.6819739248619897), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0616 - acc: 0.9905 - val_loss: 0.9363 - val_acc: 0.9268\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0466 - acc: 0.9933 - val_loss: 0.9470 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0419 - acc: 0.9942 - val_loss: 0.9517 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0350 - acc: 0.9940 - val_loss: 0.9557 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0276 - acc: 0.9958 - val_loss: 0.9546 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0211 - acc: 0.9964 - val_loss: 0.9530 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0191 - acc: 0.9972 - val_loss: 0.9532 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0169 - acc: 0.9971 - val_loss: 0.9554 - val_acc: 0.9213\n",
      "400_0.8\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 17s 1ms/step - loss: 0.7637 - acc: 0.8672 - val_loss: 0.8793 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6886082640259665 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0783 - acc: 0.9890 - val_loss: 0.9142 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.692371726278872 (before: 0.6886082640259665), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0582 - acc: 0.9911 - val_loss: 0.9346 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6935939338475618 (before: 0.692371726278872), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0475 - acc: 0.9928 - val_loss: 0.9404 - val_acc: 0.9266\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0388 - acc: 0.9940 - val_loss: 0.9485 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0313 - acc: 0.9949 - val_loss: 0.9495 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0280 - acc: 0.9956 - val_loss: 0.9496 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0251 - acc: 0.9966 - val_loss: 0.9523 - val_acc: 0.9223\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0184 - acc: 0.9968 - val_loss: 0.9556 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0153 - acc: 0.9969 - val_loss: 0.9583 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.5288 - acc: 0.8055 - val_loss: 0.8556 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.6694031118358472 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0758 - acc: 0.9877 - val_loss: 0.8978 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6795730768910813 (before: 0.6694031118358472), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0586 - acc: 0.9908 - val_loss: 0.9156 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6824176917210968 (before: 0.6795730768910813), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0531 - acc: 0.9915 - val_loss: 0.9230 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0405 - acc: 0.9937 - val_loss: 0.9298 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0337 - acc: 0.9944 - val_loss: 0.9343 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0319 - acc: 0.9948 - val_loss: 0.9319 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0241 - acc: 0.9953 - val_loss: 0.9315 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0221 - acc: 0.9962 - val_loss: 0.9333 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0180 - acc: 0.9966 - val_loss: 0.9344 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.6963 - acc: 0.8801 - val_loss: 0.8652 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6886185649640155 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0717 - acc: 0.9886 - val_loss: 0.8956 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6914001678818902 (before: 0.6886185649640155), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0608 - acc: 0.9907 - val_loss: 0.9113 - val_acc: 0.9268\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0439 - acc: 0.9931 - val_loss: 0.9208 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0372 - acc: 0.9946 - val_loss: 0.9240 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0275 - acc: 0.9955 - val_loss: 0.9292 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0226 - acc: 0.9959 - val_loss: 0.9363 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0202 - acc: 0.9963 - val_loss: 0.9421 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0161 - acc: 0.9971 - val_loss: 0.9372 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0158 - acc: 0.9972 - val_loss: 0.9344 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.6982 - acc: 0.8828 - val_loss: 0.8732 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6858761168406411 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0775 - acc: 0.9884 - val_loss: 0.9032 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6907460943443557 (before: 0.6858761168406411), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0575 - acc: 0.9910 - val_loss: 0.9237 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0483 - acc: 0.9929 - val_loss: 0.9313 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0407 - acc: 0.9937 - val_loss: 0.9288 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0308 - acc: 0.9953 - val_loss: 0.9293 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0261 - acc: 0.9957 - val_loss: 0.9342 - val_acc: 0.9219\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0205 - acc: 0.9968 - val_loss: 0.9360 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0168 - acc: 0.9966 - val_loss: 0.9345 - val_acc: 0.9205\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0155 - acc: 0.9973 - val_loss: 0.9400 - val_acc: 0.9195\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.7293 - acc: 0.8746 - val_loss: 0.8644 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6873908290136056 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0718 - acc: 0.9892 - val_loss: 0.9031 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6904320561453672 (before: 0.6873908290136056), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0595 - acc: 0.9915 - val_loss: 0.9216 - val_acc: 0.9264\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 14us/step - loss: 0.0460 - acc: 0.9924 - val_loss: 0.9279 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0358 - acc: 0.9944 - val_loss: 0.9406 - val_acc: 0.9237\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0323 - acc: 0.9953 - val_loss: 0.9398 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0217 - acc: 0.9960 - val_loss: 0.9438 - val_acc: 0.9231\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0193 - acc: 0.9968 - val_loss: 0.9484 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0157 - acc: 0.9967 - val_loss: 0.9417 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0139 - acc: 0.9967 - val_loss: 0.9427 - val_acc: 0.9197\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.0508 - acc: 0.8469 - val_loss: 0.8669 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6786766089673084 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0736 - acc: 0.9881 - val_loss: 0.8995 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6898960233640654 (before: 0.6786766089673084), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0636 - acc: 0.9910 - val_loss: 0.9202 - val_acc: 0.9264\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0503 - acc: 0.9924 - val_loss: 0.9280 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0404 - acc: 0.9941 - val_loss: 0.9316 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0352 - acc: 0.9948 - val_loss: 0.9321 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0290 - acc: 0.9951 - val_loss: 0.9344 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0233 - acc: 0.9959 - val_loss: 0.9399 - val_acc: 0.9231\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0201 - acc: 0.9963 - val_loss: 0.9483 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0167 - acc: 0.9969 - val_loss: 0.9442 - val_acc: 0.9223\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.1734 - acc: 0.8389 - val_loss: 0.8549 - val_acc: 0.9289\n",
      "\n",
      "kappa improvement: 0.6931361212554801 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0712 - acc: 0.9882 - val_loss: 0.8870 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6952591842070859 (before: 0.6931361212554801), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0551 - acc: 0.9914 - val_loss: 0.9097 - val_acc: 0.9272\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0456 - acc: 0.9933 - val_loss: 0.9197 - val_acc: 0.9262\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0370 - acc: 0.9947 - val_loss: 0.9356 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0317 - acc: 0.9950 - val_loss: 0.9350 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0290 - acc: 0.9955 - val_loss: 0.9402 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0231 - acc: 0.9960 - val_loss: 0.9457 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0203 - acc: 0.9964 - val_loss: 0.9499 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0180 - acc: 0.9968 - val_loss: 0.9501 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.4048 - acc: 0.9222 - val_loss: 0.8942 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6898724341125428 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0792 - acc: 0.9884 - val_loss: 0.9084 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6941721539332015 (before: 0.6898724341125428), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0589 - acc: 0.9914 - val_loss: 0.9228 - val_acc: 0.9254\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0430 - acc: 0.9944 - val_loss: 0.9224 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0344 - acc: 0.9951 - val_loss: 0.9248 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0265 - acc: 0.9954 - val_loss: 0.9269 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0183 - acc: 0.9969 - val_loss: 0.9251 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0145 - acc: 0.9973 - val_loss: 0.9422 - val_acc: 0.9195\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0127 - acc: 0.9975 - val_loss: 0.9385 - val_acc: 0.9195\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0095 - acc: 0.9979 - val_loss: 0.9343 - val_acc: 0.9185\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.0382 - acc: 0.8407 - val_loss: 0.8705 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6782864296989821 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0735 - acc: 0.9883 - val_loss: 0.8986 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6852418668803013 (before: 0.6782864296989821), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0597 - acc: 0.9906 - val_loss: 0.9146 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.685717575553207 (before: 0.6852418668803013), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0507 - acc: 0.9926 - val_loss: 0.9228 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0415 - acc: 0.9934 - val_loss: 0.9286 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0392 - acc: 0.9943 - val_loss: 0.9306 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0267 - acc: 0.9948 - val_loss: 0.9299 - val_acc: 0.9244\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0264 - acc: 0.9956 - val_loss: 0.9355 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0197 - acc: 0.9962 - val_loss: 0.9352 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0187 - acc: 0.9969 - val_loss: 0.9309 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.6164 - acc: 0.8851 - val_loss: 0.8726 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6821460928418066 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0748 - acc: 0.9883 - val_loss: 0.9026 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6880417524975777 (before: 0.6821460928418066), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0647 - acc: 0.9908 - val_loss: 0.9177 - val_acc: 0.9264\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0514 - acc: 0.9923 - val_loss: 0.9259 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0384 - acc: 0.9938 - val_loss: 0.9267 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0280 - acc: 0.9952 - val_loss: 0.9265 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0225 - acc: 0.9962 - val_loss: 0.9303 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0198 - acc: 0.9960 - val_loss: 0.9275 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0188 - acc: 0.9967 - val_loss: 0.9262 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0131 - acc: 0.9970 - val_loss: 0.9278 - val_acc: 0.9197\n",
      "400_0.9\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.9445 - acc: 0.8757 - val_loss: 0.8985 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6772371144386998 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0911 - acc: 0.9873 - val_loss: 0.9217 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.688319474068425 (before: 0.6772371144386998), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0658 - acc: 0.9904 - val_loss: 0.9386 - val_acc: 0.9252\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0567 - acc: 0.9921 - val_loss: 0.9444 - val_acc: 0.9240\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0411 - acc: 0.9943 - val_loss: 0.9469 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0392 - acc: 0.9937 - val_loss: 0.9511 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0326 - acc: 0.9949 - val_loss: 0.9540 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0284 - acc: 0.9956 - val_loss: 0.9544 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0244 - acc: 0.9960 - val_loss: 0.9583 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0245 - acc: 0.9960 - val_loss: 0.9601 - val_acc: 0.9213\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.1221 - acc: 0.8588 - val_loss: 0.8831 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6873908290136056 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0878 - acc: 0.9871 - val_loss: 0.9139 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6907460943443557 (before: 0.6873908290136056), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0726 - acc: 0.9896 - val_loss: 0.9292 - val_acc: 0.9268\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0560 - acc: 0.9912 - val_loss: 0.9370 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0429 - acc: 0.9933 - val_loss: 0.9413 - val_acc: 0.9242\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0353 - acc: 0.9945 - val_loss: 0.9477 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0331 - acc: 0.9946 - val_loss: 0.9482 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0332 - acc: 0.9945 - val_loss: 0.9566 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0244 - acc: 0.9957 - val_loss: 0.9614 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0225 - acc: 0.9961 - val_loss: 0.9592 - val_acc: 0.9199\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 0.9903 - acc: 0.8714 - val_loss: 0.8677 - val_acc: 0.9289\n",
      "\n",
      "kappa improvement: 0.6927655250533049 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0847 - acc: 0.9879 - val_loss: 0.8971 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6928661523088768 (before: 0.6927655250533049), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0650 - acc: 0.9905 - val_loss: 0.9137 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0499 - acc: 0.9923 - val_loss: 0.9244 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0466 - acc: 0.9932 - val_loss: 0.9271 - val_acc: 0.9254\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0358 - acc: 0.9937 - val_loss: 0.9293 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0321 - acc: 0.9948 - val_loss: 0.9320 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0289 - acc: 0.9951 - val_loss: 0.9359 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0232 - acc: 0.9961 - val_loss: 0.9350 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0166 - acc: 0.9967 - val_loss: 0.9388 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 1.0934 - acc: 0.8578 - val_loss: 0.8705 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6830216364192795 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0944 - acc: 0.9861 - val_loss: 0.9053 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6899817702067267 (before: 0.6830216364192795), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0692 - acc: 0.9903 - val_loss: 0.9209 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0576 - acc: 0.9916 - val_loss: 0.9260 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0453 - acc: 0.9935 - val_loss: 0.9298 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0402 - acc: 0.9936 - val_loss: 0.9301 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0347 - acc: 0.9949 - val_loss: 0.9292 - val_acc: 0.9231\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0270 - acc: 0.9953 - val_loss: 0.9288 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0205 - acc: 0.9962 - val_loss: 0.9367 - val_acc: 0.9225\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0256 - acc: 0.9959 - val_loss: 0.9366 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 1.4747 - acc: 0.8323 - val_loss: 0.8671 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6780383615659742 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0926 - acc: 0.9866 - val_loss: 0.8942 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6885173112209184 (before: 0.6780383615659742), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0662 - acc: 0.9903 - val_loss: 0.9147 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6885981827689894 (before: 0.6885173112209184), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0554 - acc: 0.9914 - val_loss: 0.9244 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0449 - acc: 0.9932 - val_loss: 0.9304 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0368 - acc: 0.9946 - val_loss: 0.9309 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0380 - acc: 0.9944 - val_loss: 0.9322 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0261 - acc: 0.9956 - val_loss: 0.9330 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0253 - acc: 0.9958 - val_loss: 0.9374 - val_acc: 0.9203\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0215 - acc: 0.9963 - val_loss: 0.9395 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.3047 - acc: 0.8436 - val_loss: 0.8642 - val_acc: 0.9289\n",
      "\n",
      "kappa improvement: 0.6938746379638006 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0916 - acc: 0.9863 - val_loss: 0.8950 - val_acc: 0.9278\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0728 - acc: 0.9898 - val_loss: 0.9152 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0620 - acc: 0.9911 - val_loss: 0.9251 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0478 - acc: 0.9929 - val_loss: 0.9291 - val_acc: 0.9246\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0414 - acc: 0.9936 - val_loss: 0.9338 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0359 - acc: 0.9942 - val_loss: 0.9298 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0268 - acc: 0.9951 - val_loss: 0.9305 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0231 - acc: 0.9955 - val_loss: 0.9294 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0234 - acc: 0.9954 - val_loss: 0.9319 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.0904 - acc: 0.8622 - val_loss: 0.8722 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6900067190726855 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0935 - acc: 0.9865 - val_loss: 0.9015 - val_acc: 0.9266\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0684 - acc: 0.9904 - val_loss: 0.9190 - val_acc: 0.9264\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0566 - acc: 0.9921 - val_loss: 0.9303 - val_acc: 0.9246\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0458 - acc: 0.9933 - val_loss: 0.9289 - val_acc: 0.9242\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0335 - acc: 0.9940 - val_loss: 0.9297 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0265 - acc: 0.9950 - val_loss: 0.9309 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0272 - acc: 0.9953 - val_loss: 0.9306 - val_acc: 0.9207\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0153 - acc: 0.9963 - val_loss: 0.9327 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0182 - acc: 0.9964 - val_loss: 0.9358 - val_acc: 0.9203\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.1845 - acc: 0.8520 - val_loss: 0.8720 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6867324725393422 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0876 - acc: 0.9873 - val_loss: 0.9089 - val_acc: 0.9289\n",
      "\n",
      "kappa improvement: 0.6982321517682573 (before: 0.6867324725393422), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0698 - acc: 0.9903 - val_loss: 0.9302 - val_acc: 0.9266\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0544 - acc: 0.9929 - val_loss: 0.9345 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0512 - acc: 0.9931 - val_loss: 0.9354 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0423 - acc: 0.9943 - val_loss: 0.9339 - val_acc: 0.9256\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0352 - acc: 0.9945 - val_loss: 0.9390 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0260 - acc: 0.9959 - val_loss: 0.9419 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0275 - acc: 0.9957 - val_loss: 0.9392 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0253 - acc: 0.9959 - val_loss: 0.9411 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.2470 - acc: 0.8526 - val_loss: 0.9024 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6683915895256884 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0984 - acc: 0.9869 - val_loss: 0.9248 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6866463583038258 (before: 0.6683915895256884), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0720 - acc: 0.9903 - val_loss: 0.9469 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0582 - acc: 0.9922 - val_loss: 0.9543 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0482 - acc: 0.9934 - val_loss: 0.9493 - val_acc: 0.9244\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0415 - acc: 0.9933 - val_loss: 0.9560 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0394 - acc: 0.9942 - val_loss: 0.9507 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0285 - acc: 0.9957 - val_loss: 0.9518 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0233 - acc: 0.9957 - val_loss: 0.9561 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0217 - acc: 0.9963 - val_loss: 0.9554 - val_acc: 0.9195\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 18s 1ms/step - loss: 1.1892 - acc: 0.8565 - val_loss: 0.8793 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.68493684969352 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0923 - acc: 0.9869 - val_loss: 0.9124 - val_acc: 0.9260\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0766 - acc: 0.9895 - val_loss: 0.9285 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6950391984645913 (before: 0.68493684969352), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0571 - acc: 0.9917 - val_loss: 0.9398 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0453 - acc: 0.9930 - val_loss: 0.9406 - val_acc: 0.9233\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0400 - acc: 0.9939 - val_loss: 0.9442 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0311 - acc: 0.9953 - val_loss: 0.9447 - val_acc: 0.9219\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0262 - acc: 0.9956 - val_loss: 0.9460 - val_acc: 0.9203\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0221 - acc: 0.9960 - val_loss: 0.9421 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0218 - acc: 0.9963 - val_loss: 0.9454 - val_acc: 0.9207\n",
      "500_0.1\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.4169 - acc: 0.8666 - val_loss: 0.9116 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6832271206407121 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0798 - acc: 0.9882 - val_loss: 0.9338 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6899817702067267 (before: 0.6832271206407121), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0643 - acc: 0.9911 - val_loss: 0.9475 - val_acc: 0.9276\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0528 - acc: 0.9926 - val_loss: 0.9578 - val_acc: 0.9262\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0426 - acc: 0.9943 - val_loss: 0.9629 - val_acc: 0.9262\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0344 - acc: 0.9952 - val_loss: 0.9660 - val_acc: 0.9246\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0283 - acc: 0.9963 - val_loss: 0.9660 - val_acc: 0.9244\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0220 - acc: 0.9969 - val_loss: 0.9646 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0185 - acc: 0.9973 - val_loss: 0.9647 - val_acc: 0.9235\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0150 - acc: 0.9978 - val_loss: 0.9727 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 1.6613 - acc: 0.7577 - val_loss: 0.8926 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6697626692547447 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0724 - acc: 0.9887 - val_loss: 0.9244 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6815399424125875 (before: 0.6697626692547447), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0629 - acc: 0.9911 - val_loss: 0.9461 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6886082640259665 (before: 0.6815399424125875), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0551 - acc: 0.9925 - val_loss: 0.9559 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6914819509913724 (before: 0.6886082640259665), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0479 - acc: 0.9936 - val_loss: 0.9612 - val_acc: 0.9266\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0407 - acc: 0.9948 - val_loss: 0.9639 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0354 - acc: 0.9952 - val_loss: 0.9651 - val_acc: 0.9256\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0315 - acc: 0.9958 - val_loss: 0.9656 - val_acc: 0.9250\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0277 - acc: 0.9963 - val_loss: 0.9701 - val_acc: 0.9246\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0239 - acc: 0.9966 - val_loss: 0.9689 - val_acc: 0.9250\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.3334 - acc: 0.8817 - val_loss: 0.9293 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6848644715299255 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0827 - acc: 0.9881 - val_loss: 0.9495 - val_acc: 0.9284\n",
      "\n",
      "kappa improvement: 0.6937331966420046 (before: 0.6848644715299255), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0617 - acc: 0.9917 - val_loss: 0.9626 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0493 - acc: 0.9934 - val_loss: 0.9685 - val_acc: 0.9262\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0409 - acc: 0.9948 - val_loss: 0.9712 - val_acc: 0.9256\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0342 - acc: 0.9954 - val_loss: 0.9712 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0290 - acc: 0.9963 - val_loss: 0.9732 - val_acc: 0.9246\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0247 - acc: 0.9969 - val_loss: 0.9778 - val_acc: 0.9242\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0207 - acc: 0.9975 - val_loss: 0.9824 - val_acc: 0.9237\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0180 - acc: 0.9979 - val_loss: 0.9895 - val_acc: 0.9229\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.3753 - acc: 0.8765 - val_loss: 0.9384 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6659413643158038 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0698 - acc: 0.9899 - val_loss: 0.9478 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6864653973489557 (before: 0.6659413643158038), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0552 - acc: 0.9919 - val_loss: 0.9630 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6870204995821033 (before: 0.6864653973489557), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0442 - acc: 0.9940 - val_loss: 0.9735 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0355 - acc: 0.9951 - val_loss: 0.9876 - val_acc: 0.9242\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0291 - acc: 0.9961 - val_loss: 0.9962 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0240 - acc: 0.9963 - val_loss: 0.9968 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0187 - acc: 0.9971 - val_loss: 0.9994 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0154 - acc: 0.9978 - val_loss: 1.0004 - val_acc: 0.9205\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0120 - acc: 0.9981 - val_loss: 0.9985 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.5149 - acc: 0.9152 - val_loss: 0.9688 - val_acc: 0.9207\n",
      "\n",
      "kappa improvement: 0.6537744735248604 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0686 - acc: 0.9903 - val_loss: 0.9750 - val_acc: 0.9209\n",
      "\n",
      "kappa improvement: 0.6654430065215708 (before: 0.6537744735248604), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0455 - acc: 0.9929 - val_loss: 0.9785 - val_acc: 0.9221\n",
      "\n",
      "kappa improvement: 0.6684658031576403 (before: 0.6654430065215708), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0311 - acc: 0.9945 - val_loss: 0.9796 - val_acc: 0.9221\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0219 - acc: 0.9959 - val_loss: 0.9840 - val_acc: 0.9215\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0171 - acc: 0.9969 - val_loss: 0.9855 - val_acc: 0.9207\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0128 - acc: 0.9977 - val_loss: 0.9880 - val_acc: 0.9197\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0093 - acc: 0.9982 - val_loss: 0.9882 - val_acc: 0.9193\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0073 - acc: 0.9990 - val_loss: 0.9867 - val_acc: 0.9191\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.9881 - val_acc: 0.9191\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.2570 - acc: 0.9419 - val_loss: 0.9418 - val_acc: 0.9250\n",
      "\n",
      "kappa improvement: 0.6860290855709434 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0782 - acc: 0.9900 - val_loss: 0.9455 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6891585826862049 (before: 0.6860290855709434), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0530 - acc: 0.9927 - val_loss: 0.9559 - val_acc: 0.9252\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0394 - acc: 0.9946 - val_loss: 0.9658 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0295 - acc: 0.9957 - val_loss: 0.9678 - val_acc: 0.9254\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0202 - acc: 0.9968 - val_loss: 0.9612 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0141 - acc: 0.9975 - val_loss: 0.9532 - val_acc: 0.9215\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0100 - acc: 0.9984 - val_loss: 0.9613 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.9599 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0048 - acc: 0.9990 - val_loss: 0.9588 - val_acc: 0.9199\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.3830 - acc: 0.8986 - val_loss: 0.9352 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6765797264082605 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0716 - acc: 0.9890 - val_loss: 0.9518 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.685835753809207 (before: 0.6765797264082605), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0541 - acc: 0.9926 - val_loss: 0.9684 - val_acc: 0.9256\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0408 - acc: 0.9949 - val_loss: 0.9743 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0327 - acc: 0.9956 - val_loss: 0.9851 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0263 - acc: 0.9963 - val_loss: 0.9837 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0204 - acc: 0.9967 - val_loss: 0.9905 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0162 - acc: 0.9975 - val_loss: 0.9931 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0126 - acc: 0.9981 - val_loss: 0.9940 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0104 - acc: 0.9986 - val_loss: 1.0007 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.1049 - acc: 0.9762 - val_loss: 0.8765 - val_acc: 0.9244\n",
      "\n",
      "kappa improvement: 0.6807631121761879 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0324 - acc: 0.9943 - val_loss: 0.8963 - val_acc: 0.9238\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0171 - acc: 0.9967 - val_loss: 0.9038 - val_acc: 0.9199\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0097 - acc: 0.9975 - val_loss: 0.9346 - val_acc: 0.9178\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.9377 - val_acc: 0.9160\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.9453 - val_acc: 0.9168\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.9259 - val_acc: 0.9180\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 5.3472e-04 - acc: 0.9997 - val_loss: 0.9294 - val_acc: 0.9156\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.9245 - val_acc: 0.9184\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 1.5809e-04 - acc: 1.0000 - val_loss: 0.9237 - val_acc: 0.9185\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.2024 - acc: 0.9507 - val_loss: 0.9644 - val_acc: 0.9187\n",
      "\n",
      "kappa improvement: 0.6767409428063507 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0822 - acc: 0.9894 - val_loss: 0.9401 - val_acc: 0.9248\n",
      "\n",
      "kappa improvement: 0.6904565697584499 (before: 0.6767409428063507), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0490 - acc: 0.9932 - val_loss: 0.9373 - val_acc: 0.9266\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0337 - acc: 0.9952 - val_loss: 0.9409 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0250 - acc: 0.9965 - val_loss: 0.9393 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0165 - acc: 0.9974 - val_loss: 0.9357 - val_acc: 0.9219\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0110 - acc: 0.9982 - val_loss: 0.9372 - val_acc: 0.9217\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0078 - acc: 0.9985 - val_loss: 0.9415 - val_acc: 0.9197\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0066 - acc: 0.9989 - val_loss: 0.9562 - val_acc: 0.9184\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0059 - acc: 0.9986 - val_loss: 0.9474 - val_acc: 0.9191\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 1.4561 - acc: 0.7723 - val_loss: 0.9237 - val_acc: 0.9238\n",
      "\n",
      "kappa improvement: 0.6570303351000615 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0856 - acc: 0.9875 - val_loss: 0.9409 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6751346544289143 (before: 0.6570303351000615), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0619 - acc: 0.9911 - val_loss: 0.9609 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6902914625987991 (before: 0.6751346544289143), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0550 - acc: 0.9927 - val_loss: 0.9722 - val_acc: 0.9274\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0467 - acc: 0.9936 - val_loss: 0.9735 - val_acc: 0.9276\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0395 - acc: 0.9950 - val_loss: 0.9755 - val_acc: 0.9266\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0342 - acc: 0.9956 - val_loss: 0.9787 - val_acc: 0.9262\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0287 - acc: 0.9960 - val_loss: 0.9820 - val_acc: 0.9250\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0245 - acc: 0.9967 - val_loss: 0.9822 - val_acc: 0.9244\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0213 - acc: 0.9969 - val_loss: 0.9838 - val_acc: 0.9238\n",
      "500_0.2\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.5649 - acc: 0.8339 - val_loss: 0.9400 - val_acc: 0.9242\n",
      "\n",
      "kappa improvement: 0.6667621193893285 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0745 - acc: 0.9890 - val_loss: 0.9700 - val_acc: 0.9233\n",
      "\n",
      "kappa improvement: 0.6699465276080734 (before: 0.6667621193893285), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0603 - acc: 0.9917 - val_loss: 0.9801 - val_acc: 0.9238\n",
      "\n",
      "kappa improvement: 0.6722820861377276 (before: 0.6699465276080734), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0496 - acc: 0.9933 - val_loss: 0.9953 - val_acc: 0.9229\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0391 - acc: 0.9941 - val_loss: 0.9845 - val_acc: 0.9238\n",
      "\n",
      "kappa improvement: 0.673850062693856 (before: 0.6722820861377276), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0330 - acc: 0.9953 - val_loss: 0.9793 - val_acc: 0.9238\n",
      "\n",
      "kappa improvement: 0.6742397152485395 (before: 0.673850062693856), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0269 - acc: 0.9959 - val_loss: 0.9890 - val_acc: 0.9227\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0208 - acc: 0.9967 - val_loss: 0.9975 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0142 - acc: 0.9975 - val_loss: 0.9931 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0105 - acc: 0.9980 - val_loss: 0.9914 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.6067 - acc: 0.8114 - val_loss: 0.9136 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6753952251046309 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 23us/step - loss: 0.0760 - acc: 0.9890 - val_loss: 0.9330 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.689547889294555 (before: 0.6753952251046309), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0580 - acc: 0.9921 - val_loss: 0.9499 - val_acc: 0.9282\n",
      "\n",
      "kappa improvement: 0.6938080851203573 (before: 0.689547889294555), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0490 - acc: 0.9938 - val_loss: 0.9607 - val_acc: 0.9268\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0413 - acc: 0.9942 - val_loss: 0.9653 - val_acc: 0.9260\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0362 - acc: 0.9953 - val_loss: 0.9672 - val_acc: 0.9252\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0296 - acc: 0.9963 - val_loss: 0.9727 - val_acc: 0.9256\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0243 - acc: 0.9967 - val_loss: 0.9803 - val_acc: 0.9240\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0205 - acc: 0.9972 - val_loss: 0.9805 - val_acc: 0.9233\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0183 - acc: 0.9976 - val_loss: 0.9833 - val_acc: 0.9231\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.3246 - acc: 0.8965 - val_loss: 0.9138 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6905156250632737 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 23us/step - loss: 0.0638 - acc: 0.9905 - val_loss: 0.9644 - val_acc: 0.9233\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0530 - acc: 0.9919 - val_loss: 0.9571 - val_acc: 0.9242\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0390 - acc: 0.9944 - val_loss: 0.9710 - val_acc: 0.9237\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0295 - acc: 0.9953 - val_loss: 0.9807 - val_acc: 0.9229\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0220 - acc: 0.9966 - val_loss: 0.9750 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0158 - acc: 0.9974 - val_loss: 0.9837 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0120 - acc: 0.9979 - val_loss: 0.9806 - val_acc: 0.9215\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.9769 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0067 - acc: 0.9988 - val_loss: 0.9779 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.4900 - acc: 0.9259 - val_loss: 0.9993 - val_acc: 0.9191\n",
      "\n",
      "kappa improvement: 0.6793713103047985 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 23us/step - loss: 0.1120 - acc: 0.9873 - val_loss: 0.9802 - val_acc: 0.9219\n",
      "\n",
      "kappa improvement: 0.6810842265017418 (before: 0.6793713103047985), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0826 - acc: 0.9900 - val_loss: 0.9627 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6873072015763038 (before: 0.6810842265017418), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0552 - acc: 0.9925 - val_loss: 0.9555 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6875804809850259 (before: 0.6873072015763038), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0380 - acc: 0.9945 - val_loss: 0.9518 - val_acc: 0.9260\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0289 - acc: 0.9959 - val_loss: 0.9503 - val_acc: 0.9254\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0199 - acc: 0.9968 - val_loss: 0.9495 - val_acc: 0.9256\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0139 - acc: 0.9974 - val_loss: 0.9447 - val_acc: 0.9238\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0090 - acc: 0.9986 - val_loss: 0.9462 - val_acc: 0.9231\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0078 - acc: 0.9987 - val_loss: 0.9545 - val_acc: 0.9219\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.2907 - acc: 0.9462 - val_loss: 0.9705 - val_acc: 0.9217\n",
      "\n",
      "kappa improvement: 0.6822754392751228 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0953 - acc: 0.9890 - val_loss: 0.9589 - val_acc: 0.9248\n",
      "\n",
      "kappa improvement: 0.6839132917312902 (before: 0.6822754392751228), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0577 - acc: 0.9922 - val_loss: 0.9565 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6854657254952928 (before: 0.6839132917312902), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0405 - acc: 0.9938 - val_loss: 0.9599 - val_acc: 0.9252\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0292 - acc: 0.9959 - val_loss: 0.9540 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0201 - acc: 0.9968 - val_loss: 0.9541 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0129 - acc: 0.9976 - val_loss: 0.9606 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.9638 - val_acc: 0.9227\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.9719 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.9644 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.6588 - acc: 0.8116 - val_loss: 0.8937 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.681861290987659 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0667 - acc: 0.9907 - val_loss: 0.9259 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6844861700982705 (before: 0.681861290987659), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0517 - acc: 0.9927 - val_loss: 0.9495 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6867424522641152 (before: 0.6844861700982705), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0429 - acc: 0.9941 - val_loss: 0.9707 - val_acc: 0.9256\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0358 - acc: 0.9952 - val_loss: 0.9693 - val_acc: 0.9256\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0296 - acc: 0.9959 - val_loss: 0.9735 - val_acc: 0.9264\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0251 - acc: 0.9967 - val_loss: 0.9777 - val_acc: 0.9256\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0224 - acc: 0.9967 - val_loss: 0.9850 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0193 - acc: 0.9975 - val_loss: 0.9873 - val_acc: 0.9235\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0169 - acc: 0.9978 - val_loss: 0.9871 - val_acc: 0.9238\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 1.0474 - acc: 0.7808 - val_loss: 0.9548 - val_acc: 0.9219\n",
      "\n",
      "kappa improvement: 0.6455156499925705 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.1022 - acc: 0.9864 - val_loss: 0.9605 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6746041040893447 (before: 0.6455156499925705), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0698 - acc: 0.9908 - val_loss: 0.9813 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6781430351316551 (before: 0.6746041040893447), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0590 - acc: 0.9925 - val_loss: 0.9889 - val_acc: 0.9260\n",
      "\n",
      "kappa improvement: 0.6829069388327837 (before: 0.6781430351316551), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0508 - acc: 0.9939 - val_loss: 0.9897 - val_acc: 0.9258\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0430 - acc: 0.9946 - val_loss: 0.9929 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0372 - acc: 0.9952 - val_loss: 0.9963 - val_acc: 0.9250\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0327 - acc: 0.9960 - val_loss: 1.0067 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0273 - acc: 0.9964 - val_loss: 1.0031 - val_acc: 0.9235\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0224 - acc: 0.9969 - val_loss: 1.0010 - val_acc: 0.9235\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 19s 1ms/step - loss: 0.5327 - acc: 0.9106 - val_loss: 0.9634 - val_acc: 0.9215\n",
      "\n",
      "kappa improvement: 0.6609238908900332 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0778 - acc: 0.9893 - val_loss: 0.9716 - val_acc: 0.9238\n",
      "\n",
      "kappa improvement: 0.6769414302523207 (before: 0.6609238908900332), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0573 - acc: 0.9924 - val_loss: 0.9790 - val_acc: 0.9238\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0443 - acc: 0.9942 - val_loss: 0.9828 - val_acc: 0.9233\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0342 - acc: 0.9951 - val_loss: 0.9837 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0265 - acc: 0.9960 - val_loss: 0.9785 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0198 - acc: 0.9969 - val_loss: 0.9819 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0147 - acc: 0.9973 - val_loss: 0.9866 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0113 - acc: 0.9979 - val_loss: 0.9807 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.9816 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.3664 - acc: 0.8753 - val_loss: 0.9052 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6903768481120539 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0720 - acc: 0.9888 - val_loss: 0.9311 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.692134905257627 (before: 0.6903768481120539), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0582 - acc: 0.9918 - val_loss: 0.9503 - val_acc: 0.9262\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0461 - acc: 0.9936 - val_loss: 0.9626 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0379 - acc: 0.9949 - val_loss: 0.9653 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0319 - acc: 0.9957 - val_loss: 0.9687 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0266 - acc: 0.9963 - val_loss: 0.9709 - val_acc: 0.9240\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0221 - acc: 0.9968 - val_loss: 0.9706 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0189 - acc: 0.9972 - val_loss: 0.9726 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0149 - acc: 0.9978 - val_loss: 0.9838 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.1714 - acc: 0.9509 - val_loss: 0.9195 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6902920869679674 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0609 - acc: 0.9909 - val_loss: 0.9505 - val_acc: 0.9240\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0455 - acc: 0.9938 - val_loss: 0.9467 - val_acc: 0.9240\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0277 - acc: 0.9958 - val_loss: 0.9543 - val_acc: 0.9219\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0178 - acc: 0.9968 - val_loss: 0.9838 - val_acc: 0.9193\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0104 - acc: 0.9978 - val_loss: 0.9731 - val_acc: 0.9203\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0078 - acc: 0.9984 - val_loss: 0.9847 - val_acc: 0.9191\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.9862 - val_acc: 0.9201\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.9867 - val_acc: 0.9197\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.9876 - val_acc: 0.9195\n",
      "500_0.3\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.4408 - acc: 0.8569 - val_loss: 0.9126 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6746041040893447 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0718 - acc: 0.9892 - val_loss: 0.9448 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6797231440536994 (before: 0.6746041040893447), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0584 - acc: 0.9918 - val_loss: 0.9518 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6823077530626073 (before: 0.6797231440536994), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0455 - acc: 0.9937 - val_loss: 0.9657 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0380 - acc: 0.9951 - val_loss: 0.9743 - val_acc: 0.9260\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0310 - acc: 0.9957 - val_loss: 0.9760 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0255 - acc: 0.9964 - val_loss: 0.9819 - val_acc: 0.9237\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0213 - acc: 0.9968 - val_loss: 0.9837 - val_acc: 0.9229\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0175 - acc: 0.9975 - val_loss: 0.9838 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0158 - acc: 0.9977 - val_loss: 0.9926 - val_acc: 0.9215\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.2817 - acc: 0.9219 - val_loss: 0.9408 - val_acc: 0.9233\n",
      "\n",
      "kappa improvement: 0.6691517232502813 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0623 - acc: 0.9911 - val_loss: 0.9620 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6814940380703525 (before: 0.6691517232502813), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0487 - acc: 0.9934 - val_loss: 0.9832 - val_acc: 0.9246\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0366 - acc: 0.9945 - val_loss: 0.9851 - val_acc: 0.9233\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0277 - acc: 0.9959 - val_loss: 0.9975 - val_acc: 0.9225\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0211 - acc: 0.9971 - val_loss: 0.9990 - val_acc: 0.9209\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0172 - acc: 0.9972 - val_loss: 0.9960 - val_acc: 0.9199\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0129 - acc: 0.9980 - val_loss: 1.0029 - val_acc: 0.9197\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0103 - acc: 0.9983 - val_loss: 1.0160 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0078 - acc: 0.9983 - val_loss: 1.0245 - val_acc: 0.9201\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.6603 - acc: 0.8235 - val_loss: 0.9261 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6715384811135899 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0841 - acc: 0.9879 - val_loss: 0.9447 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6869250654531339 (before: 0.6715384811135899), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0661 - acc: 0.9909 - val_loss: 0.9633 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6894402845606931 (before: 0.6869250654531339), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0577 - acc: 0.9929 - val_loss: 0.9726 - val_acc: 0.9264\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0487 - acc: 0.9936 - val_loss: 0.9751 - val_acc: 0.9266\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0413 - acc: 0.9948 - val_loss: 0.9755 - val_acc: 0.9254\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0345 - acc: 0.9956 - val_loss: 0.9764 - val_acc: 0.9250\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0283 - acc: 0.9959 - val_loss: 0.9783 - val_acc: 0.9244\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0232 - acc: 0.9967 - val_loss: 0.9821 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0199 - acc: 0.9972 - val_loss: 0.9849 - val_acc: 0.9225\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.4114 - acc: 0.9048 - val_loss: 0.9162 - val_acc: 0.9252\n",
      "\n",
      "kappa improvement: 0.6866677696488885 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0839 - acc: 0.9891 - val_loss: 0.9363 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6884176263161788 (before: 0.6866677696488885), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0646 - acc: 0.9908 - val_loss: 0.9498 - val_acc: 0.9268\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0505 - acc: 0.9932 - val_loss: 0.9556 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6894214318515237 (before: 0.6884176263161788), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0396 - acc: 0.9946 - val_loss: 0.9559 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0317 - acc: 0.9958 - val_loss: 0.9539 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0271 - acc: 0.9961 - val_loss: 0.9581 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0208 - acc: 0.9966 - val_loss: 0.9527 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0166 - acc: 0.9976 - val_loss: 0.9650 - val_acc: 0.9227\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0126 - acc: 0.9979 - val_loss: 0.9903 - val_acc: 0.9209\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.6038 - acc: 0.8319 - val_loss: 0.9052 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6727460194043473 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0819 - acc: 0.9875 - val_loss: 0.9315 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6893523057782465 (before: 0.6727460194043473), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0607 - acc: 0.9908 - val_loss: 0.9426 - val_acc: 0.9280\n",
      "\n",
      "kappa improvement: 0.6916868994571155 (before: 0.6893523057782465), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0510 - acc: 0.9933 - val_loss: 0.9515 - val_acc: 0.9272\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0419 - acc: 0.9942 - val_loss: 0.9555 - val_acc: 0.9264\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0366 - acc: 0.9953 - val_loss: 0.9575 - val_acc: 0.9264\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0317 - acc: 0.9955 - val_loss: 0.9625 - val_acc: 0.9250\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0266 - acc: 0.9965 - val_loss: 0.9627 - val_acc: 0.9250\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0222 - acc: 0.9968 - val_loss: 0.9622 - val_acc: 0.9250\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0193 - acc: 0.9971 - val_loss: 0.9615 - val_acc: 0.9242\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.9544 - acc: 0.8370 - val_loss: 0.9967 - val_acc: 0.9238\n",
      "\n",
      "kappa improvement: 0.6544222919525562 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0907 - acc: 0.9874 - val_loss: 0.9968 - val_acc: 0.9217\n",
      "\n",
      "kappa improvement: 0.6627884699120439 (before: 0.6544222919525562), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0597 - acc: 0.9915 - val_loss: 1.0161 - val_acc: 0.9213\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0458 - acc: 0.9935 - val_loss: 1.0170 - val_acc: 0.9223\n",
      "\n",
      "kappa improvement: 0.6679197458729036 (before: 0.6627884699120439), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0382 - acc: 0.9944 - val_loss: 1.0218 - val_acc: 0.9229\n",
      "\n",
      "kappa improvement: 0.6698445544595268 (before: 0.6679197458729036), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0303 - acc: 0.9956 - val_loss: 1.0254 - val_acc: 0.9223\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0245 - acc: 0.9961 - val_loss: 1.0204 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0197 - acc: 0.9970 - val_loss: 1.0162 - val_acc: 0.9199\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0157 - acc: 0.9972 - val_loss: 1.0196 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0116 - acc: 0.9982 - val_loss: 1.0205 - val_acc: 0.9205\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.2549 - acc: 0.9276 - val_loss: 0.9139 - val_acc: 0.9254\n",
      "\n",
      "kappa improvement: 0.6865732046882083 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0760 - acc: 0.9895 - val_loss: 0.9289 - val_acc: 0.9284\n",
      "\n",
      "kappa improvement: 0.6944628136513556 (before: 0.6865732046882083), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0571 - acc: 0.9917 - val_loss: 0.9402 - val_acc: 0.9270\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0405 - acc: 0.9946 - val_loss: 0.9448 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0298 - acc: 0.9958 - val_loss: 0.9517 - val_acc: 0.9223\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0235 - acc: 0.9963 - val_loss: 0.9565 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0166 - acc: 0.9971 - val_loss: 0.9467 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0112 - acc: 0.9980 - val_loss: 0.9576 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.9644 - val_acc: 0.9195\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.9730 - val_acc: 0.9193\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.3249 - acc: 0.9044 - val_loss: 0.9240 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.680381242341487 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0711 - acc: 0.9895 - val_loss: 0.9449 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.68757959283179 (before: 0.680381242341487), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0540 - acc: 0.9927 - val_loss: 0.9616 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6897011048779098 (before: 0.68757959283179), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0447 - acc: 0.9941 - val_loss: 0.9638 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0357 - acc: 0.9953 - val_loss: 0.9685 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0286 - acc: 0.9962 - val_loss: 0.9721 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0221 - acc: 0.9971 - val_loss: 0.9721 - val_acc: 0.9235\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0187 - acc: 0.9971 - val_loss: 0.9727 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0141 - acc: 0.9979 - val_loss: 0.9732 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0115 - acc: 0.9984 - val_loss: 0.9747 - val_acc: 0.9217\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.4668 - acc: 0.8775 - val_loss: 0.9168 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.690661915132317 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0630 - acc: 0.9902 - val_loss: 0.9506 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6909129558545191 (before: 0.690661915132317), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0490 - acc: 0.9933 - val_loss: 0.9683 - val_acc: 0.9262\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0404 - acc: 0.9942 - val_loss: 0.9686 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0327 - acc: 0.9954 - val_loss: 0.9804 - val_acc: 0.9256\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0270 - acc: 0.9961 - val_loss: 0.9891 - val_acc: 0.9248\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0225 - acc: 0.9971 - val_loss: 0.9887 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0194 - acc: 0.9972 - val_loss: 0.9862 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0160 - acc: 0.9976 - val_loss: 0.9951 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0145 - acc: 0.9980 - val_loss: 0.9918 - val_acc: 0.9223\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.3865 - acc: 0.9424 - val_loss: 0.9323 - val_acc: 0.9221\n",
      "\n",
      "kappa improvement: 0.6735094607627525 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0769 - acc: 0.9895 - val_loss: 0.9341 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6817800331804431 (before: 0.6735094607627525), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0487 - acc: 0.9933 - val_loss: 0.9306 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6846218861391595 (before: 0.6817800331804431), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0331 - acc: 0.9949 - val_loss: 0.9277 - val_acc: 0.9235\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0219 - acc: 0.9969 - val_loss: 0.9301 - val_acc: 0.9213\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0142 - acc: 0.9971 - val_loss: 0.9236 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0105 - acc: 0.9980 - val_loss: 0.9325 - val_acc: 0.9207\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0065 - acc: 0.9986 - val_loss: 0.9220 - val_acc: 0.9211\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0045 - acc: 0.9992 - val_loss: 0.9404 - val_acc: 0.9195\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.9225 - val_acc: 0.9193\n",
      "500_0.4\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.6574 - acc: 0.8594 - val_loss: 0.9889 - val_acc: 0.9211\n",
      "\n",
      "kappa improvement: 0.6490692115926634 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0864 - acc: 0.9884 - val_loss: 1.0022 - val_acc: 0.9223\n",
      "\n",
      "kappa improvement: 0.6643146519811328 (before: 0.6490692115926634), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0591 - acc: 0.9918 - val_loss: 0.9995 - val_acc: 0.9223\n",
      "\n",
      "kappa improvement: 0.6675230083464476 (before: 0.6643146519811328), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0468 - acc: 0.9938 - val_loss: 1.0060 - val_acc: 0.9229\n",
      "\n",
      "kappa improvement: 0.6690533153177722 (before: 0.6675230083464476), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0361 - acc: 0.9949 - val_loss: 1.0073 - val_acc: 0.9219\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0293 - acc: 0.9958 - val_loss: 1.0119 - val_acc: 0.9221\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0239 - acc: 0.9967 - val_loss: 1.0101 - val_acc: 0.9217\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0200 - acc: 0.9972 - val_loss: 1.0111 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0156 - acc: 0.9975 - val_loss: 1.0175 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0123 - acc: 0.9980 - val_loss: 1.0091 - val_acc: 0.9201\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 1.3204 - acc: 0.7795 - val_loss: 0.9092 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.6627919604263488 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0734 - acc: 0.9880 - val_loss: 0.9296 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6833457965667946 (before: 0.6627919604263488), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0596 - acc: 0.9916 - val_loss: 0.9461 - val_acc: 0.9268\n",
      "\n",
      "kappa improvement: 0.6873937484835899 (before: 0.6833457965667946), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0533 - acc: 0.9925 - val_loss: 0.9566 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6883265386882557 (before: 0.6873937484835899), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0450 - acc: 0.9940 - val_loss: 0.9617 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0390 - acc: 0.9945 - val_loss: 0.9655 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0330 - acc: 0.9953 - val_loss: 0.9674 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0296 - acc: 0.9957 - val_loss: 0.9713 - val_acc: 0.9237\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0253 - acc: 0.9964 - val_loss: 0.9717 - val_acc: 0.9229\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0219 - acc: 0.9969 - val_loss: 0.9728 - val_acc: 0.9227\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.5020 - acc: 0.8621 - val_loss: 0.9110 - val_acc: 0.9276\n",
      "\n",
      "kappa improvement: 0.6892637998785189 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0694 - acc: 0.9890 - val_loss: 0.9416 - val_acc: 0.9260\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0578 - acc: 0.9917 - val_loss: 0.9544 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6902634331285136 (before: 0.6892637998785189), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0486 - acc: 0.9936 - val_loss: 0.9637 - val_acc: 0.9262\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0400 - acc: 0.9946 - val_loss: 0.9696 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0334 - acc: 0.9957 - val_loss: 0.9722 - val_acc: 0.9246\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0271 - acc: 0.9963 - val_loss: 0.9729 - val_acc: 0.9244\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0235 - acc: 0.9964 - val_loss: 0.9733 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0180 - acc: 0.9974 - val_loss: 0.9721 - val_acc: 0.9231\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0143 - acc: 0.9976 - val_loss: 0.9707 - val_acc: 0.9221\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 21s 1ms/step - loss: 0.8004 - acc: 0.8202 - val_loss: 0.9242 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6680809914411014 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0807 - acc: 0.9887 - val_loss: 0.9472 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6871094365928347 (before: 0.6680809914411014), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0644 - acc: 0.9913 - val_loss: 0.9657 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.68757959283179 (before: 0.6871094365928347), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0551 - acc: 0.9927 - val_loss: 0.9734 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6893523057782465 (before: 0.68757959283179), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0472 - acc: 0.9938 - val_loss: 0.9780 - val_acc: 0.9270\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0397 - acc: 0.9950 - val_loss: 0.9788 - val_acc: 0.9254\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0354 - acc: 0.9955 - val_loss: 0.9794 - val_acc: 0.9246\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0307 - acc: 0.9957 - val_loss: 0.9793 - val_acc: 0.9248\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0258 - acc: 0.9967 - val_loss: 0.9806 - val_acc: 0.9246\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0228 - acc: 0.9970 - val_loss: 0.9819 - val_acc: 0.9237\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 21s 1ms/step - loss: 0.3196 - acc: 0.9131 - val_loss: 0.9249 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6746041040893447 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0647 - acc: 0.9910 - val_loss: 0.9520 - val_acc: 0.9258\n",
      "\n",
      "kappa improvement: 0.6814940380703525 (before: 0.6746041040893447), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0467 - acc: 0.9935 - val_loss: 0.9645 - val_acc: 0.9256\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0369 - acc: 0.9949 - val_loss: 0.9780 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0272 - acc: 0.9961 - val_loss: 0.9840 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0241 - acc: 0.9965 - val_loss: 0.9939 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0180 - acc: 0.9974 - val_loss: 0.9913 - val_acc: 0.9215\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0155 - acc: 0.9978 - val_loss: 1.0064 - val_acc: 0.9207\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0130 - acc: 0.9983 - val_loss: 1.0082 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0101 - acc: 0.9986 - val_loss: 1.0140 - val_acc: 0.9203\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 20s 1ms/step - loss: 0.4553 - acc: 0.8855 - val_loss: 0.9273 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6832984737377046 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0722 - acc: 0.9891 - val_loss: 0.9558 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6872096687717173 (before: 0.6832984737377046), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0537 - acc: 0.9926 - val_loss: 0.9771 - val_acc: 0.9254\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0451 - acc: 0.9942 - val_loss: 0.9847 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0341 - acc: 0.9955 - val_loss: 0.9972 - val_acc: 0.9238\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0289 - acc: 0.9963 - val_loss: 0.9945 - val_acc: 0.9242\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0228 - acc: 0.9972 - val_loss: 0.9904 - val_acc: 0.9229\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0176 - acc: 0.9975 - val_loss: 0.9949 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 22us/step - loss: 0.0139 - acc: 0.9979 - val_loss: 0.9995 - val_acc: 0.9217\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0092 - acc: 0.9983 - val_loss: 1.0087 - val_acc: 0.9201\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 21s 1ms/step - loss: 0.2297 - acc: 0.9468 - val_loss: 0.9315 - val_acc: 0.9240\n",
      "\n",
      "kappa improvement: 0.6764322900641223 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 23us/step - loss: 0.0775 - acc: 0.9899 - val_loss: 0.9402 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6882349049894984 (before: 0.6764322900641223), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0498 - acc: 0.9929 - val_loss: 0.9444 - val_acc: 0.9262\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0371 - acc: 0.9948 - val_loss: 0.9420 - val_acc: 0.9258\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0243 - acc: 0.9965 - val_loss: 0.9396 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0203 - acc: 0.9970 - val_loss: 0.9443 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0154 - acc: 0.9975 - val_loss: 0.9359 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0111 - acc: 0.9982 - val_loss: 0.9452 - val_acc: 0.9213\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0075 - acc: 0.9985 - val_loss: 0.9453 - val_acc: 0.9213\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0069 - acc: 0.9987 - val_loss: 0.9588 - val_acc: 0.9197\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 21s 1ms/step - loss: 0.6296 - acc: 0.8284 - val_loss: 0.9099 - val_acc: 0.9246\n",
      "\n",
      "kappa improvement: 0.6693012406612353 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0751 - acc: 0.9888 - val_loss: 0.9369 - val_acc: 0.9266\n",
      "\n",
      "kappa improvement: 0.6859939523272005 (before: 0.6693012406612353), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0616 - acc: 0.9913 - val_loss: 0.9517 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6905460989714856 (before: 0.6859939523272005), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0518 - acc: 0.9933 - val_loss: 0.9627 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0433 - acc: 0.9944 - val_loss: 0.9647 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0371 - acc: 0.9948 - val_loss: 0.9692 - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0320 - acc: 0.9955 - val_loss: 0.9719 - val_acc: 0.9225\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0260 - acc: 0.9963 - val_loss: 0.9707 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0229 - acc: 0.9965 - val_loss: 0.9745 - val_acc: 0.9211\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0186 - acc: 0.9973 - val_loss: 0.9764 - val_acc: 0.9211\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 21s 1ms/step - loss: 1.2600 - acc: 0.7817 - val_loss: 0.9178 - val_acc: 0.9256\n",
      "\n",
      "kappa improvement: 0.6705795550020685 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0803 - acc: 0.9880 - val_loss: 0.9396 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6855961107080613 (before: 0.6705795550020685), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 19us/step - loss: 0.0602 - acc: 0.9915 - val_loss: 0.9583 - val_acc: 0.9270\n",
      "\n",
      "kappa improvement: 0.6876731290527236 (before: 0.6855961107080613), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0537 - acc: 0.9932 - val_loss: 0.9701 - val_acc: 0.9268\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0447 - acc: 0.9944 - val_loss: 0.9767 - val_acc: 0.9256\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0404 - acc: 0.9949 - val_loss: 0.9818 - val_acc: 0.9256\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0325 - acc: 0.9958 - val_loss: 0.9846 - val_acc: 0.9260\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 15us/step - loss: 0.0285 - acc: 0.9964 - val_loss: 0.9894 - val_acc: 0.9246\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0251 - acc: 0.9967 - val_loss: 0.9875 - val_acc: 0.9235\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0206 - acc: 0.9968 - val_loss: 0.9907 - val_acc: 0.9233\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 21s 1ms/step - loss: 1.0706 - acc: 0.7874 - val_loss: 0.8829 - val_acc: 0.9262\n",
      "\n",
      "kappa improvement: 0.6757934996911465 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 21us/step - loss: 0.0696 - acc: 0.9888 - val_loss: 0.9105 - val_acc: 0.9272\n",
      "\n",
      "kappa improvement: 0.6864524369357601 (before: 0.6757934996911465), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0551 - acc: 0.9915 - val_loss: 0.9301 - val_acc: 0.9274\n",
      "\n",
      "kappa improvement: 0.6889807298884709 (before: 0.6864524369357601), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0515 - acc: 0.9927 - val_loss: 0.9398 - val_acc: 0.9278\n",
      "\n",
      "kappa improvement: 0.6899201217192849 (before: 0.6889807298884709), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0415 - acc: 0.9938 - val_loss: 0.9473 - val_acc: 0.9268\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0367 - acc: 0.9949 - val_loss: 0.9513 - val_acc: 0.9260\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0292 - acc: 0.9952 - val_loss: 0.9523 - val_acc: 0.9256\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0246 - acc: 0.9965 - val_loss: 0.9550 - val_acc: 0.9240\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0194 - acc: 0.9969 - val_loss: 0.9536 - val_acc: 0.9233\n",
      "Epoch 10/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0154 - acc: 0.9972 - val_loss: 0.9542 - val_acc: 0.9221\n",
      "500_0.5\n",
      "=================================\n",
      "Train on 17376 samples, validate on 5095 samples\n",
      "Epoch 1/10\n",
      "17376/17376 [==============================] - 21s 1ms/step - loss: 0.3034 - acc: 0.9199 - val_loss: 0.9161 - val_acc: 0.9264\n",
      "\n",
      "kappa improvement: 0.6901517516511051 (before: -inf), saving to exp3_img-text_mlp_model.hdf5\n",
      "Epoch 2/10\n",
      "17376/17376 [==============================] - 0s 20us/step - loss: 0.0650 - acc: 0.9902 - val_loss: 0.9350 - val_acc: 0.9274\n",
      "Epoch 3/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0496 - acc: 0.9928 - val_loss: 0.9486 - val_acc: 0.9264\n",
      "Epoch 4/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0404 - acc: 0.9945 - val_loss: 0.9546 - val_acc: 0.9242\n",
      "Epoch 5/10\n",
      "17376/17376 [==============================] - 0s 18us/step - loss: 0.0305 - acc: 0.9955 - val_loss: 0.9559 - val_acc: 0.9231\n",
      "Epoch 6/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0252 - acc: 0.9963 - val_loss: 0.9560 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "17376/17376 [==============================] - 0s 16us/step - loss: 0.0192 - acc: 0.9970 - val_loss: 0.9583 - val_acc: 0.9231\n",
      "Epoch 8/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0152 - acc: 0.9979 - val_loss: 0.9622 - val_acc: 0.9221\n",
      "Epoch 9/10\n",
      "17376/17376 [==============================] - 0s 17us/step - loss: 0.0125 - acc: 0.9979 - val_loss: 0.9684 - val_acc: 0.9223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 10\n",
    "n_dense = [300,400,500]\n",
    "n_dropouts = [i / 10 for i in range(1,10)]\n",
    "param_selection_results = {}\n",
    "for p_dense in n_dense:\n",
    "    for p_dropout in n_dropouts:\n",
    "        exp_identifier = str(p_dense) + '_' + str(p_dropout)\n",
    "        repeat_res = []\n",
    "        print(exp_identifier)\n",
    "        print(\"=================================\")\n",
    "        for n_repeat in range(n_repeats):\n",
    "            input_tp = Input(shape=sequence_x_2inputs_train[0][0].shape)\n",
    "            input_pp = Input(shape=sequence_x_2inputs_train[1][0].shape)\n",
    "            difference = subtract([input_pp, input_tp])\n",
    "            final_feat = concatenate([input_tp, input_pp, difference])\n",
    "            final_feat = Dense(p_dense)(final_feat)\n",
    "            final_feat = LeakyReLU()(final_feat)\n",
    "            final_feat = Dropout(p_dropout)(final_feat)\n",
    "            model_output = Dense(1, activation = 'sigmoid')(final_feat)\n",
    "            combined_model = Model([input_tp, input_pp], model_output)\n",
    "            model_path = \"exp3_img-text_mlp_model.hdf5\"\n",
    "            checkpoint = ValidationCheckpoint(model_path, sequence_x_2inputs_test, data_test_y)\n",
    "            combined_model.compile(loss = 'binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "            combined_model.fit(sequence_x_2inputs_train, data_train_y, validation_data = (sequence_x_2inputs_test, data_test_y), \n",
    "                               batch_size=4096, epochs=10, callbacks=[checkpoint])\n",
    "            \n",
    "            \n",
    "            repeat_res.append(checkpoint.max_metric)\n",
    "        param_selection_results[exp_identifier] = np.average(repeat_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300_0.1: 0.6852515810316551\n",
      "300_0.2: 0.6871223351208229\n",
      "300_0.3: 0.68686121506216\n",
      "300_0.4: 0.689159652336207\n",
      "300_0.5: 0.685658893687956\n",
      "300_0.6: 0.6853433528813586\n",
      "300_0.7: 0.6878746665438003\n",
      "300_0.8: 0.6891409725882904\n",
      "300_0.9: 0.6874184973695996\n",
      "400_0.1: 0.6832988830279183\n",
      "400_0.2: 0.6876135694830794\n",
      "400_0.3: 0.6854449904544734\n",
      "400_0.4: 0.6910287819300474\n",
      "400_0.5: 0.6866319842816794\n",
      "400_0.6: 0.6898778886492986\n",
      "400_0.7: 0.6873365297429803\n",
      "400_0.8: 0.6901676633495409\n",
      "400_0.9: 0.6914310739270534\n",
      "500_0.1: 0.6867188701608696\n",
      "500_0.2: 0.6860627445487304\n",
      "500_0.3: 0.6863893721984763\n",
      "500_0.4: 0.686207355448785\n",
      "500_0.5: 0.6903744622590591\n",
      "500_0.6: 0.6877049657707486\n",
      "500_0.7: 0.68878342194352\n",
      "500_0.8: 0.6909000005464196\n",
      "500_0.9: 0.6900227148787077\n"
     ]
    }
   ],
   "source": [
    "for experiment in param_selection_results.keys():\n",
    "    print(experiment + \": \" + str(param_selection_results[experiment]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 300_0.1: 0.6852515810316551\n",
    "* 300_0.2: 0.6871223351208229\n",
    "* 300_0.3: 0.68686121506216\n",
    "* 300_0.4: 0.689159652336207\n",
    "* 300_0.5: 0.685658893687956\n",
    "* 300_0.6: 0.6853433528813586\n",
    "* 300_0.7: 0.6878746665438003\n",
    "* 300_0.8: 0.6891409725882904\n",
    "* 300_0.9: 0.6874184973695996\n",
    "* 400_0.1: 0.6832988830279183\n",
    "* 400_0.2: 0.6876135694830794\n",
    "* 400_0.3: 0.6854449904544734\n",
    "* 400_0.4: 0.6910287819300474\n",
    "* 400_0.5: 0.6866319842816794\n",
    "* 400_0.6: 0.6898778886492986\n",
    "* 400_0.7: 0.6873365297429803\n",
    "* 400_0.8: 0.6901676633495409\n",
    "* 400_0.9: 0.6914310739270534\n",
    "* 500_0.1: 0.6867188701608696\n",
    "* 500_0.2: 0.6860627445487304\n",
    "* 500_0.3: 0.6863893721984763\n",
    "* 500_0.4: 0.686207355448785\n",
    "* 500_0.5: 0.6903744622590591\n",
    "* 500_0.6: 0.6877049657707486\n",
    "* 500_0.7: 0.68878342194352\n",
    "* 500_0.8: 0.6909000005464196\n",
    "* 500_0.9: 0.6900227148787077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best setup: 400, 0.9\n",
    "input_tp = Input(shape=sequence_x_2inputs_train[0][0].shape)\n",
    "input_pp = Input(shape=sequence_x_2inputs_train[1][0].shape)\n",
    "difference = subtract([input_pp, input_tp])\n",
    "final_feat = concatenate([input_tp, input_pp, difference])\n",
    "final_feat = Dense(400)(final_feat)\n",
    "final_feat = LeakyReLU()(final_feat)\n",
    "final_feat = Dropout(0.9)(final_feat)\n",
    "model_output = Dense(1, activation = 'sigmoid')(final_feat)\n",
    "combined_model = Model([input_tp, input_pp], model_output)\n",
    "model_path = \"exp3_img-text_mlp_model.hdf5\"\n",
    "checkpoint = ValidationCheckpoint(model_path, sequence_x_2inputs_test, data_test_y)\n",
    "combined_model.compile(loss = 'binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "combined_model.fit(sequence_x_2inputs_train, data_train_y, validation_data = (sequence_x_2inputs_test, data_test_y), \n",
    "                   batch_size=4096, epochs=10, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17376, 514)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_x_train = np.concatenate([text_features_train, image_features_train, lda_train_x[:,100:102]], axis = 1)\n",
    "features_x_test = np.concatenate([text_features_test, image_features_test, lda_test_x[:,100:102]], axis = 1)\n",
    "features_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioes2Idx = {'B' : 0, 'I' : 1, 'E' : 2, 'S' : 3}\n",
    "\n",
    "def binary_to_BIOES(sequence):\n",
    "    x_all, y_all = zip(*sequence)\n",
    "    # B begin\n",
    "    # I Inside\n",
    "    # O None - we dont have O ...\n",
    "    # E End\n",
    "    # S Single\n",
    "    last_state = 'O'\n",
    "    y_translated = []\n",
    "    for y in y_all:\n",
    "        if y == 1:\n",
    "            if last_state == 'B':\n",
    "                # single\n",
    "                y_translated[-1] = 'S'\n",
    "            elif last_state == 'I':\n",
    "                # end\n",
    "                y_translated[-1] = 'E'\n",
    "            # begin\n",
    "            y_translated.append('B')\n",
    "        elif y == 0:\n",
    "            # inside\n",
    "            y_translated.append('I')\n",
    "        else:\n",
    "            raise ValueError('Only accept 0 or 1 as label.')\n",
    "            \n",
    "        last_state = y_translated[-1]\n",
    "        \n",
    "    if last_state == 'B':\n",
    "        # single\n",
    "        y_translated[-1] = 'S'\n",
    "    elif last_state == 'I':\n",
    "        y_translated[-1] = 'E'\n",
    "        \n",
    "    return [(x_all[i], bioes2Idx[y_translated[i]]) for i in range(len(x_all))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "label2Idx = {'FirstPage':1, 'NextPage':0}\n",
    "\n",
    "def create_sequences(data_instances, data_features, max_seq_len = 764):\n",
    "    \n",
    "    max_len = 0\n",
    "    \n",
    "    sequences = []\n",
    "    prevBinder = \"\"\n",
    "    tmp_sequence = []\n",
    "    for i, instance in enumerate(data_instances):\n",
    "        # \"0 docid\";\"1 class\";\"2 type\";\"3 text\";\"4 binder\"\n",
    "        if prevBinder != instance[4]:\n",
    "            if len(tmp_sequence) > 0:\n",
    "                sequences.append(binary_to_BIOES(tmp_sequence))\n",
    "            tmp_sequence = []\n",
    "        tmp_sequence.append((data_features[i], label2Idx[instance[1]]))\n",
    "        prevBinder = instance[4]\n",
    "    if len(tmp_sequence) > 0:\n",
    "        sequences.append(binary_to_BIOES(tmp_sequence))\n",
    "        \n",
    "        \n",
    "        \n",
    "    # create batches of same length\n",
    "    batch_dict = {}\n",
    "    for i, s in enumerate(sequences):\n",
    "        if (len(s)) in batch_dict:\n",
    "            batch_dict[len(s)].append(i)\n",
    "        else:\n",
    "            batch_dict[len(s)] = [i]\n",
    "    batch_indexes = []\n",
    "    for k in batch_dict.keys():\n",
    "        batch_indexes.append(batch_dict[k])\n",
    "        \n",
    "    return batch_indexes, sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_idx, rnn_x_train = create_sequences(data_text_train, features_x_train)\n",
    "test_batch_idx, rnn_x_test = create_sequences(data_text_test, features_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "275\n",
      "2\n",
      "24\n",
      "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23]]\n",
      "514\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(rnn_x_train))\n",
    "print(len(rnn_x_train[20]))\n",
    "print(len(rnn_x_train[20][1]))\n",
    "print(len(test_batch_idx))\n",
    "print(test_batch_idx)\n",
    "print(rnn_x_train[20][0][0].shape[0])\n",
    "for i in range(100):\n",
    "    print(rnn_x_train[20][i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "import math\n",
    "\n",
    "class SequenceGenerator(Sequence):\n",
    "    def __init__(self, sequence_data, batch_idx):\n",
    "        self.sequence_data = sequence_data\n",
    "        self.batch_idx = batch_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_idx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.batch_idx[idx]\n",
    "        batch_x, batch_y = self.process_sequence_data(inds)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def process_sequence_data(self, inds):\n",
    "        features = []\n",
    "        output_labels = []\n",
    "        for index in inds:\n",
    "            tmp_features, tmp_output_labels = zip(*self.sequence_data[index])\n",
    "            features.append(tmp_features)\n",
    "            tmp_output_labels = to_categorical(tmp_output_labels, num_classes=4)\n",
    "            output_labels.append(tmp_output_labels)\n",
    "            \n",
    "        batch_input = np.array(features)\n",
    "        batch_output = np.array(output_labels)\n",
    "        \n",
    "        #print(batch_input.shape)\n",
    "        #print(batch_output.shape)\n",
    "        \n",
    "        return (batch_input, batch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceCheckpoint(Callback):\n",
    "    def __init__(self, filepath, metric = 'kappa'):\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "        #self.x = validation_x\n",
    "        #self.x_batches = x_batches\n",
    "        #self.validation_y = validation_y\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        true_labels = []\n",
    "        predicted_labels = []\n",
    "        for i in range(len(rnn_x_test)):\n",
    "            example_features, y_true_binder = zip(*rnn_x_test[i])\n",
    "            example_features = np.array(example_features)\n",
    "            example_features = np.reshape(example_features, (1,) + example_features.shape)\n",
    "            # example_features.shape\n",
    "            y_pred_binder = rnn_model.predict(example_features).argmax(axis=-1)\n",
    "            predicted_labels.extend(y_pred_binder[0])\n",
    "            true_labels.extend(y_true_binder)\n",
    "\n",
    "            \n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            # 'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='binary', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metric)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            self.model.save(self.filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, None, 514)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_35 (Bidirectio (None, None, 50)          81000     \n",
      "_________________________________________________________________\n",
      "bidirectional_36 (Bidirectio (None, None, 50)          11400     \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, None, 4)           204       \n",
      "_________________________________________________________________\n",
      "crf (CRF)                    (None, None, 4)           44        \n",
      "=================================================================\n",
      "Total params: 92,648\n",
      "Trainable params: 92,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "71/71 [==============================] - 115s 2s/step - loss: 0.4228 - crf_accuracy: 0.8593 - val_loss: 0.6647 - val_crf_accuracy: 0.8407\n",
      "\n",
      "kappa improvement: 0.5991290946136566 (before: -inf), saving to exp3_seq_model.hdf5\n",
      "Epoch 2/15\n",
      "71/71 [==============================] - 105s 1s/step - loss: 0.0807 - crf_accuracy: 0.9800 - val_loss: 0.7313 - val_crf_accuracy: 0.8525\n",
      "\n",
      "kappa improvement: 0.6093914710110206 (before: 0.5991290946136566), saving to exp3_seq_model.hdf5\n",
      "Epoch 3/15\n",
      "71/71 [==============================] - 105s 1s/step - loss: 0.0164 - crf_accuracy: 0.9973 - val_loss: 0.7679 - val_crf_accuracy: 0.8581\n",
      "\n",
      "kappa improvement: 0.6270913165117544 (before: 0.6093914710110206), saving to exp3_seq_model.hdf5\n",
      "Epoch 4/15\n",
      "30/71 [===========>..................] - ETA: 53s - loss: -0.0066 - crf_accuracy: 0.9999"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-2c29ce10c55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSequenceGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_x_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_check\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_input = Input(shape = (None,rnn_x_train[0][0][0].shape[0]))\n",
    "rnn_layer = Bidirectional(GRU(200, return_sequences=True))(rnn_input)\n",
    "# rnn_layer = Bidirectional(GRU(25, return_sequences=True))(rnn_layer)\n",
    "rnn_dense = TimeDistributed(Dense(4))(rnn_layer)\n",
    "\n",
    "crf = CRF(4, name = 'crf')\n",
    "rnn_output = crf(rnn_dense)\n",
    "rnn_model = Model(rnn_input, rnn_output)\n",
    "rnn_model.compile(loss=crf_loss, optimizer='nadam', metrics=[crf_accuracy])\n",
    "rnn_model.summary()\n",
    "\n",
    "s_check = SequenceCheckpoint(\"exp3_seq_model.hdf5\")\n",
    "\n",
    "rnn_model.fit(\n",
    "    SequenceGenerator(rnn_x_train, train_batch_idx), \n",
    "    validation_data=SequenceGenerator(rnn_x_test, test_batch_idx), \n",
    "    callbacks=[s_check],\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.load_weights(s_check.filepath)\n",
    "# FirstPage = 1, NextPage = 0\n",
    "idx2label = {0 : 1, 1 : 0, 2 : 0, 3 : 1}\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for i in range(len(rnn_x_test)):\n",
    "    example_features, y_true_binder = zip(*rnn_x_test[i])\n",
    "    example_features = np.array(example_features)\n",
    "    example_features = np.reshape(example_features, (1,) + example_features.shape)\n",
    "    # example_features.shape\n",
    "    y_pred_binder = rnn_model.predict(example_features).argmax(axis=-1)\n",
    "    y_pred.extend([idx2label[y] for y in y_pred_binder[0]])\n",
    "    y_true.extend([idx2label[y] for y in y_true_binder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6757859051984949"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklm.cohen_kappa_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([idx2label[y] for y in y_pred_binder[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([idx2label[y] for y in y_true_binder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
