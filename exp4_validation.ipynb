{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "import model_img\n",
    "import fasttext\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "from keras import regularizers\n",
    "from importlib import reload\n",
    "from sklearn import metrics as sklm\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# CHOSEN_GPU_ID = 1\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "#   try:\n",
    "#     tf.config.experimental.set_visible_devices(gpus[CHOSEN_GPU_ID], 'GPU')\n",
    "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Visible devices must be set before GPUs have been initialized\n",
    "#     print(e)\n",
    "# else:\n",
    "#     print('No GPUs detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/srv/home/gwiedemann/pss-lre/model.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model_img)\n",
    "reload(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text_train = model.read_csv_data(\"data/archive20k/text/dataset.train\")\n",
    "data_text_test = model.read_csv_data(\"data/archive20k/text/dataset.validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive26k\n",
      "0.8557409224730128\n",
      "0.0\n",
      "0.2521440823327616\n",
      "0.1260720411663808\n",
      "tobacco\n",
      "0.42084942084942084\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# MAJORITY BASELINE\n",
    "\n",
    "print(\"archive26k\")\n",
    "tmp = model.read_csv_data(\"data/archive20k/text/dataset.test\")\n",
    "_, y_tmp, _, _, _ = zip(*tmp)\n",
    "print(sklm.accuracy_score([1 if y == 'NextPage' else 0 for y in y_tmp], [1] * len(y_tmp)))\n",
    "print(sklm.cohen_kappa_score([1 if y == 'NextPage' else 0 for y in y_tmp], [1] * len(y_tmp)))\n",
    "print(sklm.f1_score([1 if y == 'FirstPage' else 0 for y in y_tmp], [1] * len(y_tmp), average='binary', pos_label=1))\n",
    "print(sklm.f1_score([1 if y == 'FirstPage' else 0 for y in y_tmp], [1] * len(y_tmp), average='macro'))\n",
    "\n",
    "print(\"tobacco\")\n",
    "tmp = model.read_csv_data(\"data/Tobacco800/dataset.test\", csvformat='Tobacco800')\n",
    "_, y_tmp, _, _, _ = zip(*tmp)\n",
    "print(sklm.accuracy_score([1 if y == 'NextPage' else 0 for y in y_tmp], [1] * len(y_tmp)))\n",
    "print(sklm.cohen_kappa_score([1 if y == 'NextPage' else 0 for y in y_tmp], [1] * len(y_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ft' not in locals():\n",
    "    ft = fasttext.load_model(\"./../embeddings/wiki.de.bin\")\n",
    "    model.ft = ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "# model_text = load_model(\"models/exp1_single-page_repeat-07.hdf5\")\n",
    "model_text = load_model(\"models/exp1_prev-page_repeat-01.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8795289855072463\n",
      "Kappa: 0.5661347090090533\n"
     ]
    }
   ],
   "source": [
    "_, y_true, _, _, _ = zip(*data_text_test)\n",
    "y_true = [1 if y == 'FirstPage' else 0 for y in y_true]\n",
    "y_predict = np.round(model_text.predict_generator(model.TextFeatureGenerator2(data_text_test)))\n",
    "print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predict)))\n",
    "print(\"Kappa: \" + str(sklm.cohen_kappa_score(y_true, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text.layers.pop()\n",
    "model_text_features = Model(model_text.input, model_text.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_train = model_text_features.predict_generator(model.TextFeatureGenerator2(data_text_train))\n",
    "text_features_test = model_text_features.predict_generator(model.TextFeatureGenerator2(data_text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image_train = model_img.read_csv_data(\"data/archive20k/text/dataset.train\")\n",
    "data_image_test = model_img.read_csv_data(\"data/archive20k/text/dataset.validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_image = load_model(\"models/exp2_img_repeat-07.hdf5\")\n",
    "model_image = load_model(\"models/exp2_prev-page_repeat-05.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8596014492753623\n",
      "Kappa: 0.47228042041474805\n"
     ]
    }
   ],
   "source": [
    "_, y_true, _, _, _ = zip(*data_text_test)\n",
    "y_true = [1 if y == 'FirstPage' else 0 for y in y_true]\n",
    "y_predict = np.round(model_image.predict_generator(model_img.ImageFeatureGenerator(data_image_test, img_dim, prevpage=True)))\n",
    "print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predict)))\n",
    "print(\"Kappa: \" + str(sklm.cohen_kappa_score(y_true, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_image.layers.pop()\n",
    "model_image_features = Model(model_image.input, model_image.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_train = model_image_features.predict_generator(model_img.ImageFeatureGenerator(data_image_train, img_dim, prevpage=True))\n",
    "image_features_test = model_image_features.predict_generator(model_img.ImageFeatureGenerator(data_image_test, img_dim, prevpage=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and test targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "_, data_train_y, _, _, _ = zip(*data_text_train)\n",
    "data_train_y = [1 if y == 'FirstPage' else 0 for y in data_train_y]\n",
    "# Test data\n",
    "_, data_test_y, _, _, _ = zip(*data_text_test)\n",
    "data_test_y = [1 if y == 'FirstPage' else 0 for y in data_test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, validation_x, validation_y, metric = 'kappa'):\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "        self.validation_x = validation_x\n",
    "        self.validation_y = validation_y\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = np.round(self.model.predict(self.validation_x))\n",
    "        true_labels = self.validation_y\n",
    "\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='binary', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metric)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            self.model.save(self.filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17376, 102)\n",
      "(4416, 102)\n"
     ]
    }
   ],
   "source": [
    "lda_train_x = []\n",
    "with open(\"data/archive20k/lda_train.csv\") as f:\n",
    "    next(f)\n",
    "    for l in f:\n",
    "        lda_train_x.append([float(n) for n in l.split(\",\")])\n",
    "lda_train_x = np.array(lda_train_x)\n",
    "print(lda_train_x.shape)\n",
    "\n",
    "lda_test_x = []\n",
    "with open(\"data/archive20k/lda_validation.csv\") as f:\n",
    "    next(f)\n",
    "    for l in f:\n",
    "        lda_test_x.append([float(n) for n in l.split(\",\")])\n",
    "lda_test_x = np.array(lda_test_x)\n",
    "print(lda_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17376, 102)\n",
      "(17376, 102)\n",
      "(4416, 102)\n",
      "(4416, 102)\n"
     ]
    }
   ],
   "source": [
    "features_x_train = lda_train_x\n",
    "features_x_test = lda_test_x\n",
    "sequence_x_train = np.empty((len(features_x_train),2,len(features_x_train[0])))\n",
    "sep_tp_x_train = np.empty((len(features_x_train),len(features_x_train[0])))\n",
    "sep_pp_x_train = np.empty((len(features_x_train),len(features_x_train[0])))\n",
    "for i, d in enumerate(features_x_train):\n",
    "    if d[3] == \"\":\n",
    "        prev_page = np.zeros((1,len(features_x_train[0])))\n",
    "    else:\n",
    "        prev_page = features_x_train[i-1]\n",
    "    sequence_x_train[i][0] = sep_pp_x_train[i] = prev_page\n",
    "    sequence_x_train[i][1] = sep_tp_x_train[i] = features_x_train[i]\n",
    "\n",
    "sequence_x_test = np.empty((len(features_x_test),2,len(features_x_test[0])))\n",
    "sep_tp_x_test = np.empty((len(features_x_test),len(features_x_test[0])))\n",
    "sep_pp_x_test = np.empty((len(features_x_test),len(features_x_test[0])))\n",
    "for i, d in enumerate(features_x_test):\n",
    "    if d[3] == \"\":\n",
    "        prev_page = np.zeros((1,len(features_x_test[0])))\n",
    "    else:\n",
    "        prev_page = features_x_test[i-1]\n",
    "    sequence_x_test[i][0] = sep_pp_x_test[i] = prev_page\n",
    "    sequence_x_test[i][1] = sep_tp_x_test[i] = features_x_test[i]\n",
    "print(sep_tp_x_train.shape)\n",
    "print(sep_pp_x_train.shape)\n",
    "print(sep_tp_x_test.shape)\n",
    "print(sep_pp_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_x_2inputs_train = [sep_tp_x_train, sep_pp_x_train]\n",
    "sequence_x_2inputs_test = [sep_tp_x_test, sep_pp_x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text = load_model(\"models/exp1_prev-page_repeat-01.hdf5\")\n",
    "model_image = load_model(\"models/exp2_prev-page_repeat-05.hdf5\")\n",
    "model_lda = load_model(\"models/exp3_img-text_lda_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t = model_text.predict_generator(model.TextFeatureGenerator2(data_text_test))\n",
    "p_v = model_image.predict_generator(model_img.ImageFeatureGenerator(data_image_test, img_dim, prevpage=True))\n",
    "p_l = model_lda.predict(sequence_x_2inputs_test)\n",
    "p_t = np.concatenate([1 - p_t, p_t], axis = 1) # probability from text model\n",
    "p_v = np.concatenate([1 - p_v, p_v], axis = 1) # probability from visual model\n",
    "p_l = np.concatenate([1 - p_l, p_l], axis = 1) # probability from lda model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.1 0.2\n",
      "Accuracy: 0.8890398550724637\n",
      "Kappa: 0.5905957197061001\n"
     ]
    }
   ],
   "source": [
    "i = 0.4 \n",
    "j = 0.1 \n",
    "k = 0.2\n",
    "\n",
    "y_predict = np.argmax(np.power(p_t, i) * np.power(p_v, j) * np.power(p_l, k), axis = 1)\n",
    "acc = sklm.accuracy_score(y_true, y_predict)\n",
    "kappa = sklm.cohen_kappa_score(y_true, y_predict)\n",
    "\n",
    "print(str(i) + \" \" + str(j) + \" \" + str(k))\n",
    "print(\"Accuracy: \" + str(acc))\n",
    "print(\"Kappa: \" + str(kappa))\n",
    "        \n",
    "# Best results test set: \n",
    "# Accuracy: 0.9338567222767419\n",
    "# Kappa: 0.7078080262749252\n",
    "# Best results validation set (hold out): \n",
    "# Accuracy: 0.8899456521739131\n",
    "# Kappa: 0.5914350798654169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3465,   92],\n",
       "       [ 398,  461]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklm.confusion_matrix(y_true, y_predict)\n",
    "# fp: 92\n",
    "# fn: 398"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single vs multipage docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter(text_features, single_page = True):\n",
    "    bool_filter = []\n",
    "    for i in range(len(text_features)-1):\n",
    "        if text_features[i][1] == 'FirstPage' and text_features[i+1][1] != 'NextPage':\n",
    "            bool_filter.append(True)\n",
    "        else:\n",
    "            bool_filter.append(False)\n",
    "    if text_features[len(text_features)-1][1] == 'FirstPage':\n",
    "        bool_filter.append(True)\n",
    "    else:\n",
    "        bool_filter.append(False)\n",
    "    \n",
    "    if single_page:\n",
    "        return bool_filter\n",
    "    else:\n",
    "        return [False if y else True for y in bool_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490\n",
      "0.42244897959183675\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [283, 207]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_y_true = np.array(y_true)\n",
    "np_y_pred = np.array(y_predict)\n",
    "sp_docs = get_filter(data_text_test, single_page = True)\n",
    "\n",
    "acc = sklm.accuracy_score(np_y_true[sp_docs], np_y_pred[sp_docs])\n",
    "kappa = sklm.cohen_kappa_score(np_y_true[sp_docs], np_y_pred[sp_docs])\n",
    "\n",
    "print(np.sum(sp_docs))\n",
    "print(acc)\n",
    "print(kappa)\n",
    "\n",
    "sklm.confusion_matrix(np_y_true[sp_docs], np_y_pred[sp_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3926\n",
      "0.9472745797249108\n",
      "0.6815187428823133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3465,   92],\n",
       "       [ 115,  254]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_docs = get_filter(data_text_test, single_page = False)\n",
    "\n",
    "acc = sklm.accuracy_score(np_y_true[mp_docs], np_y_pred[mp_docs])\n",
    "kappa = sklm.cohen_kappa_score(np_y_true[mp_docs], np_y_pred[mp_docs])\n",
    "\n",
    "print(np.sum(mp_docs))\n",
    "print(acc)\n",
    "print(kappa)\n",
    "\n",
    "sklm.confusion_matrix(np_y_true[mp_docs], np_y_pred[mp_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divided into Single and Multi-Page Documents\n",
    "def filter_dataset(text_features, img_features, lda_features, y, single_page = True):\n",
    "    filtered_txt = []\n",
    "    filtered_img = []\n",
    "    filtered_lda_tp = []\n",
    "    filtered_lda_pp = []\n",
    "    filtered_y = []\n",
    "    \n",
    "    if single_page:\n",
    "        for i in range(len(text_features)-2):\n",
    "            if text_features[i][1] == 'FirstPage' and text_features[i+1][1] != 'NextPage':\n",
    "                filtered_txt.append(text_features[i])\n",
    "                filtered_img.append(img_features[i])\n",
    "                filtered_lda_tp.append(lda_features[0][i])\n",
    "                filtered_lda_pp.append(lda_features[1][i])\n",
    "                filtered_y.append(y[i])\n",
    "        i = len(text_features)-1\n",
    "        if text_features[i][1] == 'FirstPage':\n",
    "            filtered_txt.append(text_features[i])\n",
    "            filtered_img.append(img_features[i])\n",
    "            filtered_lda_tp.append(lda_features[0][i])\n",
    "            filtered_lda_pp.append(lda_features[1][i])\n",
    "            filtered_y.append(y[i])\n",
    "    else:\n",
    "        for i in range(len(text_features)-2):\n",
    "            if (text_features[i][1] == 'FirstPage' and text_features[i+1][1] != 'FirstPage') or (text_features[i][1] == 'NextPage'):\n",
    "                filtered_txt.append(text_features[i])\n",
    "                filtered_img.append(img_features[i])\n",
    "                filtered_lda_tp.append(lda_features[0][i])\n",
    "                filtered_lda_pp.append(lda_features[1][i])\n",
    "                filtered_y.append(y[i])\n",
    "        i = len(text_features)-1\n",
    "        if text_features[i][1] != 'FirstPage':\n",
    "            filtered_txt.append(text_features[i])\n",
    "            filtered_img.append(img_features[i])\n",
    "            filtered_lda_tp.append(lda_features[0][i])\n",
    "            filtered_lda_pp.append(lda_features[1][i])\n",
    "            filtered_y.append(y[i])\n",
    "    return filtered_txt, filtered_img, [filtered_lda_tp, filtered_lda_pp], filtered_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3926\n"
     ]
    }
   ],
   "source": [
    "feat_txt, feat_img, feat_lda, y_true_filtered = filter_dataset(data_text_test, data_image_test, sequence_x_2inputs_test, y_true, \n",
    "                                                               single_page=False)\n",
    "print(len(y_true_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t = model_text.predict_generator(model.TextFeatureGenerator2(feat_txt))\n",
    "p_v = model_image.predict_generator(model_img.ImageFeatureGenerator(feat_img, img_dim, prevpage=True))\n",
    "p_l = model_lda.predict(feat_lda)\n",
    "p_t = np.concatenate([1 - p_t, p_t], axis = 1) # probability from text model\n",
    "p_v = np.concatenate([1 - p_v, p_v], axis = 1) # probability from visual model\n",
    "p_l = np.concatenate([1 - p_l, p_l], axis = 1) # probability from lda model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.1 0.2\n",
      "Accuracy: 0.9472745797249108\n",
      "Kappa: 0.6815187428823133\n"
     ]
    }
   ],
   "source": [
    "i = 0.4 \n",
    "j = 0.1 \n",
    "k = 0.2\n",
    "\n",
    "y_predict = np.argmax(np.power(p_t, i) * np.power(p_v, j) * np.power(p_l, k), axis = 1)\n",
    "acc = sklm.accuracy_score(y_true_filtered, y_predict)\n",
    "kappa = sklm.cohen_kappa_score(y_true_filtered, y_predict)\n",
    "\n",
    "print(str(i) + \" \" + str(j) + \" \" + str(k))\n",
    "print(\"Accuracy: \" + str(acc))\n",
    "print(\"Kappa: \" + str(kappa))\n",
    "\n",
    "# Single Page Docs\n",
    "# Accuracy: 0.41922290388548056\n",
    "# Kappa: 0.0\n",
    "\n",
    "# Multi-Page Docs\n",
    "# Accuracy: 0.9488028527763627\n",
    "# Kappa: 0.6868376125359246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "fp = 0\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == 1 and y_true_filtered[i] == 0:\n",
    "        fp += 1\n",
    "    if y_predict[i] == 0 and y_true_filtered[i] == 1:\n",
    "        fn += 1\n",
    "print(fp)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3465,   92],\n",
       "       [ 115,  254]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-page\n",
    "# FP: 84\n",
    "# FN: 117\n",
    "\n",
    "# Single-page\n",
    "# FP: not defined\n",
    "# FN: 282\n",
    "sklm.confusion_matrix(y_true_filtered, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4415"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3926+489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4416"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
